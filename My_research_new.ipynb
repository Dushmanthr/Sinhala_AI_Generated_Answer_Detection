{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dushmanthr/Sinhala_AI_Generated_Answer_Detection/blob/main/My_research_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frCKoc3kayfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5691520-cafb-4c5a-a3a0-ab24e5aaf474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sinling\n",
            "  Downloading sinling-0.3.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting emoji (from sinling)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sinling) (1.4.2)\n",
            "Collecting pygtrie (from sinling)\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting sklearn-crfsuite (from sinling)\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from sinling) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->sinling) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->sinling) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->sinling) (4.67.1)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->sinling)\n",
            "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->sinling) (1.6.1)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->sinling) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite->sinling) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite->sinling) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite->sinling) (3.5.0)\n",
            "Downloading sinling-0.3.6-py3-none-any.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygtrie, python-crfsuite, emoji, sklearn-crfsuite, sinling\n",
            "Successfully installed emoji-2.14.1 pygtrie-2.5.0 python-crfsuite-0.9.11 sinling-0.3.6 sklearn-crfsuite-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sinling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMtk_IQpgAbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5443e29a-b18e-4277-c78d-39639140d8ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting advertools\n",
            "  Downloading advertools-0.16.4-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from advertools) (2.2.2)\n",
            "Requirement already satisfied: pyasn1>=0.4 in /usr/local/lib/python3.11/dist-packages (from advertools) (0.6.1)\n",
            "Collecting scrapy>=2.5.0 (from advertools)\n",
            "  Downloading Scrapy-2.12.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting twython>=3.8.0 (from advertools)\n",
            "  Downloading twython-3.9.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from advertools) (17.0.0)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.11/dist-packages (from advertools) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0->advertools) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0->advertools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0->advertools) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0->advertools) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->advertools) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->advertools) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->advertools) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->advertools) (2024.12.14)\n",
            "Collecting Twisted>=21.7.0 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading twisted-24.11.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: cryptography>=37.0.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (43.0.3)\n",
            "Collecting cssselect>=0.9.1 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting itemloaders>=1.0.1 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading itemloaders-1.3.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting parsel>=1.5.0 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading parsel-1.10.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyOpenSSL>=22.0.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (24.2.1)\n",
            "Collecting queuelib>=1.4.2 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading queuelib-1.7.0-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting service-identity>=18.1.0 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading service_identity-24.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting w3lib>=1.17.0 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading w3lib-2.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting zope.interface>=5.1.0 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protego>=0.1.15 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading Protego-0.4.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting itemadapter>=0.1.0 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading itemadapter-0.11.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (24.2)\n",
            "Collecting tldextract (from scrapy>=2.5.0->advertools)\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: lxml>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (5.3.0)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from scrapy>=2.5.0->advertools) (0.7.1)\n",
            "Collecting PyDispatcher>=2.0.5 (from scrapy>=2.5.0->advertools)\n",
            "  Downloading PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from twython>=3.8.0->advertools) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=37.0.0->scrapy>=2.5.0->advertools) (1.17.1)\n",
            "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy>=2.5.0->advertools)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.0->advertools) (1.17.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.4.0->twython>=3.8.0->advertools) (3.2.2)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (25.1.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (0.4.1)\n",
            "Collecting automat>=24.8.0 (from Twisted>=21.7.0->scrapy>=2.5.0->advertools)\n",
            "  Downloading Automat-24.8.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting constantly>=15.1 (from Twisted>=21.7.0->scrapy>=2.5.0->advertools)\n",
            "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting hyperlink>=17.1.1 (from Twisted>=21.7.0->scrapy>=2.5.0->advertools)\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting incremental>=24.7.0 (from Twisted>=21.7.0->scrapy>=2.5.0->advertools)\n",
            "  Downloading incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy>=2.5.0->advertools) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from zope.interface>=5.1.0->scrapy>=2.5.0->advertools) (75.1.0)\n",
            "Collecting requests-file>=1.4 (from tldextract->scrapy>=2.5.0->advertools)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->scrapy>=2.5.0->advertools) (3.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=37.0.0->scrapy>=2.5.0->advertools) (2.22)\n",
            "Downloading advertools-0.16.4-py2.py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Scrapy-2.12.0-py2.py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
            "Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading itemadapter-0.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading itemloaders-1.3.2-py3-none-any.whl (12 kB)\n",
            "Downloading parsel-1.10.0-py2.py3-none-any.whl (17 kB)\n",
            "Downloading Protego-0.4.0-py2.py3-none-any.whl (8.6 kB)\n",
            "Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
            "Downloading queuelib-1.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading service_identity-24.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading twisted-24.11.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading w3lib-2.3.1-py3-none-any.whl (21 kB)\n",
            "Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Automat-24.8.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
            "Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading incremental-24.7.2-py3-none-any.whl (20 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: PyDispatcher, zope.interface, w3lib, queuelib, protego, jmespath, itemadapter, incremental, hyperlink, cssselect, constantly, automat, Twisted, requests-file, parsel, twython, tldextract, service-identity, itemloaders, scrapy, advertools\n",
            "Successfully installed PyDispatcher-2.0.7 Twisted-24.11.0 advertools-0.16.4 automat-24.8.1 constantly-23.10.4 cssselect-1.2.0 hyperlink-21.0.0 incremental-24.7.2 itemadapter-0.11.0 itemloaders-1.3.2 jmespath-1.0.1 parsel-1.10.0 protego-0.4.0 queuelib-1.7.0 requests-file-2.1.0 scrapy-2.12.0 service-identity-24.2.0 tldextract-5.1.3 twython-3.9.1 w3lib-2.3.1 zope.interface-7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install advertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDwb-Gqughph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc174af0-9e40-45c9-cd84-616a562e21f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting translate\n",
            "  Downloading translate-3.6.1-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from translate) (8.1.8)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from translate) (5.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from translate) (2.32.3)\n",
            "Collecting libretranslatepy==2.1.1 (from translate)\n",
            "  Downloading libretranslatepy-2.1.1-py3-none-any.whl.metadata (233 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->translate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->translate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->translate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->translate) (2024.12.14)\n",
            "Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
            "Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
            "Installing collected packages: libretranslatepy, translate\n",
            "Successfully installed libretranslatepy-2.1.1 translate-3.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK5nQX7jhC0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f65227b-f373-418b-9289-63926e76f36f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyenchant\n",
            "  Downloading pyenchant-3.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading pyenchant-3.2.2-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyenchant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaMhHQ3Eh6E5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17f58af-66ca-45b6-df25-e3f5ae699432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "from sinling import SinhalaTokenizer as tokenizer,SinhalaStemmer as stemmer, POSTagger,preprocess, word_joiner,word_splitter\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize,TweetTokenizer\n",
        "from nltk.probability import FreqDist\n",
        "import advertools as adv\n",
        "from pathlib import Path\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB\n",
        "from sklearn import linear_model\n",
        "\n",
        "import codecs\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer as Detok\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "34TLfAiqiO2S",
        "outputId": "52eb94d2-1483-4f98-b8a5-fba7e45f6354"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1fff2d2-97d6-4491-a197-f4d6935f05a3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a1fff2d2-97d6-4491-a197-f4d6935f05a3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Processed.xlsx to Processed.xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQLT9t3-je97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "outputId": "1f52496d-84a1-4829-9636-8fb84e25af6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                            රාවණා 1\n",
            "1                     ලෝන්ලි ප්ලැනට්\n",
            "2                             වූහාන්\n",
            "3                              25200\n",
            "4     ආසියා රග්බී පළමු කාණ්ඩ ශූරතාවය\n",
            "5                            වලයාකාර\n",
            "6             නෝත්රා දාම් දෙව්මැදුර \n",
            "7                             ලන්ඩන්\n",
            "8                               චීනය\n",
            "9                     උණ කුලයේ ශාඛයි\n",
            "10                   මැක්සිම් ගෝර්කි\n",
            "Name: Answers, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seaborn/categorical.py:2641: UserWarning: cmr10 font should ideally be used with mathtext, set axes.formatter.use_mathtext to True\n",
            "  ax = plt.gca()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# %% read csv file data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "file = pd.read_excel('Processed.xlsx')\n",
        "#pd.read_csv(Path().joinpath('data','traindata2.csv'))\n",
        "print(file['Answers'].head(11))\n",
        "plt.rcParams['font.sans-serif']= \"cmr10\"\n",
        "sns.countplot(x='Label',hue='Label',data=file)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFH5BstQpjOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4aa57a-753a-4e99-c66e-581d967881e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                                 රාවණා 1\n",
            "1                                          ලෝන්ලි ප්ලැනට්\n",
            "2                                                  වූහාන්\n",
            "3                                                   25200\n",
            "4                          ආසියා රග්බී පළමු කාණ්ඩ ශූරතාවය\n",
            "                              ...                        \n",
            "2001    ශ්‍රී ලංකාවේ ප්‍රථම සිංහල දිනපතා පුවත්පත වන්නේ...\n",
            "2002    ශ්‍රී ලංකාවේ ප්‍රථම ඉරිදා පුවත්පත වන්නේ ස්වදේශ...\n",
            "2003    ශ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව ලෙස සැලකෙන්නේ ...\n",
            "2004    ශ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව වන \"නිලා\" නිර්...\n",
            "2005    ඔව්, ශ්‍රී ලංකාවේ නූතන පන්සල් චිත්‍ර කථාවේ පුර...\n",
            "Name: Answers, Length: 2006, dtype: object\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_excel('Processed.xlsx')\n",
        "\n",
        "print(df['Answers'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5exibbc7aRv"
      },
      "outputs": [],
      "source": [
        "stopwords_set = [\"සහ\",\"සමග\",\"සමඟ\",\"අහා\",\"ආහ්\",\"ආ\",\"ඕහෝ\",\"අනේ\",\"අඳෝ\",\"අපොයි\",\"පෝ\",\"අයියෝ\",\"ආයි\",\"ඌයි\",\"චී\",\"චිහ්\",\"චික්\",\"හෝ‍\",\"දෝ\",\n",
        "                 \"දෝහෝ\",\"මෙන්\",\"සේ\",\"වැනි\",\"බඳු\",\"වන්\",\"අයුරු\",\"අයුරින්\",\"ලෙස\",\"වැඩි\",\"ශ්‍රී\",\"හා\",\"ය\",\"නිසා\",\"නිසාවෙන්\",\"බවට\",\"බව\",\"බවෙන්\",\"නම්\",\"වැඩි\",\"සිට\",\n",
        "                 \"දී\",\"මහා\",\"මහ\",\"පමණ\",\"පමණින්\",\"පමන\",\"වන\",\"විට\",\"විටින්\",\"මේ\",\"මෙලෙස\",\"මෙයින්\",\"ඇති\",\"ලෙස\",\"සිදු\",\"වශයෙන්\",\"යන\",\"සඳහා\",\"මගින්\",\"හෝ‍\",\n",
        "                 \"ඉතා\",\"ඒ\",\"එම\",\"ද\",\"අතර\",\"විසින්\",\"සමග\",\"පිළිබඳව\",\"පිළිබඳ\",\"තුළ\",\"බව\",\"වැනි\",\"මහ\",\"මෙම\",\"මෙහි\",\"මේ\",\"වෙත\",\"වෙතින්\",\"වෙතට\",\"වෙනුවෙන්\",\n",
        "                 \"වෙනුවට\",\"වෙන\",\"ගැන\",\"නෑ\",\"අනුව\",\"නව\",\"පිළිබඳ\",\"විශේෂ\",\"දැනට\",\"එහෙන්\",\"මෙහෙන්\",\"එහේ\",\"මෙහේ\",\"ම\",\"තවත්\",\"තව\",\"සහ\",\"දක්වා\",\"ට\",\"ගේ\",\n",
        "                 \"එ\",\"ක\",\"ක්\",\"බවත්\",\"බවද\",\"මත\",\"ඇතුලු\",\"ඇතුළු\",\"මෙසේ\",\"වඩා\",\"වඩාත්ම\",\"නිති\",\"නිතිත්\",\"නිතොර\",\"නිතර\",\"ඉක්බිති\",\"දැන්\",\"යලි\",\"පුන\",\"ඉතින්\",\n",
        "                 \"සිට\",\"සිටන්\",\"පටන්\",\"තෙක්\",\"දක්වා\",\"සා\",\"තාක්\",\"තුවක්\",\"පවා\",\"ද\",\"හෝ‍\",\"වත්\",\"විනා\",\"හැර\",\"මිස\",\"මුත්\",\"කිම\",\"කිම්\",\"ඇයි\",\"මන්ද\",\"හෙවත්\",\n",
        "                 \"නොහොත්\",\"පතා\",\"පාසා\",\"ගානෙ\",\"තව\",\"ඉතා\",\"බොහෝ\",\"වහා\",\"සෙද\",\"සැනින්\",\"හනික\",\"එම්බා\",\"එම්බල\",\"බොල\",\"නම්\",\"වනාහි\",\"කලී\",\"ඉඳුරා\",\n",
        "                 \"අන්න\",\"ඔන්න\",\"මෙන්න\",\"උදෙසා\",\"පිණිස\",\"සඳහා\",\"රබයා\",\"නිසා\",\"එනිසා\",\"එබැවින්\",\"බැවින්\",\"හෙයින්\",\"සේක්\",\"සේක\",\"ගැන\",\"අනුව\",\"පරිදි\",\"විට\",\n",
        "                 \"තෙක්\",\"මෙතෙක්\",\"මේතාක්\",\"තුරු\",\"තුරා\",\"තුරාවට\",\"තුලින්\",\"නමුත්\",\"එනමුත්\",\"වස්\",'මෙන්',\"ලෙස\",\"පරිදි\",\"එහෙත්\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2JZq56Q7l2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a29c8877-3da4-46fe-b29b-8da4e4e71055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['සහ', 'සමග', 'සමඟ', 'අහා', 'ආහ්', 'ආ', 'ඕහෝ', 'අනේ', 'අඳෝ', 'අපොයි', 'පෝ', 'අයියෝ', 'ආයි', 'ඌයි', 'චී', 'චිහ්', 'චික්', 'හෝ\\u200d', 'දෝ', 'දෝහෝ', 'මෙන්', 'සේ', 'වැනි', 'බඳු', 'වන්', 'අයුරු', 'අයුරින්', 'ලෙස', 'වැඩි', 'ශ්\\u200dරී', 'හා', 'ය', 'නිසා', 'නිසාවෙන්', 'බවට', 'බව', 'බවෙන්', 'නම්', 'වැඩි', 'සිට', 'දී', 'මහා', 'මහ', 'පමණ', 'පමණින්', 'පමන', 'වන', 'විට', 'විටින්', 'මේ', 'මෙලෙස', 'මෙයින්', 'ඇති', 'ලෙස', 'සිදු', 'වශයෙන්', 'යන', 'සඳහා', 'මගින්', 'හෝ\\u200d', 'ඉතා', 'ඒ', 'එම', 'ද', 'අතර', 'විසින්', 'සමග', 'පිළිබඳව', 'පිළිබඳ', 'තුළ', 'බව', 'වැනි', 'මහ', 'මෙම', 'මෙහි', 'මේ', 'වෙත', 'වෙතින්', 'වෙතට', 'වෙනුවෙන්', 'වෙනුවට', 'වෙන', 'ගැන', 'නෑ', 'අනුව', 'නව', 'පිළිබඳ', 'විශේෂ', 'දැනට', 'එහෙන්', 'මෙහෙන්', 'එහේ', 'මෙහේ', 'ම', 'තවත්', 'තව', 'සහ', 'දක්වා', 'ට', 'ගේ', 'එ', 'ක', 'ක්', 'බවත්', 'බවද', 'මත', 'ඇතුලු', 'ඇතුළු', 'මෙසේ', 'වඩා', 'වඩාත්ම', 'නිති', 'නිතිත්', 'නිතොර', 'නිතර', 'ඉක්බිති', 'දැන්', 'යලි', 'පුන', 'ඉතින්', 'සිට', 'සිටන්', 'පටන්', 'තෙක්', 'දක්වා', 'සා', 'තාක්', 'තුවක්', 'පවා', 'ද', 'හෝ\\u200d', 'වත්', 'විනා', 'හැර', 'මිස', 'මුත්', 'කිම', 'කිම්', 'ඇයි', 'මන්ද', 'හෙවත්', 'නොහොත්', 'පතා', 'පාසා', 'ගානෙ', 'තව', 'ඉතා', 'බොහෝ', 'වහා', 'සෙද', 'සැනින්', 'හනික', 'එම්බා', 'එම්බල', 'බොල', 'නම්', 'වනාහි', 'කලී', 'ඉඳුරා', 'අන්න', 'ඔන්න', 'මෙන්න', 'උදෙසා', 'පිණිස', 'සඳහා', 'රබයා', 'නිසා', 'එනිසා', 'එබැවින්', 'බැවින්', 'හෙයින්', 'සේක්', 'සේක', 'ගැන', 'අනුව', 'පරිදි', 'විට', 'තෙක්', 'මෙතෙක්', 'මේතාක්', 'තුරු', 'තුරා', 'තුරාවට', 'තුලින්', 'නමුත්', 'එනමුත්', 'වස්', 'මෙන්', 'ලෙස', 'පරිදි', 'එහෙත්']\n"
          ]
        }
      ],
      "source": [
        "print(stopwords_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq4hqLTk_LGe"
      },
      "outputs": [],
      "source": [
        "translate_words_dict = {\n",
        "    \"unp\": \"එක්සත් ජාතික පක්ෂය\",\n",
        "    \"muslim\": \"මුස්ලිම්\",\n",
        "    \"srilankanpolitics\": \"ශ්‍රී ලංකන් දේශපාලනය\",\n",
        "    \"council\": \"සභාව\",\n",
        "    \"sinhala\": \"සිංහල\",\n",
        "    \"buddhist\": \"බෞද්ධ\",\n",
        "    \"buddhism\": \"බුද්ධාගම\",\n",
        "    \"srilanka\": \"ශ්‍රී ලංකාව\",\n",
        "    \"racist\": \"ජාතිවාදී\",\n",
        "    \"presidentialfirst\": \"පළමු ජනාධිපති\",\n",
        "    \"feeling\": \"හැඟීම\",\n",
        "    \"feminist\": \"ස්ත්‍රීවාදී\",\n",
        "    \"loved\": \"ආදරය කළා\",\n",
        "    \"team\": \"කණ්ඩායම\",\n",
        "    \"tclsl\":\"ට්විටර් ක්‍රිකට් ලීගය ශ්‍රී ලංකාව\",\n",
        "    \"pongal\": \"පොංගල්\",\n",
        "    \"pongalfestival\": \"පොංගල් උත්සවය\",\n",
        "    \"women\": \"කාන්තා\",\n",
        "    \"nextpresidentinsl\": \"ශ්‍රී ලංකාවේ මීළඟ ජනාධිපති \",\n",
        "    \"seventhexecutivepresident\": \"හත්වන විධායක සභාපති\",\n",
        "    \"hate\": \"වෛරය\",\n",
        "    \"love\": \"ආදරය\",\n",
        "    \"angry\": \"තරහයි\",\n",
        "    \"doctor\": \"ඩොක්ටර්\",\n",
        "    \"ltte\": \"එල්ටීටීඊය\",\n",
        "    \"lka\": \"‍ශ්‍රී ලංකාව\",\n",
        "    \"hurt\": \"රිදෙනවා\",\n",
        "    \"typo\": \"යතුරු ලියනය\",\n",
        "    \"racial\": \"වාර්ගික\",\n",
        "    \"hatred\": \"වෛරය\",\n",
        "    \"halal\": \"හලාල්\",\n",
        "    \"wicket\": \"කඩුල්ල\",\n",
        "    \"taker\": \"ටේකර්\",\n",
        "    \"indoor\": \"ගෘහස්ථ\",\n",
        "    \"attacker\": \"ප්‍රහාරකයා\",\n",
        "    \"attack\": \"ප්රහාරය\",\n",
        "    \"spikers\": \"ස්පිකර්ස්\",\n",
        "    \"training\": \"පුහුණුව\",\n",
        "    \"final\": \"අවසාන\",\n",
        "    \"match\": \"තරගය\",\n",
        "    \"tournament\": \"තරඟාවලිය\",\n",
        "    \"youth\": \"තරුණ\",\n",
        "    \"amen\": \"ආමෙන්\",\n",
        "    \"enough\": \"ඇති\",\n",
        "    \"standagainstracism\": \"ජාතිවාදයට එරෙහිව නැගී සිටින්න\"\n",
        "}\n",
        "\n",
        "def translate_to_sinhala(word: str) -> str:\n",
        "  word = word.lower()\n",
        "  if word in translate_words_dict:\n",
        "        return translate_words_dict[word]\n",
        "  return word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhLs1C9Y_A3T"
      },
      "outputs": [],
      "source": [
        "from sinling import SinhalaTokenizer as tokenizer,SinhalaStemmer as stemmer, POSTagger,preprocess, word_joiner,word_splitter\n",
        "stemmer = stemmer()\n",
        "\n",
        "def stem_word(word: str) -> str:\n",
        "    word= translate_to_sinhala(word)\n",
        "    \"\"\"\n",
        "    Stemming words\n",
        "    :param word: word\n",
        "    :return: stemmed word\n",
        "    \"\"\"\n",
        "    if len(word) < 4:\n",
        "        return word\n",
        "\n",
        "    # remove 'ට'\n",
        "    if word[-1] == 'ට':\n",
        "        return word[:-1]\n",
        "\n",
        "    # remove 'ම'\n",
        "    if word[-1] == 'ම':\n",
        "        return word[:-1]\n",
        "\n",
        "    # remove 'ද'\n",
        "    if word[-1] == 'ද':\n",
        "        return word[:-1]\n",
        "\n",
        "    # remove 'ටත්'\n",
        "    if word[-3:] == 'ටත්':\n",
        "        return word[:-3]\n",
        "\n",
        "    # remove 'එක්'\n",
        "    if word[-3:] == 'ෙක්':\n",
        "        return word[:-3]\n",
        "\n",
        "    # remove 'යේ'\n",
        "    if word[-2:] == 'යේ':\n",
        "        return word[:-2]\n",
        "\n",
        "    # remove 'ගෙ' (instead of ගේ because this step comes after simplifying text)\n",
        "    if word[-2:] == 'ගෙ':\n",
        "        return word[:-2]\n",
        "\n",
        "    # remove 'එ'\n",
        "    if word[-1:] == 'ෙ':\n",
        "        return word[:-1]\n",
        "\n",
        "    # remove 'ක්'\n",
        "    if word[-2:] == 'ක්':\n",
        "        return word[:-2]\n",
        "\n",
        "    # remove 'වත්'\n",
        "    if word[-3:] == 'වත්':\n",
        "        return word[:-3]\n",
        "\n",
        "    word=stemmer.stem(word)\n",
        "    word=word[0]\n",
        "\n",
        "\n",
        "    # else\n",
        "    return word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNj26MNQ7992"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def filter_stop_words(sentences):\n",
        "    filtered_sentences = []\n",
        "    detokenizer = Detok()\n",
        "    for sentence in sentences:\n",
        "        tokenized_sentence = word_tokenize(sentence)\n",
        "        filtered_sentence = [word for word in tokenized_sentence if word not in stopwords_set]\n",
        "        filtered_sentence = []\n",
        "        for w in tokenized_sentence:\n",
        "            if w not in stopwords_set:\n",
        "                filtered_sentence.append(stem_word(w))\n",
        "        filtered_sentences.append(filtered_sentence)\n",
        "    return filtered_sentences\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpUYnUoC-Oqv"
      },
      "outputs": [],
      "source": [
        "def detokenize(filtered_sentences):\n",
        "    detokenized_sentences = []\n",
        "    for sentence in filtered_sentences:\n",
        "        detokenized_sentences.append(TreebankWordDetokenizer().detokenize(sentence))\n",
        "    return detokenized_sentences\n",
        "\n",
        "    print(detokenized_sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epEbye9yDr6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c2f684-84af-4a75-e055-a8a7c70bd5dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2006 entries, 0 to 2005\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Answers  2000 non-null   object\n",
            " 1   Label    2006 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 31.5+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cr5kgwpEKg1"
      },
      "outputs": [],
      "source": [
        "df['Answers'] = df['Answers'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxajLOkuDEDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c936b4-eac9-47dd-e283-a55f56d785a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt_tab')\n",
        "filtered_sentences = filter_stop_words(df['Answers'])\n",
        "detokenized_sentences = detokenize(filtered_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUhV37hFERW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c7cfa7-1cca-46d1-f541-bb94d91069f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['රාවණ 1',\n",
              " 'ලෝන්ලි ප්ලැනට',\n",
              " 'වූහා',\n",
              " '25200',\n",
              " 'ආසි රග්බ පළ කාණ්ඩ ශූරතාව',\n",
              " 'වලයාකාර',\n",
              " 'නෝත්ර දා දෙව්මැදුර',\n",
              " 'ලන්ඩ',\n",
              " 'චීන',\n",
              " 'උණ කුල ශාඛ',\n",
              " 'මැක්සි ගෝර්',\n",
              " 'ඇෆ්ලටොක්සී',\n",
              " 'කියුබා',\n",
              " 'කැරොලොය ජූරි',\n",
              " 'පිහිනී',\n",
              " 'ඉන්දියා',\n",
              " 'ආචාර්\\u200d ශිරාණි බණ්ඩාරනා',\n",
              " 'ජිනී ස්විස්ටර්ලන්ත',\n",
              " 'මිථාලි රාජ',\n",
              " 'මධ්යධරණ මුහු රතු මුහු',\n",
              " 'ෂෙයි හසී',\n",
              " 'මේස පන්ද',\n",
              " 'දක ඇමරික අන්දීස',\n",
              " 'ජනමාධ්\\u200d අමාත්යංශ',\n",
              " 'ජී.බ . සේනන මහත',\n",
              " 'චීන, තායිවාන සිංගප්පූර',\n",
              " 'සෝඩිය ක්ලෝරයිඩ',\n",
              " 'නීල ආර්ථික',\n",
              " 'ෆැල්ක 9',\n",
              " 'ශාන් නිකේතන',\n",
              " 'රැම්සාර',\n",
              " 'තාඩ',\n",
              " 'ඩෙන්මාර්ක',\n",
              " 'රැෆ්ලේශි ආර්නෝල්ඩ',\n",
              " 'ස්විස්ටර්ලන්ත',\n",
              " 'වැලන්ටි ටෙරෙෂ්කෝ',\n",
              " 'මහාචාර් මොහා මුණසිංහ',\n",
              " 'නේපාල',\n",
              " 'සමුද්\\u200dර පරිසර ආරක්ෂණ අධිකාර',\n",
              " 'ෂෙන්ෂ 12',\n",
              " 'මීටර 330',\n",
              " 'ජෝර්ජ වොෂිංට',\n",
              " 'සෙන්ට වින්සන්ට දූපත',\n",
              " 'ගංග්න ස්ටයිල නැටු',\n",
              " 'ජපාන',\n",
              " 'ඩන්ක වයිට',\n",
              " 'ජේ . රොබට ඕපන්හයිමර',\n",
              " 'ජනමාධ්\\u200dයවේද, සාහිත්\\u200d කලා සංගීත ක්ෂේත්\\u200dරය කුසලත',\n",
              " 'ඉන්දියා',\n",
              " 'කොළොම්බි විශ්වවිද්\\u200dයාල',\n",
              " 'චීන',\n",
              " 'ඇමරිකා',\n",
              " '103',\n",
              " 'පට්ටිපොළ',\n",
              " 'රතු',\n",
              " 'ඉත්තෑ මස් රතු මස් ගණය අ මස් වර්ග',\n",
              " 'නැත . කුකුල මස් සුද මස් ගණය අ වේ',\n",
              " 'විලිය ගයිගර',\n",
              " 'රුපියල 20',\n",
              " 'උතුර කොරියා',\n",
              " 'ආවේණික ලක්ෂණ යනු පරම්පරා පරම්පරාව සම්ප්\\u200dරේෂණ ලක්ෂණ.',\n",
              " 'ආවේණික ලක්ෂණ ඉදිරි පරම්පරාව සම්ප්\\u200dරේෂණ වීම ආවේණ හදුන්ව ලක්ෂණ සම්ප්\\u200dරේෂණ ව ක්\\u200dරියාවල ප්\\u200dරවේණ වේ',\n",
              " 'ප්\\u200dරතිවිරුද්ධ ලක්ෂණ යුගල එක් ලක්ෂණය බැග පමණ ප්\\u200dරවේණි ගතව ආකාර.',\n",
              " 'කිසිය ලක්ෂණය වූ ජාන දෙක සමා ජීවි ලක්ෂණය සමයුග් වේ . නැතහ ජීවි සමයුග් ජාන සහිත යැ කිය ලැබ',\n",
              " 'කිසිය ලක්ෂණය වූ ජාන දෙක අසමා ජීවි ලක්ෂණය විෂමයුග් වේ . නැතහ ජීවි විෂමයුග් ජාන සහිත යැ කිය ලැබ',\n",
              " 'ලිංගික ප්\\u200dරජනන ජනකය නිපදව ශුක්\\u200dරාණ, ඩිම්බ, පරාග ආද ජන්මාණ වේ',\n",
              " 'එකම වර්ණ්දේහය ජාන දෙක හෝ ඊට ගනණ ස්වාධීන වෙන්ව නොහැ ආකාරය ඒකාබද්ධ පවති තත්ව ජනා ප්\\u200dරතිබද්ධ.',\n",
              " 'ස ස්වාභාවික වර්ණ වීම බලපා වර්ණක ව මෙලනීන්\\u200d . වර්ණක නිපදවීම මූලික දෛහික වර්ණ්දේහ පිහිටි ජාන ඇතිව විකෘතිය ඇලි වේ.',\n",
              " 'සත හෝ ශාක හඳු ගැනී අධ්\\u200dයන කිර පහස අන ජීවී වෙන්කර හඳු ගැනී.',\n",
              " 'ච',\n",
              " 'තාඩ',\n",
              " 'ඉතාලි',\n",
              " 'තිත්ත රස',\n",
              " 'හම්බන්තො',\n",
              " 'එංගලන්ත',\n",
              " 'කලම්බ රේඩි',\n",
              " 'ශ්\\u200dරීම අයි ජෙනිස',\n",
              " 'චීන',\n",
              " 'මැදග',\n",
              " 'ඔමර බයියා',\n",
              " 'ආසියා',\n",
              " 'එක් ජීව පරම්පරා ජීව පරම්පරාව ලබා ගැන ජීව ක්\\u200dරියාවල යි.',\n",
              " 'මව් ජීවි වර්ධක දේහ කොටස ජීවී බි වීම',\n",
              " 'ශාම අත්ත මව් ශාක තිබියදී පළම මුල අද්ද් දෙවන මව් ශාක  කර සිටුවීම',\n",
              " 'කෘති රෝපණ මාධ්\\u200dයකද අලු තත්ත් යටත ශාකය වේග වර්ධනය සහිත කොටස සෛල සමූහය විද්\\u200dයාගාර පරිසර වගාකර ශාක සමූහය ලබා ගැනීම',\n",
              " 'ශාක පුෂ්ප ජන්මා එන ඩිම්බ පරාග නිප වී ඒවා සංසේජන ව ශාක බි වීම',\n",
              " 'පුෂ්ප වේ.',\n",
              " 'ශාක පුෂ්ප ජායාංගය පූමාංගය ඇත . ද්ව ලිංගික වේ.',\n",
              " 'පුෂ්ප පරිණත පරාගධානි නිකුත්ව පරාග කුම හෝ ක්\\u200dරම ගම කර පුෂ්ප කලංක පතිත වීම',\n",
              " 'සංසේචන තොර ඵල හට ගැන ක්\\u200dරියාවලි එලෙස ඵල හට ගැනීම මිනිස කෘති වර්ධක ද්\\u200dරව්\\u200d භාවිත කර එමග ඇතිව ඵල බීජ නැත.',\n",
              " 'ඵල ප්\\u200dරබ පිපිරීම බීජ ඈතට ව්\\u200dයාප්ත වීම.',\n",
              " 'බීජ ජීව්\\u200dයතාව ජලය වාත උෂ්ණත්ව',\n",
              " 'ප්\\u200dරරෝහණ අත්\\u200dයවශ්\\u200dය සාධක පැවතුණ බීජ ප්\\u200dරරෝහණ නොව තත්ව බීජ සුප්තතා හැඳින්',\n",
              " 'ස්ත්\\u200dර ප්\\u200dරජනක සෛල ඩිම්බ වර්ධන කිරීම., ඊස්ට්\\u200dරජ ප්\\u200dරොජෙස්ටරෝ හෝමෝ නිප වීම',\n",
              " 'වැඩිවිය පත් ස්ත්\\u200dරී ප්\\u200dරජනක පද්ධත ආශ්\\u200dරිත සිදුව චක්\\u200dරාණුකූ ක්\\u200dරියාවලි . එක් ආර්ත චක්\\u200dරය සම්පූර්ණ වීම දින 28 ගත වේ',\n",
              " 'ජීවී පැවැත් වූ අන්තර ක්\\u200dරි සිදුව භෞතික ජෛව සංවරණ.',\n",
              " 'ජීවී ඔව වෙසෙ භෞතික පරිසර තුලාත් සම්බන්ධතාව ක්\\u200dරියාත් වේ හිතකර සම්බන්ධතා පාරිසරික සමතුලිතතාව',\n",
              " 'මිහිතල සියලු පරිසර පද්ධතී එකත ජෛව ගෝල වේ . එන පෘතුව ජීවී ව්\\u200dයාප්ත පවති කලාප',\n",
              " 'නිශ්චිත කාලසීමාවකද කිසිය භූගෝල ප්\\u200dරදේශය ජී එකම විශේෂයක අ ජීවී සමූහ',\n",
              " 'කිසිය ප්\\u200dරදේශය ජී එකිනෙ අන්තර ක්\\u200dරි දක්ව විවිධ විශේෂවල අ ගහන වේ',\n",
              " 'කිසිය ප්\\u200dරදේශ ජීවත්ව සියලු ජීව ප්\\u200dරජාව ඒවා අන්තර ක්\\u200dරි දක්ව භෞතික පරිසරය එක් ගත් කළ පරිසර පද්ධතිය වෙ',\n",
              " 'ගහන ඝනත්ව යනු ඒකක පරිමා පසු වූ ද්\\u200dරව්\\u200dය ස්කන්ධ . ගහන ඝනත්ව (density) ගණන කිරී, ද්\\u200dරව්\\u200dය ස්කන්ධ (mass) ද්\\u200dරව්\\u200dය පරිමා (volume) බෙද ලැබ.',\n",
              " 'කාල ගහණ ජීවී සංඛ්\\u200dයා වෙනස්වී ප්\\u200dරස්ථාර ගත කිර ගහන වර්ධ චක්\\u200dර ලැබ',\n",
              " 'සූර්ය',\n",
              " 'පෝෂණ ජීවී පවති අන්\\u200dයෝන්\\u200d සම්බන්ධත ආහාර ජාලය වේ',\n",
              " 'නිෂ්පාදක ආරම්භ වී පිළිවෙල ප්\\u200dරාථමික යැපෙන් ද්විතීක යැපෙන් ආදී ජීවී ශ්\\u200dරේණිය හරහ ආහාර ශක්ත ගලා අනුපිළිවෙල',\n",
              " 'සෑම ජීව ජීවියකු ඔව පෝෂණ ලබා ගන් ආකාර යම් නිශ්චිත පෝෂ මට්ටමක අ අයත් එය පෝෂ මට්ට වේ',\n",
              " 'තමා අවශ්\\u200d ආහාර තමා නිපද ගැන හැකියා නැ වෙන ජීවී නිපදව ආහාර යැපෙ සත මීට අ වේ',\n",
              " 'මළ ජීවිතේහ සංකීර්ණ කාබනික සංයෝග සරල සංයෝග බිඳ හෙළ ශක්ත ලබාගන් ජීවී බැක්ටීරි දිලීර හැඳින්',\n",
              " 'මොව ශාක භක්ෂකය නිෂ්පාදකය යැප',\n",
              " 'මොව ශාක භක්ෂකය හෝ සර්වභක්ෂකය ප්\\u200dරාථමික යැපෙන්න ආහාරය ගනී',\n",
              " 'දේහ අන්තර්ගත ශක්ත ආහාරදා තුළ ඉදිරිය ගලා ආකාර පෙන්ව සටහන',\n",
              " 'ආහාර දාම සිටි ජීවී දේහ ස්කන්ධ සල සකස කර ලබන පිරමීඩ',\n",
              " 'පෝෂ මට්ට පෝෂ මට්ටම ශක්ත ගලා යාමේද ශක්ත අපත යාම',\n",
              " 'ආහාර දාම ශක් ගලායාමේද කිසිය පෝෂ මට්ටමක ලැබෙ ශක්ති 10% ඉදිරි පෝෂ මට්ටම ගලා 90% පරිසරය හා වීම සිද',\n",
              " 'ස්වාභාවික පරිසර පීඩාකාර වෙනස්ක කරන දූෂක ද්\\u200dරව්\\u200d පරිසරය එකත කිරීම',\n",
              " 'හරිතාගාර වාය වැඩිව . පෘතුව වායුගෝල උෂ්ණත්ව ඉහළ යාම',\n",
              " 'අධික පොස ඉන්ධ දහන co2 නිදහස වීම, ගල් අඟුර පෙට්\\u200dරෝලිය ඉන්ධ දහන ගිනිකඳ පිපිරී කර co2 වලට අමතර sco2 නිදහස්වී',\n",
              " 'සාපේක්ෂ ඉහළ ඝනත්වය හෝ ඉහළ සාපේක්ෂ පරමාණුක ස්කන්ධය සහිත ලෝහ',\n",
              " 'ගල් අඟුර ඉන්ධනය භාවිත කිරී, පෙට්\\u200dරෝලිය ඉන්ධ දහන, වල්කනයිස කරන ලද රබර නිෂ්පාද දහන',\n",
              " 'වනාන්තර විනාශ වීම, මත්ස්\\u200d ප්\\u200dරජා වඳවී, නටබ විනාශවී, පාෂාණ දියවී',\n",
              " 'පුද්ගලය නිෂ්පාදනය ක්\\u200dරියාව හෝ ආයතනය හේත කොට ගෙන නිශ්චිත කාල පරිච්ඡේදයකද විමෝචන මුළ co2 වාය ප්\\u200dරමාණ',\n",
              " 'කිසිය පුද්ගල හෝ කණ්ඩායම භාණ්ඩ සේ නිෂ්පාදන හෝ සැපයීමේද පාරිභෝජන කරන මිරිද ජලය ප්\\u200dරමාණ',\n",
              " 'කිසිය ආහාර ඒකක ස්කන්ධය එය නිපදව ස්ථාන පාරිභෝජන කර ලබන ස්ථාන ගෙ දුර',\n",
              " 'සම්ප සංරක්ෂණ, වියද අවම කර ගැනී අරම ඇති පාරිභෝගිකයා ඔව අවශ්\\u200dයත තිරසාර ශක්ත භාවිතය අවස්ථා සලස ශක් නිෂ්පාදන ශක් පාරිභෝජන සැලස කිරී මෙහෙයවී',\n",
              " 'බලශක් සැපයීම ඉල්ලු වැඩිවී දින දින මිළ ඉහළ යාම බලශක්ත දුර වීම',\n",
              " 'විවිධ ආයත ගොස ශක් පරිභෝජන විගණනය සිදුකර නිර්දේශ උපදෙස ඉදිරිප කර පාල අධිකාර දැනු කිරීම',\n",
              " 'ශක් පරිභෝජන කළමනාකරණ කිරී තුළ කිසිය සේවාව සැපයී අඩු ශක් ප්\\u200dරමාණය භාවිත කිරීම',\n",
              " 'පුනර්ජනන ශක් තිරසාර ශක්තී සැල',\n",
              " 'ස්ථිර තීරණය නැ',\n",
              " 'මස මැරී',\n",
              " 'ස්කන්ධ සහිත පරිමා සහිත අවකාශ යම්කිසි ඉඩ ගන් සුළ සියල දේ පදාර්ථ වේ',\n",
              " 'ස්කන්ධ රහිත පරිමාව නැ දෑ ශක්තී වේ',\n",
              " 'එක් සංඝටකය පමණ අඩංග පදාර්ථ',\n",
              " 'තවදුර වෙනස ගුණ ද්\\u200dරව්\\u200d බෙද  කර නොහැ මූලික ද්\\u200dරව්\\u200d වේ',\n",
              " 'මූලද්\\u200dරව්\\u200d දෙක හෝ කිහිපය නිශ්චිත සරල අනුපාතය සම්බන්ධ ව සෑදෙ ද්\\u200dරව්\\u200dය',\n",
              " 'මිශ්\\u200dරණ පුරා එකම සංයුත සහිත මිශ්\\u200dරණ සමජාත මිශ්\\u200dරණ',\n",
              " 'පදාර්ථ තැනීම දා වූ කුඩා අංශ පරමාණ වේ',\n",
              " 'පරමාණ එය සෑදීම දා ඊ කුඩ අංශ උප පරමාණුක අංශ වේ',\n",
              " 'න්\\u200dයෂ්ට වටා නිශ්චිත පත කක්ෂ ශක් මට්ට හැඳින්',\n",
              " 'කිසිය මූලද්\\u200dරව්\\u200dය ප්\\u200dරෝටෝ සංඛ්\\u200dයාවේ නියුට්\\u200dරෝ සංඛ්\\u200dයාවේ එකත ස්කන්ධ ක්\\u200dරමාංක වේ',\n",
              " 'මූලද්\\u200dරව්\\u200dය කවච වලට ඉලෙක්ට්\\u200dරෝ පිරෙ කිසිය රටාවක අනුව මූලද්\\u200dරව්\\u200d පරමාණුවක ඉලෙක්ට්\\u200dරෝ පිරෙ රටා එහි ඉලෙක්ට්\\u200dරෝ වින්\\u200dයාස වේ',\n",
              " 'පරමාණුක ක්\\u200dරමාංක ආරෝහණ මූලද්\\u200dරව්\\u200d සකස කළ කිසිය මූලද්\\u200dරව්\\u200d පරාසයක පස සමා ගුණ සහිත මූලද්\\u200dරව්\\u200d යළි හමුව බ',\n",
              " 'වාය අවස්ථ මූලද්\\u200dරව්\\u200d පරමාණු ඉලෙක්ට්\\u200dරෝනය ඉ ඉවත්කර වායුම ඒක අයනය සෑදීම සැපය යුත අවම ශක්ත එහි ප්\\u200dරථ අයනීකරණ ශක්ත වෙ',\n",
              " 'විද්\\u200dයු ඍණතාව යනු මූලද්\\u200dරව්\\u200d පරමාණුව මූලද්\\u200dරව්\\u200d පරමාණුව සහසංයුජ බන්ධන බැඳ බන්ධන ඉලෙක්ට්\\u200dරෝ තමා ඇද ගැන හැකියා',\n",
              " 'වායුගෝල නිදහස වායුව පවත, වාත පරිමාණ 78.1% ඇත, වර්ණය නැත, ගන්ධය නැත, දහන අපෝෂක, වාතය මද සැහැල්ල',\n",
              " 'සංයෝග නොසාද ඉලෙක්ට්\\u200dරෝ හවුල තබා ගනි එකට සිටි පරමාණ පොකුර ඛණ්ඩක වේ . ඛණ්ඩක වලට පොද අයනය සංයුජතාවය ඇත',\n",
              " 'රතු රුධිරාණ, සුද රුධිරාණ, රුධිර පට්ටි',\n",
              " 'දේහ පිටත හෝ ඇතුළත දැනෙ හෝ නොදැනෙ චලනය සිද එය සිදුකර පටක වේ',\n",
              " 'මිහිතල කොළ පැහැ දිස්ව සියල ශාක හරිත ශාක වේ',\n",
              " 'nan',\n",
              " 'හරිත ශාක පස ජලය වායුගෝල co2 සූර්ය හිර එළිය ලබාගෙ හරිත ලව හරිතප්\\u200dර ආනුසාර තමා අවශ්\\u200d ආහාර තමා නිපදව ක්\\u200dරියාවලි',\n",
              " 'මාධ්\\u200dයය දි හෝ අවකාශ ගම කරන කැලඹීම තරංගය හඳුන්ව ලැබ',\n",
              " 'ප්\\u200dරචාරණ වීම මාධ්\\u200dයය අවශ්\\u200d තරංග යාන්ත්\\u200dරික තරංග හැඳින්',\n",
              " 'එකිනෙක ලම්භක තල දෙක ඔස්ස හටගන් විද්\\u200dයු චුම්භක ක්ෂේත්\\u200dර දෝලන හටගන් තල දෙකට ලම්භක දිශාව ඔස්ස ගම ගන් තරංග වෙ',\n",
              " 'එක් එක් සංඛ්\\u200dයාත පරාස වලද විද්\\u200dයු චුම්භක තරංග වල ගුණ විශා වෙනස වෙ . සංඛ්\\u200dයාත ආරෝහණ පිළිවෙළ විද්\\u200dයු චුම්භක තරංග පෙළගැස්ව ලැබෙ සටහ යි',\n",
              " 'තරංග ගම කරන දිශාව ලම්භක අංශ ඉහළ පහළ කම්පන වෙ ඉදිරිය ගම කරන තරංග තීර්ථ තරංග වෙ',\n",
              " 'තරංග ගම දිශාවට අංශ ඉදිරිය පසුපස කම්පන වෙ ගම කරන තරංග අන්වායා තරංග හැඳින්',\n",
              " 'තරංග චලිතය සහභාගි අංශ මධ්\\u200d පිහිට සිදුකර උපරි විස්ථාපන තරංග විස්තාර වෙ',\n",
              " 'තරංග චලිතය සහභාගි එක් අංශු චලිත ස්වභාවයෙන් පවති ආසන්නත අන අංශුව දුර',\n",
              " 'අනුයාත ශීර්ෂ දෙක හෝ නිම් දෙක දුර',\n",
              " 'සම්පීඩ දෙක හෝ විරලක දෙක දුර',\n",
              " 'එක් අංශුව සම්පූර්ණ දෝලනය සිදුකිරී ගතව කාල තරංගය එහි තරංග ආයාමය සම්මා දුර ගම කිරී ගතව කාල ලෙස හඳුන්',\n",
              " 'තත්පරයකද සිදුව කම්ප වාර ගණන සංඛ්\\u200dයාත වේ',\n",
              " '20hz - 20000hz',\n",
              " 'ස්වරතන්ත්\\u200dර කම්පන කිර මිනිස හඬ ඇති',\n",
              " 'කාන්තා ස්වරතන්ත්\\u200dර කෙටි සිහ සංඛ්\\u200dයාත හඬ තිය වේ . පිරිමි සොරතන්ත්\\u200dර දිග මහත වේ සංඛ්\\u200dයාත අඩ',\n",
              " 'තාරතාව යනු ශබ්දය හෝ සංගීත නාදය එක් ශබ්දය හෝ නාදය සම්බන්ධත ගැසීමේද ඇතිව ශබ් පසුර (pitch) විශේෂාංගය මැනීම . තාරතාව පසුර (pitch) වෙනස, එය දත්ත කාල (frequency) තීරණ කෙර.',\n",
              " 'මිනිස ශ්\\u200dරව්\\u200d පරාස ඉක්ම තරංග',\n",
              " 'කම්පන ව හඬ උත්පාදන කරන වස්තූ වේ',\n",
              " 'වස්තුවක ශක්ති පහර දෙන එහි විස්තාර වී හඬේ සැර වැඩි',\n",
              " 'ධ් ප්\\u200dරභව නිකුත්ව තරංග හැඩ වෙනස්ව ධ් තරංග',\n",
              " 'බාධකය ඉදිරි කළ හඬ බාධක නැවත වෙන හඬ ඇසීම',\n",
              " 'ආහාර වල අඩංග සංකීර්ණ සංයෝග අවශෝෂණ කළ හැ සරල කාබනික සංයෝග පත්වීම',\n",
              " 'ආහාර අන්නශ්\\u200dරෝත ආමාශය ගම කිරී',\n",
              " '1 . දාන පාරමිතා 2 . ශීල පාරමිතා 3 . නෙක්ඛම් පාරමිතා 4 . ප්\\u200dරඥ පාරමිතා 5 . විර පාරමිතා 6 . ක්ෂාන් පාරමිතා 7 . සච්ච පාරමිතා 8 . අධිෂ්ඨා පාරමිතා 9 . මෙත්ත පාරමිතා 10 . උපේක්ෂ පාරමිතා',\n",
              " '1 . දුක්ඛ සත්\\u200dය 2 . දුක්ඛ සමුද සත්\\u200dය 3 . දුක්ඛ නිරෝධ සත්\\u200dය 4 . දුක්ඛ නිරෝධ ගාමින පටිපද සත්\\u200dය',\n",
              " 'කාශ්\\u200dයප රහත වහන්ස',\n",
              " 'අජාසත්ත රජතුම',\n",
              " 'රජගහනුවර වේභාර පර්වත පාමු සප්තපර්ණ ගුහ ද්වාර අබියස',\n",
              " 'මාස තුනක පසු',\n",
              " 'පන්සී',\n",
              " 'ථූපාරාම',\n",
              " 'nan',\n",
              " 'බුදුරජාණ වහන්සේ දක අකු ධාත',\n",
              " 'ඝණ්ඨාකාර, ඝටාකාර බුම්බුලාකාර, ධාන්\\u200dයාකාර පද්මාකාර ආමලකාකාර',\n",
              " 'ඝණ්ඨාකාර',\n",
              " 'ධාන්\\u200dයාකාර',\n",
              " 'කනිෂ්ක රජතුම',\n",
              " 'ජීව ක්\\u200dරි අවශ්\\u200d ශක්ත නිපද ගැනීම සජීව සෛල තුළද සරල ආහාර ඔක්සිකරණ කිර ක්\\u200dරියාවලි',\n",
              " 'වෘක්කාන',\n",
              " 'බාහිර අභ්\\u200dයන්තර පරිසර පැමිණෙ උත්තේජ වලට ප්\\u200dරතිචාර දැක්වීම හැකියා',\n",
              " 'අභ්\\u200dයන්තර බාහිර පරිසර සිදුව වෙනස ව වලට අනුකූල දේහ ක්\\u200dරියාකාරීත්ව හැඩගැස ක්\\u200dරියාවලි',\n",
              " 'සංවේද ඉන්ද්\\u200dරියන් ගෝචර පරිසර සිදුව වෙනස වීම',\n",
              " 'උත්තේජය දක්ව ප්\\u200dරතික්\\u200dරියා',\n",
              " 'උත්තේජය ඇතිව ක්ෂණික අනිමිජානුගත ප්\\u200dරතිචාරය',\n",
              " 'ජල ද්\\u200dරාවණයකද පූර්ණ අයනීකරණ භෂ්ම',\n",
              " 'ජල ද්\\u200dරාවණ භාගික අයනීකරණ භෂ්ම',\n",
              " 'කෙල්ව',\n",
              " 'ආහාර අඩංග සංකීර්ණ කාබනික සංයෝග අවශෝෂණ කළ හැ සරල කාබනික සංයෝග පත්කර පද්ධති',\n",
              " '1.ආහාර ජීර්ණ 2.ජීර්ණ ඵල අවශෝෂණ',\n",
              " 'ක්\\u200dරමාඛුංචන',\n",
              " 'ඇමයිලේස ටයලී',\n",
              " 'ආහාර ජීර්ණ ජෛව රසායනික ප්\\u200dරතික්\\u200dරියා උත්පේරණ කිරීම දා රසායනික ද්\\u200dරව්\\u200d වේ . මේ ඊටම විශේෂිත ආම්ලික භාෂ්මික හෝ උදාසී මාධ්\\u200dයයකද ක්\\u200dරි කර',\n",
              " 'මල තාවකාලික ගබඩ කර තබාගෙ ගුද පිටත යො කෙර',\n",
              " 'සරල විසරණ',\n",
              " 'සෛල තුළද මයිටොකොන්ඩ්\\u200dරියා ඔක්සිජ ලබාගෙ ශක්ත නිෂ්පාදන කර කාබන්ඩයොක්සයිඩ පිට කිරීම',\n",
              " 'සෛල තුළද ඔක්සිජ වාය සිදුව ශ්වසන.',\n",
              " 'ඔක්සිජ නොමැතිව ජීවීන් ශ්වසන සිදුකළ හැ ජීවී ඔක්සියජ වාය රහිත සිදුකර ශ්වසන නිර්වාය ශ්වසන වේ',\n",
              " 'ශක්ති කොටස තාප මුද හැරෙ ඉතිරි කොටස රසායනික ශක්ත ඇඩිනොසි ට්\\u200dරයිපොස්ෆේට නමැ අධි ශක් සංයෝග තැන්ප වේ',\n",
              " 'වස්තු අවස්ථිත වෙනස කරන සාධක බල',\n",
              " 'කිසිය වස්තුව නිශ්චලතාව පවත හෝ ඒකාකාර ප්\\u200dරවේග ගම කර නිශ්චලතාව හෝ චලිත ස්වභාව වෙනස්වී හෝ බිඳ වැටී බාහිර යොද බල',\n",
              " 'නිව්ට',\n",
              " 'බලය දිශාව විශාලත්වය බලය දෛශික රාශි',\n",
              " 'සෑම ක්\\u200dරියාවකට සමා වූ ප්\\u200dරතිවිරුද්ධ වූ ක්\\u200dරියාව ඇත',\n",
              " 'ක්\\u200dරියාව යනු යම් වස්තුව වස්තුව යෙදෙ බල . එවි ප්\\u200dරතික්\\u200dරියා ව දෙව වස්ත පළ වස්ත යෙදෙ බල',\n",
              " 'චලන වස්තු ගම්\\u200dයතාව යනු වස්ත චලිත නැවැත්වීම කොතර අපහසු ය මිනුම',\n",
              " 'කිසිය ද්\\u200dරව්\\u200dය වස්තු අඩංග පදාර්ථ ප්\\u200dරමාණ ස්කන්ධ වේ',\n",
              " 'පෘථිව ගුරුත් බල වස්ත පහළ ඇද ගනී එය බර වේ',\n",
              " 'ගුරුත්වාකර්ෂණ බලය හට ගන් ත්වරණ හඳුන්ව ගුරුත්ත ත්වරණ ලෙස',\n",
              " 'එකිනෙක ස්පර්ශ වී වස්ත දෙක සාපේක්ෂ විස්ථාපනය සිදුව පෙළඹුම වුවහ පෙළඹු විස්තාපන වැළැක්වීම වස්ත දෙ පෘෂ්ඨ ක්\\u200dරියාත් බල ඝර්ෂණ බල',\n",
              " 'චලිත ඇරඹීම පෙර ක්\\u200dරි කරන ඝර්ෂණ යි',\n",
              " 'කිසිය වස්තුව ස්පර්ශන මැඩ පවත්ව චලන ආරම්භ කරන මොහොත පවති උපරි ඝර්ෂණ බලය සීමාකාර ඝර්ෂණ බලය වේ',\n",
              " 'වස්ත චලන ව ඇරඹ පවත් ඝර්ෂණ බලය යි',\n",
              " 'බල එකක ගණන යෙදෙ බල සියල්ල ඇතිව ප්\\u200dරතිඵල කරන තනි බලය බලය සම්ප්\\u200dරයුක්ත වේ',\n",
              " 'ආලෝක කිරණය පුෂ්ඨය වැද ආපස හැර ආලෝක කිරණ පැමිණි මාධ්\\u200dයයේ ගම කිරී යි',\n",
              " 'පතන කිරණ පතන ලක්ෂ ඇඳි අභිලම්භ පරාවර්ත කිරණ එකම තල පිහිට, පතන කෝණ අගය සෑම විට පරාවර්ත කෝණ අගය සමා වෙ',\n",
              " 'තිරයක ගත නොහැ ප්\\u200dරතිබිම්භ අතාත්වික ප්\\u200dරතිබිම්භ වේ . තල උත්ත දර්පණ සෑම විට අතාත්වික ප්\\u200dරතිබිම්බ සෑද',\n",
              " 'තල උත්ත අවත දර්පණ  සෑදෙ ප්\\u200dරතිබිම්භ වල පැ මාරුව පෙනීම',\n",
              " 'පරාවර්තක පෘෂ්ඨ වක්\\u200dර පිහිටි දර්පණ වේ',\n",
              " 'අවතල දර්පණ ප්\\u200dරධා අක්ෂය වැටෙ සමාන්තර ආලෝක කිරණය පරාවර්තන වී නාභ හරහ ගම කර',\n",
              " 'ආලෝක කිරණ එක් එක් පාරදෘශ්\\u200d මාධ්\\u200dය ගම කරන ප්\\u200dරවේග වෙනස්වීම',\n",
              " 'ආලෝක කිරණය ගහන මාධ්\\u200dය විර මාධ්\\u200dයයක හෝ විර මාධ්\\u200dය ගහන මාධ්\\u200dයයක වීමේද මාධ්\\u200d දෙක වෙන්ව පොද පෘෂ්ඨ මතද ආලෝකකිරණ සිදුව හැරීම',\n",
              " 'උත්ත දර්පණය ඉදිරි වස්ත තැබ සෑම විට කුඩ උඩුකුර අතාත්වික ප්\\u200dරතිබිම්බය දර්පණ පිටුපස සෑද',\n",
              " 'ගහන මාධ්\\u200dය විර මාධ්\\u200dයයක ආලෝක කිරණ ඇතුල්වීමේද වර්ත කිරණ අභිලම්භ ඉවත ගම කර .වර්ත කෝණ අගය අංශක අනූව අවස්ථ පතන කෝණ අගය අවදිකෝණ වේ',\n",
              " 'පතන කෝණ අගය අවදිකෝණ ඉක්ම ආලෝක කිරණ පූර්ණ අභ්\\u200dයන්තර පරාවර්තනය ලක්',\n",
              " 'පාර දුෂ්\\u200d ද්\\u200dරව්\\u200dය සෑද වක්\\u200dර පෘෂ්ඨ සහිත ප්\\u200dරකාශ උපකරණ කාච හැඳින්',\n",
              " 'දෙපස ඝණක අඩු මධ්\\u200dය ඝණක වක්\\u200dර පෘෂ්ඨ සහිත ප්\\u200dරකාශ උපකරණ උත්ත කාච හැඳින්',\n",
              " 'දෙපස ඝණක මධ්\\u200dය ඝනක අඩු කාච අවත කාච හැඳින්',\n",
              " 'අවත කාචය ඉදිරි තබන වස්තු ප්\\u200dරතිබිම්බ සෑම විට අතාත්වික උඩුකුර කුඩ ප්\\u200dරකාශ කේන්ද්\\u200dර නාභ සෑද',\n",
              " 'අක්ෂ බල ක්\\u200dරි රේඛාව පවති ලම්භක දුර බල විශාලත්ව ගුණිත ලක්ෂ වටා බල ඝූර්ණ වේ',\n",
              " 'වස්තුව යොද බලය වස්ත භ්\\u200dරමණ වීම පෙළඹීම',\n",
              " 'එකිනෙක යම් පරතරය සහිත ක්\\u200dරි රේඛ දි වස්තුව ප්\\u200dරතිවිරුද්ධ දිශාවල ක්\\u200dරි කරන සමා විශාලත්ව යු බල දෙක',\n",
              " 'ඕනෑ වස්තු බර ක්\\u200dරි කරන ලක්ෂ ගුරුත් කේන්ද්\\u200dර වෙ',\n",
              " 'වස්තුව මතට බලය යොද බල උපයෝග ලක්ෂ බලය යෙද දිශාව කිසිය දුර චලිත කළ එය කාර්යය වේ',\n",
              " 'බලය බල උපයෝග ලක්ෂ චලන වූ දුර',\n",
              " 'කාර්යය වැඩ කිරීම හැකියා',\n",
              " 'ශක්ත මැවීම හෝ නැසීම හෝ නොහැ කාර්යය කිරීමේද සිදුව එක් ශක් ආකාරය ශක් ආකාරයක පරිණාම වීම පමණි',\n",
              " 'වස්තුව පිහිට උස ගබඩ වී ශක්ත විභ ශක්ත වේ',\n",
              " 'චලන වස්තු පවති ශක් ආකාර චාලක ශක්ති',\n",
              " '්කන්ධ ප්\\u200dරවේග',\n",
              " 'කාර්යය කිර සීඝ්\\u200dරතාව ක්ෂමතාව වේ',\n",
              " 'වර්ගඵල ඒකකය ඊට ලම්භක ක්\\u200dරි කරන බලය පීඩන වේ',\n",
              " '්\\u200dරවය ඇතිකර පීඩන ද්\\u200dර පීඩන',\n",
              " 'ද්\\u200dර පීඩනය නිශ්චිත දිශාව නොමැත එය සෑම දිශාවකට ක්\\u200dරි කර',\n",
              " 'ඔව් . උස බඳුනක ජලය පුර උස වැඩිව සිදුර කළ ඉහළ ක්\\u200dරම ද්\\u200dර කඳ විඳි දුර අඩුව පෙන',\n",
              " 'වස්තු බර හට ග ගුරුත්වාකර්ෂණ බලය ද්\\u200dර පීඩන කෙර ද්\\u200dර කදේ බර හෝ ගුරුත්වාකර්ෂණ බලය බලපා',\n",
              " 'පීඩන රඳා පවති එක් එක් නලය ද්\\u200dර ප්\\u200dරමාණ හෝ ද්\\u200dර කඳේ හැඩ නොව ද්\\u200dර මට්ට පමණි',\n",
              " 'බල යෙද ද්\\u200dර සම්පීඩනය භාජ නො, ද්\\u200dරව එක් තැනක යොද පීඩන ද්\\u200dරව තැනක සම්ප්\\u200dරේෂණ කළ හැ මෙය පදන කරගෙ යන්ත්\\u200dර වේ',\n",
              " 'ෘථිවිය ඉහළ වාය ස්කන්ධ පෘතුව එහි වස්ත කරන පීඩන වායුගෝල පීඩන වේ',\n",
              " 'වස්තු බරට විරුද්ධ තරලය කරන ප්\\u200dරතික්\\u200dරි බලය උඩුකුර තෙරපු වේ',\n",
              " 'වස්තුව සම්පූර්ණයෙන් හෝ අර්ධ තරලය ගිල වස්ත විස්තාපන කර ලබන තරල බරට සමා උඩුකුර තෙරප බලය තරල වස්ත ඇතිකර',\n",
              " 'ද්\\u200dරව ඝනත්ව මැන ගැනී භාවිත කරන උපකරණ ද්\\u200dර මාන වේ',\n",
              " 'චලන වස්තුව ගෙ ගිය ගම මග දිග දුර වේ',\n",
              " 'චලන වස්තුව නිශ්චිත දිශාවක චලිත වූ සරල රේඛ මාර්ග දිග විස්ථාපන වේ',\n",
              " 'වස්තු මුල පිහිට සිදුව වෙනස චලිත වේ',\n",
              " 'චලන වස්තුව ඒකක කාලයකද ගෙ දුර වේග වේ',\n",
              " 'චලන වස්තුව සෑම මොහොතකදී ඒකාකාර වේග ගම කර එය නියත වේග වේ',\n",
              " 'චලන වස්තුව ගම කළ මුළ දුර ගත වූ මුළ කාල බෙද මධ්\\u200d වේග ලැබෙ',\n",
              " 'සරල රේඛ මාර්ග චලන වස්තුව කාල ඒකකයකද ගෙ විස්ථාපන ප්\\u200dරවේග වේ',\n",
              " 'චලන වස්තුව සෑම කාල ඒකකයකදී නියත වේග ගම කර එය ඒකාකාර ප්\\u200dරවේගය වෙ',\n",
              " 'චලන වස්තු ප්\\u200dරවේග වෙනස ව සීඝ්\\u200dරතාව තරණ වේ',\n",
              " 'යම් පදාර්ථ සංයුත වෙනස වී ද්\\u200dරව්\\u200d සෑද සිදුව ප්\\u200dරතික්\\u200dරි රසායනික ප්\\u200dරතික්\\u200dරි හැඳින්',\n",
              " 'මූලද්\\u200dරවය, යම් සංයෝග පවති මූලද්\\u200dරව්\\u200dයය ඉන් විස්ථාපන කර ඊට හි ස්ථාන අත් කරගෙ වෙන සංයෝගය සෑද ප්\\u200dරතික්\\u200dරි ඒක විස්ථාප ප්\\u200dරතික්\\u200dරිය.',\n",
              " 'ප්\\u200dරතික්\\u200dරි කරන සංයෝග සංයෝග දෙ මූලද්\\u200dරව්\\u200d හෝ ඛණ්ඩක එකිනෙ විස්ථාපන කර සිදුව ප්\\u200dරතික්\\u200dරියාව වේ',\n",
              " 'ප්\\u200dරතික්\\u200dරි සතු මුලද්\\u200dරව්\\u200d පරමාණ සංඛ්\\u200dයා ඵල සතු පරමාණ සංඛ්\\u200dයාව සමා විය යුතු . ප්\\u200dරතික්\\u200dරියක පරමාණ සංඛ්\\u200dයා පළව පරමාණ සංඛ්\\u200dයාව සමා කිරී වේ',\n",
              " 'ලෝහ අඩංග ස්වභාවික පරිසර හමුව සංයෝග ලෝපස.',\n",
              " 'බිසෝකොට',\n",
              " 'මැද කලාප',\n",
              " 'උෂ්ණත්ව',\n",
              " 'පහත රට වියළි කලාප',\n",
              " 'ප්\\u200dරධා ශාක පෝෂක තුන අඩංග පොහොර මිශ්\\u200dරණය වේ',\n",
              " 'දිලීර ආසාදන',\n",
              " 'පසට යෙද සිදුව පෝෂක හා වීම වැළැක්වීම',\n",
              " 'හෙන්රි බෝ ක්\\u200dරම',\n",
              " 'ධාතුසේ රජතුමා',\n",
              " 'කාලගුණ ලෙස',\n",
              " 'නොවැම්බර පෙබරවාරි මාස වලද',\n",
              " 'තම දේවිය පු කුමර ලැබ ඇසීමෙ',\n",
              " 'අංගුලිමා පිරිත',\n",
              " 'ව්\\u200dයාපාද',\n",
              " 'විදර්ශ භාවනා',\n",
              " 'නිර්භීත බ',\n",
              " 'ව්\\u200dයග්ගපජ්ජ සූත්\\u200dර',\n",
              " 'සතර සංග්\\u200dරහ වස්තු',\n",
              " 'අග්ගිවච්චගොත්ත සූත්\\u200dර',\n",
              " 'බරණැස ඉසිපත මිගදායෙහ',\n",
              " 'මහනුවර යුග',\n",
              " 'වාහල්කඩ නමි',\n",
              " 'උපපජ්ජ වේදන කර්ම නමි',\n",
              " 'ත්\\u200dරී්\\u200dලක්ෂණ',\n",
              " 'තණ්හා හේත කොට ගෙන',\n",
              " 'කෙලෙස න හඳුන්',\n",
              " 'පංච නීවරණ',\n",
              " 'හ',\n",
              " 'සහේතුක හේත සහිත අහේතුක නොව පෙන් දෙන ධර්මතාව කර',\n",
              " 'චතුරාර් සත්\\u200dය',\n",
              " 'විපරිණා දුක්ඛ වේ',\n",
              " 'රාජාණ්ඩ ක්\\u200dරම සමූහාණ්ඩ ක්\\u200dරම',\n",
              " 'ගුරුළුගෝම පඬිතුම',\n",
              " 'සද්ධර්මරත්නාවල',\n",
              " 'කවි සිළුමිණ වේ',\n",
              " 'යැප කෘෂිකර්ම ලෙස',\n",
              " 'මහවැලි බහු කාර් සංවර්ධ යෝජ ක්\\u200dරමය',\n",
              " 'අතුර භෝග වගාව ලෙස',\n",
              " 'පසට නයිට්\\u200dරජ ලැබීම',\n",
              " 'කැදලි ක්\\u200dරම',\n",
              " 'iso සහතික',\n",
              " 'ආහාර සුරක්ෂිතතා',\n",
              " 'ඊසා නිරිත දෙස',\n",
              " 'බොරළ ඉතුර වේ',\n",
              " 'වියළි කාල යනුවෙ',\n",
              " 'රතු දුඹුර පස්',\n",
              " 'මහාවංශ',\n",
              " 'මිනිස අශ් හිස',\n",
              " 'ප්\\u200dරාග ඓතිහාසික යුග',\n",
              " 'නකර',\n",
              " 'ගමික',\n",
              " 'එක්තැ සමය',\n",
              " 'රෝමාණුක දේශ',\n",
              " 'දක ඉන්දියා',\n",
              " 'රළපනා',\n",
              " 'ඇළ ඇළ',\n",
              " 'රජු අ ඉඩ අය කළ බදු',\n",
              " 'තලත ලක්ෂ් දේව',\n",
              " 'හයව බුවනෙකබා රජු න',\n",
              " 'නායක්කාර වංශ',\n",
              " 'දන්තුර ස්ථාන',\n",
              " 'රෙසිඩන්ට්',\n",
              " 'සර් පෙඩ්\\u200dරි නෝ ආණ්ඩුකාරවර',\n",
              " 'පහතර වැසි වනාන්තර වියලි කලාප වනාන්තර මුහුදුබඩ කල විල්ල කඳුකර තණබි',\n",
              " 'පි පුතා සහෝදර රජු බිස සොයුරා',\n",
              " 'එහි සඳහ ඇතැ තොරතුර ශිලාලිපි වෙන මූලාශ්\\u200dර තහවුර',\n",
              " 'ප්ලී',\n",
              " 'කිතුල්ග බෙලි ලෙන',\n",
              " 'තිරුකේතීශ්වර කෝව',\n",
              " 'ලෝකඩ ලෝහ',\n",
              " 'කටුපුල්ල පණිවිඩකරු',\n",
              " 'ෆන් එංගල්බ ආණ්ඩුකාරවර',\n",
              " 'ලං සංගම',\n",
              " 'බූන්ද වැල්ලේගංගොඩ ප්\\u200dරදේශ',\n",
              " 'කනපෙඩික න',\n",
              " 'බටහිර ජර්මනියෙ',\n",
              " 'වර්ජීනි',\n",
              " 'ගතිද පරිගණක පාඨමාලාව හදාර තිබීම',\n",
              " 'භාණ්ඩ හුවමාර යුග',\n",
              " 'කළමනාකරු හඳුන්',\n",
              " 'නෛතික පරිසර හඳුන්',\n",
              " 'අභ්\\u200dයන්තර පරිසර හඳුන්',\n",
              " 'රාජ්\\u200d දෙපාර්තමේන්ත',\n",
              " \"ගැන ජ'නල\",\n",
              " 'බැං ප්\\u200dරකාශ න හඳුන්',\n",
              " 'උප ලබ්ධි නොව ච පත් යනු හැඳින්',\n",
              " 'චෙක්පත නිෂ්කාශන වීම යනු හැඳින්වෙ',\n",
              " 'සී ද්\\u200dරාවණයක බෙනඩි ද්\\u200dරාවණ සල්පය දමා එයට තනුක සල්ෆියුරි අම් බිංද කීපය දමා රත් කළ වර්ණ නිල කොළ කහ තැඹ රතු වර්ණ වෙනස වෙ අවසාන ගඩොල රතු අවක්ෂේපය සාද',\n",
              " 'ඉල්මැස්ස පලිබෝධක වේ',\n",
              " 'ශ්\\u200dර විභජන යනු වෙළඳපොළ ක්\\u200dරියාකාරක කාර්ය ගණනාවක  කිරී එක් එක් කාර්ය වෙන පුද්ගල හෝ කණ්ඩායම සිදුකිරීම',\n",
              " 'ආර්ථික පිරිවැය ව්\\u200dයාපාර ක්\\u200dරියා ප්\\u200dරත්\\u200dයක්ෂ ව්\\u200dයංග පිරිවැ දෙක ඇතුළ වේ . සියලු ගිණුම්කරණ වියද ව්\\u200dයාපාර තීරණ ගැන අවස්ථික පිරිවැ ආර්ථික පිරිවැ යටත පැමිණ.',\n",
              " 'ආර්ථික භාණ්ඩ යනු මිනිස අවශ්\\u200dයත තෘප්තිම කිරී පුද්ගල හෝ සමාජ වටිනාක උපරි කරන භාණ්ඩ හෝ සේව හිඟක අවස්ථිතික පිරිවැය පැවතී ආර්ථික භාණ්ඩ වැදග ලක්ෂණ . එය මිනිසුන් ප්\\u200dරයෝජන ප්\\u200dරත්\\u200dයක්ෂ ව්\\u200dයංග වටිනාක ඇත',\n",
              " 'ආර්ථික ලාභ යනු ප්\\u200dරත්\\u200dයක්ෂ පිරිවැ ව්\\u200dයංග පිරිව දෙක ඇතුළ මුළ ආදාය මුළ පිරිවැ වෙනස . ආර්ථික ලාභ ප්\\u200dරත්\\u200dයක්ෂ පිරිවැ පමණ සලක ලබන ගිණුම්කරණ ලාභය අඩු',\n",
              " 'ආර්ථික අතිරික්ත යනු පාරිභෝගික අතිරික්ත නිෂ්පාද අතිරික්ත දෙ එකතු',\n",
              " 'ආර්ථික පද්ධත යනු පාරිභෝගිකය නිෂ්පාදකය රජ විවිධ ආර්ථික නියෝජිතයි සහභාගිත්ව යම් භූගෝල ප්\\u200dරදේශ හෝ රටක නිෂ්පාදන බෙද හැරී සම්ප  කිර ක්\\u200dරම . නිෂ්පාදන කර කුමක් නිෂ්පාදන කර කෙසේ නිෂ්පාදන කළ යුත්ත කාට ය මූලික ආර්ථික ගැටල විසඳ ක්\\u200dරියාවල ආර්ථික පද්ධ නිරත වේ',\n",
              " 'ආර්ථික විද්\\u200dයා යනු හිඟක අධ්\\u200dයයන . එය පුද්ගල තම අසීමිත අවශ්\\u200dයත සපුර ගැනී සීමිත සම්ප භාවිත කරන ආකාර අධ්\\u200dයාන කරන සමාජ විද්\\u200dයා අපූර්ණ තොරතුර ආදාය අවිනිශ්චිත භාව යටත පුද්ගල ගෘහ කුටුම්භ සමාග රටවල තෝරාගැන හැසිරී ආර්ථික විද්\\u200dය විෂ පථය යි',\n",
              " 'පරිමාණානුකූ ඵල විශා සමාග අත්ප කරගන් පිරිවැ වාසි . ආයත පරිමාණ නිමව ඒකක නිෂ්පාදන කරන යෙදව පිරිවැ ඒකකයක පිරිවැ අඩුව නිමැව ඒකක ගණන වැඩි',\n",
              " 'ඵලදාය ඉල්ලු යනු විවිධ මිල ගණ යටත භාණ්ඩ මිලද ගැනීම පාරිභෝගිකයි කැමැත්ත හැකියා තත්ත්ව .ම අදාය ණය ලබා ගැන හැකියා ඵලදාය ඉල්ලු තීරණ කර .කේන්ස් එය සමහාර ඉල්ලු සමහාර සැපයුම සමා ලක්ෂ්\\u200dය වේ',\n",
              " 'කාර්යක්ෂමතා යනු ඉහළ නිමැව ප්\\u200dරමාණ ලබා ගැනී අඩු යෙදව ඒකක භාවිත කරන තත්ත්ව .කාර්යක්ෂමතා ගණන කර ලබ මුළ යෙදවු මුළ නිමැව බෙදීමෙ .සම්ප හිඟ වූ එය වඩා වැදග වේ .සම්ප අපත නොය ප්\\u200dරශස්ත භාවිත කළ කාර්යක්ෂමතා ළඟ',\n",
              " 'නම්\\u200dයතා යනු එක් ආර්ථික විචල්\\u200dයය ආර්ථික විචල්\\u200dයයක ප්\\u200dරතිචාරීතා මිනුම . එය එක් විචල්\\u200dය වෙනසක අන විචල්\\u200dය සංවේදීත තීව්\\u200dරතා පෙන් . නම්\\u200dයතා පූර්ණ නම්\\u200d, නම්\\u200d, පූර්ණ අනම්\\u200d, අනම්\\u200d ඒක පුළුල කාණ්ඩ පහක බෙද හැ',\n",
              " 'ඉල්ල නම්\\u200dයතා ආර්ථික විචල්\\u200dය වෙනස්ව බලපෑ නිෂ්පාදනය ඉල්ල කරන ප්\\u200dරමාණ මනි ලබ . එය භාණ්ඩ මිල සම්බන්ධිත භාණ්ඩ මිල ආදාය විචල්\\u200dය වෙනස ප්\\u200dරතිචාර නිෂ්පාද ප්\\u200dරමාණ වෙනස්ව තීව්\\u200dරතා පෙන්න',\n",
              " 'එංගල වක්\\u200dර මිල කැමැත්ත ස්ථාවර වූ විවිධ ආදාය මට්ට භාණ්ඩ ඉ සිටි ප්\\u200dරමාණ නියෝජන කරන සියලු ලක්ෂ එකතු .ය භාණ්ඩය වියද සමානුපාතික හෝ නිරපේක්ෂ නියම කුටුම්භ ආදාය වෙනස ආකාර මෙමග පෙන්න කර',\n",
              " 'ව්\\u200dයවසායකත්ව යනු නවෝත්පාද නිර්මාණශීලීත්ව ව්\\u200dයාපාරය ආරම්භ කිරී දි කිර ක්\\u200dරියාවලි . ව්\\u200dයාපාර අවදාන භාර ගැනීම කැමැත්ත හැකියා මෙහිද සැලකිලිම ආපස ලැබුම ලාභ උපද . මෙය වෙළෙඳපොළ ආර්ථික ආර්ථික වර්ධන වේග කර',\n",
              " 'සමතුලිත යනු බාහිර බලවේග වලට බලපෑම නැතැ උපකල්පන කර වෙළෙඳපොළ බලවේග ඉල්ලු සැපයී සමතුලිත ආර්ථික තත්ත්ව .මෙ තත්ත්ව ඉල්ලු සැපයු ගැලපෙ වෙළඳපොළ මිල සමතුලිතතාවය ළඟ .එ අවස්ථා අතිරික්ත ඉල්ලුම හෝ අතිරික්ත සැපයීම නො',\n",
              " 'සමතුලිත මිල නිෂ්පාදකයි පාරිභෝගිකයි තීරණ ගැලපෙ මිල මට්ට කි . ඉල්ලු ප්\\u200dරමාණ සැපය ප්\\u200dරමාණය සමා වෙළඳපොළ මිල සමතුලිත මිල වේ . එය වෙළඳපොළ නිෂ්කාශ මිල හැඳින් .චිත්\\u200dරක වීජ වගු ක්\\u200dර භාවිත සමතුලිත මිල ගණන කළ හැක',\n",
              " 'අදි ඉල්ලු යනු ඉල්ල ප්\\u200dරමාණ සැපය ප්\\u200dරමාණ ඉක්ම තත්ත්ව . භාණ්ඩ මිල සමතුලිත මිල අඩු වූ සිද . අදි සැපයු යනු සමතුලිත මිල ඉල්ල ප්\\u200dරමාණය සැපය ප්\\u200dරමාණ ඉක්ම තත්ත්ව . භාණ්ඩ මිල සමතුලිත මිල වූ සිද',\n",
              " 'යම් ආර්ථික තත්ත්වය යටත භාණ්ඩ හෝ සේවා ළඟාවීම බලාපොරොත්ත මිල අපේක්ෂිත මිල හැඳින් .අපේක්ෂිත තෘප්ත යනු භාණ්ඩ හෝ සේව සැබෑ පාරිභෝජනය පෙර පාරිභෝගික උපයෝගීතාව ස්වරූප .ඇතැ භාණ්ඩ මිලද ගැනීමේද පාරිභෝගික අපේක්ෂ කරන තෘප්ත රඳා පවත.',\n",
              " 'ප්\\u200dරත්\\u200dයක්ෂ පිරිවැ යනු නිෂ්පාද සාධක දරණ පිරිවැ එය ව්\\u200dයාපාරය ක්\\u200dරියාත් කිරී සෘජ ගෙවීම වෙ .මෙ වියද උදාහරණ ව වැටුප වැටුප වේත අත්තිකාර පොල, අමුද්\\u200dරව්\\u200d ගබඩ සැපය, මුද්\\u200dරණ ලිපි දවස කුල උයෝගීත යනාදි . ඒවා ස්ථාවර හෝ විචල්\\u200d පිරිවැ විය හැ',\n",
              " 'පළ ගන මිල විශේෂ කරන යනු ව්\\u200dයාපාරය එක් එක් පාරිභෝගික ගෙවීම කැම උපරි මුද අය කරන තත්ත්ව .එ ප්\\u200dරධා පරමාර්ථ ව සමාග ලාභ සිය පාරිභෝගික සියලු පාරිභෝගික අතිරික්ත ලබා ගැනීම',\n",
              " 'ස්ථාවර පිරිවැ යනු නිෂ්පාදන කරන ලද හෝ විකුණ ලද භාණ්ඩ හෝ සේ ප්\\u200dරමාණ වැඩිවීම හෝ අඩුවීම වෙනස නොව පිරිවැ වෙ . නිෂ්පාදනය නොමැ වියද දැරීම සිද',\n",
              " 'කා නිපදවන්නේ ය සම්ප හිඟක සම්ප භාවිත විකල්ප පැවතී හේතු හටගන් මූලික ආර්ථික ගැටල එක .ආර්ථික නිෂ්පාදන කිරීම අපේක්ෂිත භාණ්ඩ හෝ සේවා අවසා පාරිභෝගික කවුරුන් ය තීරණ කිරී මෙය ඇතුළ වෙ',\n",
              " 'නිදහස ව්\\u200dයවස යනු රජ පාලන තොර හෝ රජ සුළ සීමා යටත වෙළඳපොළ මිල, නිෂ්පාද සේ තීරණ කරන ආර්ථික . ආර්ථික නිදහස, ස්වෙච්ඡ හුවමාර, පෞද්ගලික දේපළ ලාභ චේතනා සමහර ලක්\\u200dෂණ.',\n",
              " 'අබාධ ප්\\u200dරවේශ යනු නවකයින් වෙළඳපළ වීම කිසිද බාධාව නොමැ වීම . එය භාණ්ඩ හෝ සේ නිෂ්පාදන කිරී හෝ විකිණී සමාග වලට නිදහස වෙළෙඳපොළ විය හැ කොන්දේසි . පූර්ණ තරගකාර වෙළඳපොළ නිර්බාධ ප්\\u200dරවේශ උදාහරණ',\n",
              " 'නොම භාණ්ඩ යනු අවස්ථික පිරිවැ තොර භාණ්ඩය වෙ .නොම භාණ්ඩ ලක්ෂණ එය පරිසර බහු පැවතී නිෂ්පාදන කිරීම මිනිස උත්සාහ අවශ්\\u200d නොවී, මුදල වටිනාකම හෝ මිල නොමැ වීම, ආර්ථික විද්\\u200dය ධනය සැල නොහැ වීම සැල හැක . හිර එළ වාත ජලය සමහර උදාහරණ වෙ',\n",
              " 'ගිෆ භාණ්ඩ යනු ඉල්ල මිල ප්\\u200dරමාණ ධන සම්බන්ධය පෙන්න කරන භාණ්ඩ ආදාය ඉල්ල ප්\\u200dරමාණ සෘණ සම්බන්ධය පෙන්න කෙර .සියලු ගිෆ භාණ්ඩ බාල භාණ්ඩ සියලු බාල භාණ්ඩ ගිෆ භාණ්ඩ නො . ඒවා සමීප ආදේශක නොමැත',\n",
              " 'සමජාත නිෂ්පාද යනු පාරිභෝගිකය තෘප්තිම කිරීමේද එකම ගුණාංග  සමන්විත භාණ්ඩ සේ වේ . ඒවා එකිනෙක පූර්ණ ආදේශ කල හැ නිෂ්පාදක නිෂ්පාද මිල ගන්න වෙ',\n",
              " 'කුටුම්භ යනු නිවස හෝ එකම වහල යට ක්\\u200dරියාකාරක යෙදෙ පුද්ගල කුඩා සමාජ ඒකක . රටේ ආර්ථික තත්ත්ව කෙර බලපෑ කර ලබන කුටුම්භ ආර්ථික ක්\\u200dරියාකාරක තේර කරන එය රටේ ආර්ථික තත්ත්ව කෙර බලපෑ ඇතිකර',\n",
              " 'ව්\\u200dයංග පිරිවැ යනු ආයෝජ අරමුණ දැනටම වියද කර එය වියද ගිණ සටහ කර නොමැ ඕනෑ වියද .එය සෑම විට කිසි ව්\\u200dයාපෘතිය භාවිත කරන සම්පතක ආවස්ථිතික පිරිවැ පෙන් . ව්\\u200dයංග පිරිවැය සිදුකෙරෙ ආයෝජන ආයෝජක ප්\\u200dරතිලාභ අපේක්ෂ නොකර',\n",
              " 'ආදාය පරිභෝජ වක්\\u200dර පාරිභෝගික ආදාය වැඩිව පාරිභෝගික සමතුලිතතා නියෝජන කරන ලක්ෂ වල පිහිටී අර්ථ දැක්ව හැක . එය සාමාන්\\u200dය ඉහළ බෑව වේ',\n",
              " 'ආදාය ඉල්ල නම්\\u200dයතා යනු පාරිභෝගික ආදාය වෙනස යම් නිෂ්පාදනය ඉල්ල කරන ප්\\u200dරමාණ ප්\\u200dරතිචාර .එය පාරිභෝගික ආදාය ප්\\u200dරතිශත වෙනස ඉල්ල ප්\\u200dරමාණ ප්\\u200dරතිශත වෙනස ලැබ ලැබ',\n",
              " 'ආවස්ථිතික පිරිවැ යන්න අදහස කෙරෙ යම් නිෂ්පාද ආයතනය තම නිෂ්පාදන කරන එහි ආවස්ථිතික පිරිවැය වැඩිවීම . එක නිෂ්පාදන නිෂ්පාදන කළහ අමතර ඒකකය නිෂ්පාදන කිර ආවස්ථිතික පිරිවැය වැඩිවීම',\n",
              " 'උපේක්ෂ වක්\\u200dරය යනු භාණ්ඩ දෙක පරිභෝජන කිරීමේද එකිනෙක සමා උපයෝගීතා ලබා දෙන භාණ්ඩ සංයෝග පෙන්න කරන වක්\\u200dර .එ සෘණ බැව්ම පෙන්වී, මූලාරම්භය උත්ත වීම, එකිනෙක ඡේදන නොවී ඉහළ උපේක්ෂ වක්\\u200dර ඉහළ මට්ට තෘප්තිය පෙන්න කිරී ලක්ෂ කීපය ඇත',\n",
              " 'යම් කාලසීමාව යම් පුද්ගල යම් මිලක මිලද ගැනීම කැම භාණ්ඩ ඒකක ප්\\u200dරමාණ පුද්ග ඉල්ලු හැඳින් .පුද්ගල ඉල්ල කර ලබන භාණ්ඩ ප්\\u200dරමාණ භාණ්ඩයේ මිල, පාරිභෝගික ආදාය, ආදේශක භාණ්ඩ වල මිල රුච අනාගත අපේක්ෂ යනාද රඳා පවත',\n",
              " 'පුද්ග සැපයු ය නිෂ්පාදක යම් කාලසීමාව වෙළඳපොල මිලක සැපයීම කැම සැපය ප්\\u200dරමාණ . විවිධ මිල ගණ යටත විකුණුම්කරු සපය ලබන ප්\\u200dරමාණ එහි සඳහ වේ . සපය ලද ප්\\u200dරමාණ නිෂ්පාදන වෙළෙඳපොළ මිල ධනාත් සම්බන්ධය ඇත',\n",
              " 'බාල භාණ්ඩය ය පාරිභෝගික ආදාය වැඩිව පාරිභෝගික ඉල්ල කර ලබන ප්\\u200dරමාණ අඩුව භාණ්ඩ . බාල භාණ්ඩ ඉල්ල කරන ප්\\u200dරමාණ පාරිභෝගික ආදාය ප්\\u200dරතිලෝම සම්බන්ධය පවත',\n",
              " 'සම පිරිවැ වක්\\u200dර මුදල ප්\\u200dරමාණ භාවිත කළ හැ විවිධ සාධක සංයෝජ නියෝජන කර .නිෂ්පාද සාධක නිෂ්පාද සාධක මිල නිෂ්පාදකයා වියද කිරීම අවශ්\\u200d මුල මුදල වියද පෙන්න කර ලැබෙ',\n",
              " 'සම නිමැව වක්\\u200dර යනු ලබා නිමැව මට්ටම නිපදවීම භෞතික හැකියා යෙදව හැ සියලු සංයෝජන පෙන්න කර ලබන වක්\\u200dර . සම නිමැව වක්\\u200dර ගම කිර නිමැව මට්ට නියත පවති යෙදව අනුපාත අඛණ්ඩ වෙනස වේ',\n",
              " 'නිර්බාධවාද ආර්ථික යනු ඉල්ලු සැපය බලවේග දෙක වෙළඳපොළ සමතුලිතතාව තීරණ කිරීම අදෘශ්\\u200dයමා හස්ත බල ආර්ථික . ව්\\u200dයාපාරික ක්\\u200dරියාකාරක රජ මැදිහත්වීම එය විරුද්ධ විය . න්\\u200dයා 18 සියවස ආරම්භ වූ හොඳ ව්\\u200dයාපාරික තත්ත්ව ආර්ථිකය අඩු රාජ්\\u200d මැදිහත්ව වැදගත්ක අවධාරණ කිරීමෙ',\n",
              " 'ඉල්ල න්\\u200dයා යනු අනෙකු සාධක නොවෙනස් පවති ඉල්ල කරන ප්\\u200dරමාණ යම් භාණ්ඩ මිල පවති ප්\\u200dරතිලෝ සම්බන්ධ',\n",
              " 'සැපය නීත යනු අනෙකු සාධක ස්ථාවර තිබියද භාණ්ඩ මිල සැපය ප්\\u200dරමාණ ධන සම්බන්ධතා යි',\n",
              " 'දිග කාල යනු නිෂ්පාදන පිළි සියලු සාධක වෙනස කාල පරිච්ඡේද වේ.මෙ ආයතන නිෂ්පාදන ශ්\\u200dරම පමණ නොව ප්\\u200dරාග්ධන තාක්ෂණ අනෙකු නිෂ්පාද යෙදව වෙනස කරන කාල දිග කාල හඳුනාගත හැක',\n",
              " 'සුඛෝපභෝග භාණ්ඩ යනු ආදාය වැඩිවී ඉල්ලු ප්\\u200dරතිශත වැඩිව භාණ්ඩ වේ .සුඛෝපභෝග භාණ්ඩ ය ආදාය ඉල්ල නම්\\u200dයතා එකට අගය වේ .ආදාය වැඩිව ආදාය කොටස සුඛෝපභෝග භාණ්ඩ වැය වේ',\n",
              " 'ආර්ථික පිරිවැ යනු අතිර ඒකකය නිෂ්පාදන කිරී හේතු සමස්ත පිරිවැ ඇතිව වෙනස වේ',\n",
              " 'ආන්තික නිෂ්පාද යනු ආයතන අතිර යෙදව ඇතිව අතිර නිමැවු වේ .අන සාධක නොවෙනස් තිබියද ශ්\\u200dරම ඒකක ඉහළ දම, නිෂ්පාදන ඇතිව වෙනස මෙහිද ගණන කෙර',\n",
              " 'ආන්තික ආදේශ අනුපාත යනු උපයෝගීත මට්ටම යටත එක් භාණ්ඩය භාණ්ඩය . පාරිභෝජනය කැමැත්ත වේ',\n",
              " 'ආන්තික තාක්ෂණික ආදේශ අනුපාත යනු සම නිෂ්පාද වක්\\u200dර බැව්ම . කිසිය ස්ථාවර නිමැව ප්\\u200dරමාණය නිපදවීම ආයතනය එක් යෙදවුමක දෙදහම ආදේශ කර අනුපාත වේ',\n",
              " 'ආන්තික උපයෝගීතා යනු එක් භාණ්ඩය පාරිභෝජන ලැබෙ අතිර උපයෝගීතා වේ.',\n",
              " 'වී වගාව සම්බන්ධ වගා ක තුන',\n",
              " 'එළාර රජු',\n",
              " 'කීර් නිශ්ශංක මල් රජතුම',\n",
              " 'බ්\\u200dරාහ්මණ කොට්ඨාසය',\n",
              " 'ජෙරුසල',\n",
              " 'රුසියා',\n",
              " 'ජනාධිප මිහායිල ගෝර්බචෝ',\n",
              " 'ඊ.එච කාර',\n",
              " 'ඉන්දිය ධනය කොල් කා ආපස යෑම',\n",
              " 'ඝූර මුහම්මද',\n",
              " 'නිශ්ශංක අලගක්කෝනාර විසි',\n",
              " 'ස්පාඤ්ඤ වේ',\n",
              " 'අක්බර රජු',\n",
              " 'නාසිවාද වේ',\n",
              " 'ක්\\u200dරිස්ත වර්ෂ 1972 පළ ජනරජ ව්\\u200dයවස්ථා',\n",
              " 'මාඕ- සේතූ විසි',\n",
              " 'ශ්\\u200dරේෂ්ඨාධිකරණ වේ',\n",
              " 'කීර් නිශ්ශංකමල් රජු',\n",
              " 'කෝල්බෘග ආණ්ඩුක්\\u200dර ප්\\u200dරතිසංස්කරණ යටත',\n",
              " 'ඛයිබර දුර්ග මාර්ග වේ',\n",
              " 'අක්බර රජු',\n",
              " 'පොද රාජ්\\u200d මණ්ඩල',\n",
              " 'පණ්ඩුකාභ රාජ්\\u200d සමයේද',\n",
              " 'අශෝක රජතුම',\n",
              " 'මහානාගහු ස්ථාන',\n",
              " 'පාඨලීපුත්\\u200dර නගර',\n",
              " 'ටොකුග ෂොගූ පාල සම',\n",
              " 'ඉදිරි පිම් වැඩසටහන',\n",
              " 'චන්ද්\\u200dරගුප්ත මෞර් රජතුම',\n",
              " 'ලියනාඩ ඩාවින්චි චිත්\\u200dර ශිල්පි',\n",
              " 'චීන වේ',\n",
              " 'කාම්බෝජ වේ',\n",
              " 'යාපන ප්\\u200dරදේශ',\n",
              " 'හින්ද ආගම',\n",
              " 'ආර් චක්\\u200dරවර් රාජ්\\u200d පරපුර හැඳින්වෙ',\n",
              " 'ඉන්දියා වේ',\n",
              " 'සාජහා රජු',\n",
              " 'මුම්ටාස දේව සිහිවී',\n",
              " 'මල්වත ඔය ආශ්\\u200dරිත',\n",
              " 'ගල් ඔය ආශ්\\u200dරිත',\n",
              " 'කලා ඔය ආශ්\\u200dරිත',\n",
              " 'කිරිඳි ඔය ආශ්\\u200dරිත',\n",
              " 'ගෝව',\n",
              " 'බතාව',\n",
              " 'ටිකිරි කුමර',\n",
              " 'ජොරිස ෆන් ස්පිල්බර්ජ පුද්ගල',\n",
              " 'කුසුමාස දේව විවාහ කරගෙ උඩර රාජ්\\u200d අයිත ලබා ගත්ත සෙන්ාර බණ්ඩාර යි.',\n",
              " 'දෙව රාජසිංහ රජතුම',\n",
              " 'කීර් රාජසිංහ රජතුම',\n",
              " 'රට ස්වාධී රාජ්\\u200dයය තිබී බ්\\u200dරිතාන්\\u200dය කටයුතුවල බාධාව වීම පහත රට වූ කැරලිවලද උඩර රජ ඒවා උද දීම බ්\\u200dරිතාන්\\u200dයයන් බාධාව විය කොළඹ ත්\\u200dරිකුණාමල ගොඩබි මාර්ගය තැනී උඩර රජු අවසර නොලැබී',\n",
              " 'අනගාරික ධර්මපාලතුම',\n",
              " 'ආරුමුග නාවලර්තුම',\n",
              " 'ඩොනමෝර ආණ්ඩුක්\\u200dර ප්\\u200dරතිපත්ත',\n",
              " 'ඛයිබර බෝලා ගෝමල',\n",
              " 'ස්ටෙප්ස තණ බි සැල',\n",
              " 'සප්ත සින්ද ප්\\u200dරදේශ',\n",
              " 'ගව වේ',\n",
              " 'වින්ද කඳුවැට',\n",
              " 'මව බැට සාමිවර',\n",
              " 'සුභාෂ චන්ද්\\u200dර බෝස පුද්ගල',\n",
              " 'සුරේන්ද්\\u200dරනා බැනර්ජි මැතිතුම',\n",
              " 'සිම් ස්ථාන',\n",
              " 'ජාතී සංගම',\n",
              " 'ජපන පර්ල වරාය බෝම්බ දැමී',\n",
              " 'මාර්ෂල සැලැස් හඳුන්',\n",
              " 'කුවේණි කුමර',\n",
              " 'පරාක්\\u200dරමබා රජතුම',\n",
              " 'ශ්\\u200dරීම වින්ස්ටන්ට චර්ච්ල',\n",
              " 'නායක්කර රාජ වංශය',\n",
              " 'පිළිමතලව් මහාධිකාර',\n",
              " 'පත්තිරිප වේ',\n",
              " 'ලොරෙන්ස අල්මේද',\n",
              " 'අපොන්ස පෙරෙයිර ලසර්ද',\n",
              " 'කරලියද්ද බණ්ඩාර',\n",
              " 'මිගෙට්ටුවත්ත ගුණානන් හි',\n",
              " 'කර්නල හෙන්රි ස්ටීල ඕල්කට තුම',\n",
              " 'ආරුමුග නාවලර තුම',\n",
              " 'සිද්ධි ලෙබ්බ මහත',\n",
              " 'ඇලෙක්සැන්ඩර වේ',\n",
              " 'ඉන්ද නදී ශිෂ්ටාචාර',\n",
              " 'කාලිංග දේශ',\n",
              " 'අලහාබාද ප්\\u200dරශස්ත',\n",
              " 'ධනය කොල්ලකෑ වේ',\n",
              " 'කුටුබ - උද්දී අයිබේ වේ',\n",
              " 'නොබුනග වේ',\n",
              " 'ඩයිමියෝ න',\n",
              " 'ඩයට න හඳුන්වයි.ජ බස එය කොක්කා වේ',\n",
              " 'ඇල්සාස ලොරේ ප්\\u200dරදේශ',\n",
              " 'ගෙස්ටාප න හැඳින්ව',\n",
              " 'හිරෝහිත වේ',\n",
              " 'රට භාණ්ඩ වර්ග දෙක පමණ නිපදව උපකල්පන කිරී, තාක්ෂණ නොවෙනස් පවති උපකල්පන කිරී රට සතු සම්ප සම්භාර හෝ අඩු උපකල්පන කිරී පූර්ණ සේ නියුක්ත පූර්ණ නිෂ්පාදන අත්කර ගන් උපකල්පන කිරී',\n",
              " '2021 වසර ශ\\u200d්\\u200dර ලංක ආර්ථික වර්ධ වේග 3.66% පැවතී.',\n",
              " 'භාණ්ඩ නිපදව ප\\u200d්\\u200dරමාණ ආයතන මුළ පිරිවැ ඉහළ යයි . එන නිපදව ප\\u200d්\\u200dරමාණ පිරිවැ ඍණ සම්බන්ධය පවත.',\n",
              " 'ආර්ථික කිසිය සල බලන අවස්ථාව තුල සම්ප පුර්ණ උපරි කර්යෂමතාව උපයෝජන කල ලබා ගත හැ උපරි නිමව සංයෝග සම්බන්ධ කර අදි ලබන රේඛා නිෂ්පාද හැකි මය්යි වක්\\u200dර හඳුන්ව ලැබ.',\n",
              " 'ජාත්\\u200dයන්තර වෙළඳා වාසි තුළ නිෂ්පාදන හැකි මායි වක\\u200d්\\u200dර පිටත ලක්ෂ පරිභෝජන කිර හැකියා පැවැතී.',\n",
              " 'සහල පවති සමතුලිත ඉහල ගොස සමතුලිත ප\\u200d්\\u200dරමාණ පහල බැසීම සිද.',\n",
              " 'සමතුලිත මිල පහළ බසි සහනාධාර කොටස නිෂ්පාදකයා හිමි.',\n",
              " 'ඉල්ලූ\\u200d පුර්ණ නම්\\u200d වී සාධක මිල ගණ අඩු අවස්ථාවකද.',\n",
              " 'නී විරෝධ කළු කඩ මිල යටත භාණ්ඩ අලෙවි කිරීම තැ කිරී . පාරිභෝගික නිෂ පාද අතිරික්තය බල්\\u200dපෑ වී සමාජ සුභසාධන පහත වැටී අධි ඉල්ලූ\\u200d වෙළඳපොළ භාණ්ඩ හිඟය වීම.',\n",
              " 'ආයතන සාමාන්\\u200d අයභාර, සාමාන විචල්\\u200d පිරිවැ අඩු බැවි.',\n",
              " 'දේශ වියදම සාපේක්ෂ නිමැවු පහල දළ ආයෝජනය සාපේක්ෂ ඉතුර පහල යනු ලැබ.',\n",
              " 'සාර් ආර්ථික කළමනාකරණ රජය භාවිත කර ගනු ලබන ඉල්ලූ\\u200d කළමනාකරණ ප\\u200d්\\u200dරතිපත්ත රාජ්\\u200d මුල්\\u200d ප\\u200d්\\u200dරතිපත්ත හැඳින්.',\n",
              " 'වටිනාක සන්නිධිය කල්පස වූ ණය ගෙව මාධ්\\u200dය කටයුත කිරී.',\n",
              " 'මිල නොගෙව අය පරිබෝජන බැහැර කළ හැ වීම ධාරිත මට්ට ළගා වනත පරිබෝජන තරගකාර නොවී.',\n",
              " 'ආනයන කරන භාණ්ඩ බදු පැන්ව පසු දේශ වටිනාකම එකත කරන ලද ප\\u200d්\\u200dරතිශත වෙනස වී අනුපාත යි.',\n",
              " 'කිසිය පුද්ගලයෙකු හෝ කුටුම්භයක මූලික අවශ්\\u200dයත සපුර ගැනීම ප\\u200d්\\u200dරමාණ ආදායම නොලැබෙ තත්ත්වය නිරපේක්ෂ දරිද්\\u200dරතාව හදුන්.',\n",
              " 'මූලික උද්ධමන යනු ආහාර බලශක්ති බැහැර කරන ලද භාණ්ඩ සේවා පිරිවැ වෙනස්ක වල මිනුම වේ . අයිතම මිල විශා වෙනස ඒවා බැහැර කර ඇත . සාමාන්\\u200dය, මූලික උද්ධමන මනි ලබ පාරිභෝගික මිල දර්ශක භාවිත කරමි.',\n",
              " 'කුටුම්භ අංශය- කුටුම්භ අංශ යනු භාණ්ඩ සේ පරිභෝජන කරමින්භ හෝ භාණ්ඩ සේ හුවමාර කර ගනි වැටුප පොල ලාභ උපය ආර්ථික ක\\u200d්\\u200dරියාකාරක යෙදෙ පුද්ගල හෝ පුද්ග සමූහ . ව්\\u200dයාපාර අංශය-ව්\\u200dයාපාර අංශ සමන්විත ව ආර්ථික ක\\u200d්\\u200dරියාකාරක සම්බන්ධ වාණිජ සේ නිෂ්පාදන බෙද හැරී මගි . ආර්ථික සැපය අංශ අවශ්\\u200dයතාව සපුරාලී පාරිභෝගිකයින් අවසා භාණ්ඩ සේ සැපයී මෙමග සිද . රාජ්\\u200d අංශය-බද ආදාය එකත කිරී,, රාජ්\\u200d වියද වියද කිරී නී රී වෙන රෙගුලාසි ක\\u200d්\\u200dරියාත් කිරී ආර්ථිකය මැදිහ අංශය රාජ්\\u200d අංශ හඳුනාගත හැ . ආර්ථික ක\\u200d්\\u200dරියාකාරක රජය කරන මැදිහත්වී රට රටට වෙනස විය හැ.',\n",
              " 'කාන්දුවීම්-කාන්දුව යනු ආර්ථික චක\\u200d්\\u200dර ප\\u200d්\\u200dරවාහ මුදල පිටත ගලා යාම . සමාග කුටුම්භ ඔව ආදාය කොටස ඉතිරි කරන එය සිදුව හැ . කාන්දුව ආර්ථික ආදාය චක\\u200d්\\u200dර ප\\u200d්\\u200dරවාහය එක නොව ආදාය කොටස හඳුනාගත හැ . විද විද යනු ආර්ථික චක\\u200d්\\u200dර ප\\u200d්\\u200dරවාහය ආදාය එකත කිරීම . විවිධ මූල්\\u200d ප\\u200d්\\u200dරභව කුටුම්භ හෝ ව්\\u200dයාපාරික අංශ මුදල ණයට ලබා ගත් එය විය හැක . විද ආර්ථික චක\\u200d්\\u200dර ප\\u200d්\\u200dරවාහ කිරීම බලපා ඇත.',\n",
              " 'ගනුදෙ චේතනාව-ගනුදෙ චේතනා යනු මුදල ශේෂ තබා ගැනීම කැමැත්ත . එදිනෙද ගනුදෙ කිරීම අවශ්\\u200d ගනුදෙ මිනිස මුදල ළග තබා ගනී . පුද්ගල ආදාය ගනුදෙ චේතනා ධනාත් සම්බන්ධය ඇත . ආරක්ෂණ චේතනාව-ආරක්ෂණ චේතනා යනු අනාගත පුද්ගල මුහ දෙන අනපේක්ෂිත තත්වයන් මුහ දීම මුදල ශේෂ තබා ගැනීම . ආරක්ෂණ චේතනා පුද්ගල සත තිබ යුත මුදල ප\\u200d්\\u200dරමාණ ධනය, ද්\\u200dරවශීලතාව, අවදාන අභිපේ\\u200d්\\u200dරරණ තීරණ වේ.,',\n",
              " 'පටු මුදල සැපයු: m0 * -පට මුදල සැපයු යනු කාසි මුදල, ඉල්ලූ\\u200d තැන්පත අනෙකු ද්\\u200dරවශී වත්ක මුදල . එය පුළුල මුදල සැපය කොටස හඳු ගත හැ . පටු මුදල සැපයු අඩංග ව ආර්ථික ද්\\u200dරවශී වත්ක  පමණි.',\n",
              " 'අති ප\\u200d්\\u200dරාමාණික ලාභ යනු සමාග මුළ ආදාය මුළ පිරිවැ පරතර මගින් ජනන ධනාත් අතිරික්ත . ව්\\u200dයවසායක ගෙව ලබන ලාභ මුළ පිරිවැ යටත ඇතුළ අතිප\\u200d්\\u200dරාමාණික ලාභ ව්\\u200dයවසායකත් ලාභ ඉක් වූ ඉහළ සාමාන්\\u200d ලාභ මට්ටම . වෙළඳපොල තරගකාරීත්ව ස්වභාව බලපෑ වේ',\n",
              " 'නිදහස වෙළඳපොළ ආර්ථික මධ්\\u200dයගත සැලස ආර්ථික මිශ\\u200d්\\u200dර ආර්ථික විවිධ වර්ග ආර්ථික පද්ධ අසීමිත අවශ්\\u200dයත සීමිත සම්ප හේතු ආර්ථික ඇතිව හිඟය මුහ දීම පිළිතුර සැපය යුත මූලික ආර්ථික ප\\u200d්\\u200dරශ් තුන ඇතුළ වේ . නිෂ්පාදන කළ යුත්ත කුම නිෂ්පාදන කර කෙස නිෂ්පාදන කළ යුත්ත කාට,',\n",
              " \"අයවැ සංරෝධක දෙන ආදායම පාරිභෝගික දෙන ලද මිලක මිල ගත් භාණ්ඩ එ් සංයෝජන සප . විවිධ භාණ්ඩ සේ  භාණ්ඩ ප\\u200d්\\u200dරමාණය මිලද ගැනීම පාරිභෝගික කැම වුව, පාරිභෝගිකය ඔව උපයෝගීතා උපරි කර ගැනී ඔව භාණ්ඩ හෝ සේ සංයෝජ තෝර ග අයවැ සංරෝධකය යටත්වය.'\",\n",
              " 'සංඛ්\\u200dයාසූචක උපයෝගීතා යනු ” යුටීල් ” කෘත\\u200d්\\u200dරි එ්කකය භාවිත කර විවිධ භාණ්ඩ සේ පාරිභෝගික ඉල්ලූ උපයෝගීතා මැනීම සංසන්දන කිරීම පරිමාණය යොද ගන් ක\\u200d්\\u200dරමවේදයකිි . මෙය පාරිභෝගික තෘප්ත හෝ උපයෝගීතා කෘත\\u200d්\\u200dරිම සංඛ්\\u200d පරිවර්තන කිර උත්සාහ . මෙය ආර්ථික විද්\\u200dයා සම්භාව්\\u200dයවාද චින්තනය අ වේ.',\n",
              " 'කාටල යනු ලාභදායිත්ව වෙළඳපොළ ආධිපත්\\u200dය කර ගැනී වෙළඳපොළ සහභාගීවන්න කිහිප දෙන දුස්සන්ධාන (කුමන්ත\\u200d්\\u200dරණකාර හවුලකිි * . කාට සාමාන්\\u200dය සෑද ඇත්ත තරඟකාර නිෂ්පාද . නිෂ්පාදන මිල හෝ ප\\u200d්\\u200dරමාණ තීරණ කිරී කාටලය රහස එකඟත තිබ හැ . මෙය විශේෂ කතිපයාධිකාර වෙලඳපොළ, ප\\u200d්\\u200dරති-තරගකාර වෙලඳපොළ හැසිරීම සැල.',\n",
              " 'ඉල්ලූ වෙනස වීම- සල බලන භාණ්ඩ මිල ඉල්ලූ බලපා අනෙකු සාධක වෙනස ව ප\\u200d්\\u200dරතිඵලය ඉල්ලූ වෙනස වේ . ආදාය, අනුපූරක ආදේශක නිෂ්පාදන මිල මට්ට වෙනස වීම, පාරිභෝගික රුච, කාලගුණික තත්ත්ව, අනාගත අපේක්ෂා, ජනගහන වෙනස වීම සාර් ආර්ථික වෙන වෙනස්ක ප\\u200d්\\u200dරතිඵලය ඉල්ලූ වක\\u200d්\\u200dර වමට හෝ දකුණ මාර කළ හැ . ඉල්ලූ වෙනස වීම පහත පෙන් ඇත . ඉල්ලූ ප\\u200d්\\u200dරමාණ වෙනස වීම අර්ථ දැක්වෙ අනෙකු සාධක ස්ථාවර සල බලන භාණ්ඩ මිල වෙනස ව ප\\u200d්\\u200dරතිඵලය ඉල්ලූ ප\\u200d්\\u200dරමාණ වෙනස වීම . මෙය ඉල්ලූ වක\\u200d්\\u200dර සිදුව චලන.',\n",
              " 'සල බලන භාණ්ඩ මිල සැපයු බලපා අනෙකු සාධක වෙනස කිර ප\\u200d්\\u200dරතිඵලය සැපය වෙනස සිද . වෙනස බදු, නිෂ්පාද පිරිවැ, තාක්\\u200dෂණ, කාලගුණ සාර් ආර්ථික වෙන වෙනස්ක හේතු සැපය වක\\u200d්\\u200dර වමට හෝ දකුණ විතැ විය හැ . සැපය වෙනස පහත පෙන් ඇත . සැපය ප\\u200d්\\u200dරමාණ වෙනස වීම අර්ථ දැක්වෙ සල බලන භාණ්ඩ මිල වෙනස ව ප\\u200d්\\u200dරතිඵලය සැපය ප\\u200d්\\u200dරමාණ වෙනස වීම . මෙය සැපය වක\\u200d්\\u200dර දි චලන.',\n",
              " 'සම්භාව්\\u200d ආර්ථික විද්\\u200dයා 18 සියවස ආර්ථික විද්\\u200dය පි ඇඩ ස්මි ආරම්භ කරන ලදී . ආර්ථික විද්\\u200dය පළ ගුරුකුල මෙ . ගුරුකුල අදෘශ්\\u200dයමා හස්ත, නිර්බාධවාද ආර්ථික, ආර්ථික නියෝජිතයි නිදහස, තේරී, තරඟකාරිත්ව සමමිතික තොරතුර යනාද සංකල්ප ආර්ථික කාර්යක්ෂමතා කිරීම භාවිත කර.',\n",
              " 'දුස්සන්ධාන යනු රහස සංස්ථාව හරහ වෙළඳප සමතුලිතතාව බාධ කිරී කණ්ඩාය දෙක හෝ කිහිපය ඇතිව රැවටිලිකාර ගිවිසුම . සහභාගිවන්න වෙළඳපොළ තරගකරු වුව, ඔවු හරහ අධික ආර්ථික ලාභය ලබා ගැනීම එකත වෙ . සමහර මෙය නී විරෝධ විය හැ.',\n",
              " 'තරග යනු ඉහළ ආදායම, ලාභය විශාලත වෙළඳපොළ කොටස ලබා ගැන අරමුණ සමජාත නිෂ්පාද හෝ සමීප ආදේශක අලෙවි කරන ව්\\u200dයාපාරික ආයත ගැටුම . එහි පූර්ණ තරඟ එ්කාධිකාර තරග, කතිපයාධිකාර අපූර්ණ තරග විවිධ ස්වරූප පවත . ව්\\u200dයාපාරික සමාග තරඟ ජය ගැනී තමන්ගේ නිෂ්පාදනය ප\\u200d්\\u200dරවර්ධන කිරීම වෙළඳ ප\\u200d්\\u200dරචාරණ විවිධ උපා මාර්ග භාවිත කෙරෙ.',\n",
              " 'අනුපූරක භාණ්ඩ සෑම විට අන නිෂ්පාදනය වටිනාකම එක් කර . එ් සෑම එකට භාවිත කරන නිෂ්පාද දෙක . එක් අනුපූරක භාණ්ඩ මිල කිරී අන නිෂ්පාදන ඉල්ලූ අඩු කිරීම හේත වේ . උදාහරණ: ජංග දුරකථන සි කාඞ පත',\n",
              " 'ස්ථාවර ආවස්තික පිරිවැ යනු එක් භාණ්ඩ නිෂ්පාදන නිශ්චිත අනුපාත භාණ්ඩ නිෂ්පාදන කිර ආවස්තික පිරිවැ නියත පවති සෘජ රේඛ නිෂ්පාද හැකි වක\\u200d්\\u200dර සහිත අවස්ථා . උදාහරණ: සෙල්ල බඩු සමාග නිෂ්පාදක සෑම එක් සෙල්ල බස් රථය නිෂ්පාදන කරන සෙල්ල කාර දෙක අත්හැර දමයි.,',\n",
              " 'ස්ථාවර පරිමාණානුකූ ඵල- යෙදව ඉහළ දැම (ශ\\u200d්\\u200dරම, ප\\u200d්\\u200dරාග්ධන * එකම අනුපාත නිෂ්පාදන ඉහළ දැමී ස්ථාවර පරිමාණානුකූ ඵල හැඳින්',\n",
              " 'පාරිභෝගික යනු නිෂ්පාදනය හෝ ව්\\u200dයාපාරික ක\\u200d්\\u200dරියාකාරකම්වල සෘජ සම්බන්ධ නොව තම සෘජ පරිභෝජ අවශ්\\u200dයත සපුරාලී වෙළඳපොළ භාණ්ඩ සේ මිලද ගැනීම කැමැත්ත සිටි පුද්ගල හෝ පුද්ග සමූහ',\n",
              " 'පාරිභෝගික හැසිරී යනු පාරිභෝගිකයි උපයෝගීත, මනාප, ආකල්ප චිත්තවේග පදනම් භාණ්ඩ සේ මිලද ගැන ක\\u200d්\\u200dරියාකාරක වේ . ආර්ථික විද්\\u200dයාවේද, පාරිභෝගික තම උපයෝගීතා උපරි කිරීම හැසිරෙ',\n",
              " 'පාරිභෝගික සමතුලිත යනු දෙන ලද ආදාය මට්ටම භාණ්ඩ දෙන ලද මිල ගණ යටත පාරිභෝගික තම මුළ උපයෝගීතා (උපරි තෘප්ත * උපරි කරන තත්ත්ව . සංඛ්\\u200dයාසූචක උපයෝගිත ප\\u200d්\\u200dරවේශ ක\\u200d්\\u200dරමසූචක උපයෝගිත ප\\u200d්\\u200dරවේශ විවිධ ආකාර පාරිභෝගික සමතුලිතතා මැන බල.',\n",
              " 'පාරිභෝගික නිදහස- පාරිභෝගික නිදහස යනු විවිධ සැපයුම්කරු විවිධ භාණ්ඩ සේ පරාස අඩු මිල ඉහළ ගුණාත් බව යු හොඳ නිෂ්පාදන තෝර ගැන හැකියා . නිදහස වෙළඳපොළ නිසි ක\\u200d්\\u200dරියාකාරිත්ව සම්භාව්\\u200d ආර්ථික විද්\\u200dය වැදගත් සංකල්ප සැලකෙ පාරිභෝගික ස්වෛරීත්ව මෙය තවදුර හැඳින්.',\n",
              " 'පාරිභෝගික අතිරික්ත යනු ගෙවීම කැමැත්ත අඩු මිලක භාණ්ඩය හෝ සේවාව මිලද ගැනී පාරිභෝගික ලබන මූල්\\u200dයම ලාභ . භාණ්ඩ සැබෑ මිල පාරිභෝගික ගෙවීම මුල කැමැත්ත පරතර පාරිභෝගික අතිරික්ත හැඳින්.',\n",
              " 'නිෂ්පාද පිරිවැ යනු ව්\\u200dයාපාරික ආයතනය ආදායම උපදව භාණ්ඩ හෝ සේවා නිෂ්පාද ක\\u200d්\\u200dරියාවලි ජනන සෘජ වක\\u200d්\\u200dර පිරිවැ . යන්ත්\\u200dරෝපකරණ, ගොඩනැග මූලික සැකස ස්ථාවර පිරිවැ ශ\\u200d්\\u200dරම, අමුද්\\u200dරව්\\u200d පරිභෝජ ද්\\u200dරව්\\u200d විචල්\\u200d පිරිවැ දෙක මෙය ඇතුළ වේ.',\n",
              " 'හරස ඉල්ලූ නම්\\u200dයතා මනි ලබ අන සාධක නියත පවති එක් භාණ්ඩ මිල ප\\u200d්\\u200dරතිශත වෙනස ව ප\\u200d්\\u200dරතිඵලය, අන නිෂ්පාදනය ඉල්ලූ කරන ප\\u200d්\\u200dරමාණ ප\\u200d්\\u200dරතිශතක වෙනස . මෙය ආදේශක භාණ්ඩ ධන අගය අනුපූරක භාණ්ඩ සෘණ අගය ගනී.',\n",
              " 'හීනව ආවස්ථික පිරිවැ එක් භාණ්ඩ නිෂ්පාදන අතිරේක එ්කක කරන භාණ්ඩ නිෂ්පාදන කිර ආවස්ථික පිරිවැ අඛණ්ඩ අඩුවී පැහැද කරන එය මූලය උත්ත නිෂ්පාද හැකි වක\\u200d්\\u200dරය ඇතිවීම හේත වේ.',\n",
              " 'ඉල්ලූ යනු අනෙකු සාධක ස්ථාවර තබා ගනි යම් කාල සීමාව කිසිය පුද්ගල හෝ ගෘහ කුටුම්බය මිලද ගැනීම කැම, මූල්\\u200dයම හැකියා විවිධ මිල ගණ යටත මිලද ගැනීම සූදාන භාණ්ඩ සේ ප\\u200d්\\u200dරමාණ අර්ථ දැක්.',\n",
              " 'ඉල්ලූ ශ\\u200d්\\u200dරිත යනු නිෂ්පාදනය ඉල්ලූ (පරායත්ත විචල්\\u200dය * මිල, ආදාය, ආදේශක අනුපූරක භාණ්ඩ වල මිල, රුච අනාගත අපේක්ෂ එහි නිර්ණා සම්බන්ධතාව නිරූපණ . කෙස වෙ, ඉල්ලූ ශ\\u200d්\\u200dරිත ප\\u200d්\\u200dරධා සල බලනු අනෙකු සාධක නියත පවති ඉල්ලූ ප\\u200d්\\u200dරමාණ භාණ්ඩ මිල පවති සම්බන්ධතාව.',\n",
              " 'භාණ්ඩ මිල, ආදාය, සම්බන්ධ භාණ්ඩ සේ වල මිල (ආදේශක අනුපූරක *, රුච අනාගත අපේක්ෂ සාධක ඉල්ලූ නිර්ණා හැඳින් . භාණ්ඩ මිල, යෙදව මිල, විකුණුම්කරු සංඛ්\\u200dයා, තාක්ෂණික මට්ට, රජ නියාමන බදු, අනෙකු භාණ්ඩ මිල අනාගත මිල ගණ සාදක සැපය නිර්ණා හැඳින්වේ.,',\n",
              " 'යම් කාල සීමාව අනෙකු සියල භාණ්ඩ නියත පවති, භාණ්ඩ පරිභෝජන කරන ප\\u200d්\\u200dරමාණ, අනුප\\u200d්\\u200dරාප්තික එ්කක පාරිභෝගික ලබා ගන් උපයෝගීතා ක\\u200d්\\u200dරම අඩුවී හීනව ආන්තික උපයෝගීතා හැඳින්වෙ',\n",
              " 'ව්\\u200dයාපාරික ආයතන පරිමාණ ඉහළ යා ප\\u200d්\\u200dරතිඵලය නිෂ්පාදන එ් පිරිවැ අඛණ්ඩ ඉහළ යාම පරිමාණානුකූ නොපිරිමැස කර . මෙය පරිමාණ ආයතන කළමනාකරණ ගැටළ, තාක්ෂණික ගැටල අමුද්\\u200dරව්\\u200d යෙදව ගැටල හේතු ජනන වේ.',\n",
              " 'බෝධ, වජ්\\u200dරාසන, පද්ම, සිරිපතු, ධර් චක්\\u200dර, ස්තූප',\n",
              " 'ධ්\\u200dයා මුද්\\u200dරා, අභය මුද්\\u200dරා, විතර්ක මුද්\\u200dරා, ධර් චක්\\u200dර මුද්\\u200dරා, භූ ස්පර්ශ මුද්\\u200dරා, වරද මුද්\\u200dරා',\n",
              " 'වීරාසන, භද්\\u200dරාසන, පද්මාසන',\n",
              " 'පිළිමය පිටුපස ගල හෝ වෙන බාහිර ආධාරකය ඇති නිම පිළි ආබද්ධ පිළි හැඳින්',\n",
              " 'පිළිමය පිටුපස ගල හෝ වෙන බාහිර ආධාරකය නොමැති නිම පිළිම අනාබද්ධ පිළි හැඳින්',\n",
              " 'බුදුරජාණ වහන්ස සියල කෙලෙස දුර වූ හෙයින් රහසින් පව් නොකළ සියල පූජා ලැබීම සුදුස වූ හෙයින් අරහං',\n",
              " 'ආර් මාර්ග ගම කළ හෙයින් සුන්දර වූ නිර්වාණය සැප වූ හෙයින් දෙලොවට වැඩ යහප වචන පවස හෙයින් සුගත වේ',\n",
              " 'තමා විසින් පිළිපැ ඇස් පනාපි මෙලොවදී ප්\\u200dරතිඵ දැකගත හැ ධර්ම සන්දිට්ඨික වේ',\n",
              " 'සංඝරත්න මනා වූ පිළිවෙ පූර්ණ සුපටිප වෙ',\n",
              " 'සර් මිත්\\u200dර බම සිදුහ කුමාර ගුරුවර වේ',\n",
              " 'රම්\\u200d, සුරම්\\u200d, සුභ මාලිග ත්\\u200dරිත්ව',\n",
              " 'සුප්\\u200dරබුද්ධ රජතුම යශෝදර දේවි පිය',\n",
              " 'තණ්හ රති රඟා යනු මාර දූ තිදෙන',\n",
              " 'සඵල පොලි අනුපාතික 8.3% වේ.',\n",
              " 'ආයෝජන කළ හැ උපරි අගය ව රුපියල මිලිය 13.33',\n",
              " 'ජලාශිත ශිෂ්ටාචාර සම ලංකා වැදග ජාත්\\u200dයන්තර වෙළ මධ්\\u200dයස්ථානය විය ප්\\u200dරධා හේතුව වූ පෙර අපර දෙදිග වෙළඳ මාර්ග ලංකා පිහිටීම . නිරිත ඊසානම සම් සුන කලාප ලංකා පිහිට තිබී පෙර අපර දෙදික වෙළෙඳ මාර්ග එන නැව්වල මෙර වෙළඳ මධ්\\u200dයස්ථානවල පැමිණී පහසු',\n",
              " 'පෘතුගීසි, ලන්දේසි, ඉංග්\\u200dරීසි, ප්\\u200dරංශ ජාතිකය',\n",
              " 'පෘතුගීසී රූකඩය කටයුත කළා යැ සැලකෙ දො ජු ධර්මපා රජතුමා',\n",
              " 'පෘථිවිසී ලංකාව පැමිණෙ යාපන රජ කළේ පරරාජසේකර රජු',\n",
              " 'කැලිකට් පාලක ව සැමොර',\n",
              " 'පළමුව විමලධර්මසූර රජතුම හමුවීම පැමිණි ජොරිස ෆන් ස්පිල්බර්ජන',\n",
              " '1931 ඩොනමෝර ආණ්ඩුක්\\u200dර ප්\\u200dරතිසංස්කරණ',\n",
              " '1947 සෝල්බරි ආණ්ඩුක්\\u200dර ප්\\u200dරතිසංස්කරණ යටත',\n",
              " '1972 ප්\\u200dරථ ජනරජ ව්\\u200dයවස්ථා',\n",
              " 'ලංකා අත්ප කර ගැනී කෙර බේතාන්\\u200dය අවධාන යොමුවීම හේත වූ ඉන්දිය බටහිර නැගෙනහිර වෙරළ නාවික බලය ලංක පාලන කළ හැකිවී ත්\\u200dරිකුණාමල ස්වභාවික වරා පිහිටී බ්\\u200dරිතාන්\\u200dයයන් වැදග විය',\n",
              " 'අංග ජනපද මගධය ඈඳා ගත්ත බිම්බිසාර රජු විසින්',\n",
              " 'කාලිංග දේශ මෞර් අධිරාත්\\u200dරිය ඈඳාගැනී කළේ අශෝක රජතුම විසින්',\n",
              " 'දෙව චන්ද්\\u200dරගුප්ත රජතුම',\n",
              " 'චන්ද්\\u200dර ගුප්ත මෞර් රජු සට කරන ලද්ද සෙලියුකස නිකේටර පාලක සමගි',\n",
              " 'අශෝක අධිරාජ පාල නගර ව පාටලීපුත්\\u200dර නගර',\n",
              " 'මේක දූත සකුන්තර කුමාර සම්භව සම්භාවධර් රච කරන ලද්ද කාලිදාස කවි විසින්',\n",
              " 'ක්\\u200dරිස්ත වර්ෂ 1898 ඉන්දිය කැලිකට නගරය ගොඩබ පළ පෘතුගීසි නායක ව වස්කෝ ගාමාන වේ',\n",
              " 'ඉන්දියා සංවිධාන ආරම්භ කරන ලද්ද සුරේන්ද්\\u200dරනා බැනර්ජි විසින්',\n",
              " 'ජන නායක ව සුභාෂ චන්ද්\\u200dර බෝස',\n",
              " 'ටොකුගා පාල සම ජපාන වෙළඳ සම්බන්ධත පැවැත්වූ පෘතුගීසි ස්පාඤ්ඤ ලන්දේසි',\n",
              " 'පිරිස ව සමුරායිවරුන්',\n",
              " 'නායක ව ජේ.ආර්.ජයවර්ධන',\n",
              " 'nan',\n",
              " 'දෙව ලෝක යුද සම ජපා ය ව ගිවිසුම අත්ස කරන අවස්ථ මිත්\\u200dරප නියෝජන කරන ජනරාල්වර ව මැ ආතර්',\n",
              " 'මල්වත ඔය ආශ්\\u200dරිත ජනාවාස පිහිට ගත්ත උපතිස්ස ඇමත',\n",
              " 'ලංකාව ඇතුළ කොට ලෝක සිතියම නිර්මාණ කරන ලද්ද ක්ලෝඩියස ටොල වේ!',\n",
              " 'ලංකා පැවිදි ලැබ පළ රාජක කාන්තා ව අනු බිස',\n",
              " 'නිදහස ලංක ප්\\u200dරථ අගමැතිවර ව ඩී.එස්.සේනානා මහත වේ',\n",
              " 'සාංචි ස්ථූප පිහිට ඇත්ත ඉන්දියාවේ',\n",
              " 'සාංචි ස්ථූප අ ව මෞර් ගෘහ නිර්මාණ කලාවට',\n",
              " 'සාංචි ස්තූප කරව ලද්ද අශෝක රජතුම විසින්',\n",
              " 'ශිව දේවාල සම්බන්ධ ව හින්ද ආගම සමග',\n",
              " 'ශිව දේවා අ ව පොළොන්නර යුගයට',\n",
              " 'ශිව දේවා වල දක්න ලැබෙ චෝල වාස්ත විද්\\u200d ශෛල',\n",
              " 'විජ රජු පිරිස ගොඩ බසි ලද්ද තම්මැන් ප්\\u200dරදේශය',\n",
              " 'පඬු දෙ රජු පිරිස ලංක ගොඩ බසි ලද්ද කම්මල්තො ප්\\u200dරදේශයට',\n",
              " 'ජනප පිහිට ගත් ආර්ය පසුකාලීන ජල සම්පාද ව්\\u200dයාපාර ආරම්භ කිරී කෙර තම අවධාන යො කිරීම ප්\\u200dරධා හේත වූ ප්\\u200dරධා ජීවනෝපා මාර්ග වී වගා වීම',\n",
              " 'සූරතිස්ස රජු කාල ලංකාව පැමිණි ආක්\\u200dරමණිකය ව සේන ගුත්තික වේ',\n",
              " 'ේල රජු කාල ලංකාව එළාර ආක්\\u200dරමණ පැමිණියේ',\n",
              " 'පස් මිහිඳ රජු කාල ලංකාව පැමිණි ආක්\\u200dරමණ ව පළමුව රාජේන්ද්\\u200dර ආක්\\u200dරමණ',\n",
              " 'ඉන්ද සේන ආකාර ලබා තම සහෝදර සට කොට ලංකාරාජ්\\u200d උරුම ලබා ගන් ලද්ද පළමුව මුගල කුමර',\n",
              " 'එය කරන ලද්ද සංඝමිත්\\u200dර භික්ෂූ වහන්ස',\n",
              " 'පළවෙ විජේප්ප රජතුම කුමාරයෙක් සිටි කාල රැකවරණ ලබා දෙන ලද්ද බුදල් තැනැත්තෙ',\n",
              " 'පාල මධ්\\u200dයස්ථාන නිරිත දිග විතැ වූ අවධි මෙර ආර්ථික ඇතිව වැදග වෙනස්කම ව වී ගොවිතැන හිමි තිබ ප්\\u200dරමුඛතාව අඩුවීම ොයි තැන උචිත තැනිත ඉඩ අඩුවීම ප්\\u200dරමාණ ජල සම්පාද කටයුත නොතිබීම හේත වී ගොවිතැ අඩා විය . වැ වාරිමාර්ග කටයුත ජනතා පැවැ උනන්ද අඩු වූ වර්ෂ ජලය ලැබෙ ප්\\u200dරමාණ වකවාන වගා කිරී කෙරිණි',\n",
              " 'පාල පහස රජර බෙද වෙන්කර ලද ප්\\u200dරාදේශ ඒකක ව උත්තරපස්ස, දක්ඛිණපස්ස, පාචීනපස්ස, පශ්චිමපස්ස වේ',\n",
              " 'ගමක නායකත්ව දැර ගමික ග්\\u200dරා භෝජකය ඉටු වූ ප්\\u200dරධා සේවාව ව ගමේ සාම වින පව ගැනීම උපකාර කිරීමයි ගමේ කටයුත රජතුමා වගකීම බැඳ සිටි තනතුර රාජ අණ ගමේ ගැට වැළැක්ව පියවර ගැන බලය ගමක තිබිණි ගම්වාසී සාමූහික කටයුත කිරී තුළ යුක්ත පසිඳ ලීම ගමි කාර්ය විය',\n",
              " 'පෘතුගීසීන් උඩර රාජධා ය කර ගැනීම නොහැ වීම ප්\\u200dරධා හේතුව වූ උඩර රාජධානි භෞතික පරිසර නිසි අවබෝධය නොමැ වීම . ඒවගේ උඩරටි රාජ පාක්ෂික භාවය එයට හේතුව විය',\n",
              " 'ක්\\u200dරිස්ත වර්ෂ 1803 උඩර ආක්\\u200dරමණ කළේ ෆෙඩ්\\u200dරි නෝර් ආණ්ඩුකාරවර',\n",
              " 'උඩර රාජ්\\u200dය ජයගැනී සහා වූ සිවිල නිලධාරි ජෝ ඩොය නම්',\n",
              " '1840 මුදබි පනත උඩර ඉඩ රජය පවර ගැනී හ ගම් සභා ක්\\u200dරම අහෝසි කිරී හේතූ වෙ',\n",
              " 'නන් රාජ වංශ පළ පාලක ව පද්මානන් වේ.',\n",
              " 'ගුප්ත අධිරාජ්\\u200dය පාල තත්ත්ව මනා සංවිධානාත් භාව යුක්ත විය . එහි පාලන මූලික වූ රජය . මහාරාජාධිරාජවිරුද ගුප්ත රජ භාවිත කළහ . මන්ත්\\u200dරී පාල සංවිධාන ඉහළ බලධාර වූහ . ගුප්ත අධිරාජ්\\u200dය පාල තත්තිත්ව සංවිධාන වී තිබ ඒකකය වූ භුක් න හැඳින්ව ප්\\u200dරාදේශ පාල ඒකක',\n",
              " 'ඉන්දියා දේශපාලන තීරණාත් සිදුවීම සැලකෙ සිප කැරැල්ල බලපෑ හේතුව ව ඉංග්\\u200dරීසී ඉන්දිය ප්\\u200dරදේශ ඈදා ගැනීමේද අනුගමන කළ අත්තනෝමතික ප්\\u200dරතිපත්ති . දේශපාලනික ඉන්දියා නායක නිකරුව පත් කිරීම ඉංග්\\u200dරීසී ක්\\u200dරියාකලාප හේත විය . ඉන්දිය අවශ්\\u200dයත නොසල හරි බ්\\u200dරිතාන්\\u200d රජ ඕනෑ එපාක කටයුත කිරීම අකමැ ඉන්දියාන කැරැල් මෙහෙයව . තවද ඉන්දියාව ආර්ථික සිදුව බල පාඩුව වූ ඉන්දිය සම්ප බ්\\u200dරිතාන්\\u200dයය ගෙනයාම . ඉන්දියානුවන් සිදුව අසාධාරණක හම බ්\\u200dරිතාන්\\u200d ආර්ථික බල වීම නොඉවස ඉන්දියා නායක සිපො කැරැල් මෙහෙ වූහ',\n",
              " 'ගුරුත්වාකර්ශ නියම සො ගනු ලැබ සර් අයිසැ නිව්ට විසි',\n",
              " 'රුධිර සංසරණ පද්ධත තොරතුර සොයාග ලැබ විලිය හ වෛද්\\u200dයවර',\n",
              " 'මුද්\\u200dරණයන්ත්\\u200dර නිර්මාතෘවර ව ජ්\\u200dරහාන්ස ගුටර්න්බර්ග',\n",
              " 'තුර් අ ගත් නැගෙනහිර රෝම අධිරාජ්\\u200dය අගනුවර ව කෝන්ස්ටන් නෝපල වේ',\n",
              " 'දේශ ගවේෂණ යෙදෙ අයට දැක්ව පෘතුගාල නායක ව නාවික හෙන්රි වෙ',\n",
              " 'මීට පසුබි වූ හේතුව ව වාණිජ කටයුත පුළුල වීම බ්\\u200dරිතාන්\\u200dය ධන පිරිස බිහිවීම . ඔවුන් කර්මාන්ත පොළොල ආයෝජනය කළ හැකිවී කාර්මික විප්ලව බිහිවීම එංගලන්ත පසුබි සැකසිණි . ය විජිත ප්\\u200dරදේශ කර්මාන්ත අවශ්\\u200d අමු ද්\\u200dරව්\\u200d සප ගත හැකිවී යන්ත්\\u200dර සූත්\\u200dර ක්\\u200dරියාත් කිරීම අවශ්\\u200d ගල් අඟුර කර්මාන්ත අවශ්\\u200d යහප එංගලන්ත සුලභ වීම කාර්මික විප්ලව ආරම්භ වූ මුල් රට එංගලන්ත පත්වීම හේතුව විය',\n",
              " 'ජර්මනිය දඬුව පමුණුව ලද්ද වර්සල්ස ගිවිසු මගි',\n",
              " 'හිට්ලර රච කරන ලද නාසිවාද අත්පොත මගේ සටන වේ',\n",
              " 'දේශාඨක වාර්තා වශයෙන් අන්තර්ගත වී ඇත්ත ලංකා විදේශ රට වෙළඳ සම්බන්ධත ගොඩනැග තිබ බවය',\n",
              " 'ප්\\u200dරථ වරට ග්\\u200dරා සීම නිය කරන ලද්ද පණ්ඩුකාභ රාජ්\\u200d සමයේද',\n",
              " 'ක්ෂත්\\u200dර අභිෂේක මෙර හඳුන් ද ඉන්දියානුපාලක ව අශෝක රජතුමා',\n",
              " 'විශිෂ් නිර්මාණ ව ජය ගඟ වේ',\n",
              " 'සුළ පරාජ කිරී පළමුව විජයබා රජු හමුද ගම ඇරැඹ ස්ථාන ව මහානාගහුළ ස්ථාන',\n",
              " 'මූලික ජල දුර්ගය මුල්කොටගෙ ඉදිකර ලද්ද කෝට්ට රාජධානි',\n",
              " 'ඩොනමෝර ක්\\u200dර යටත මෙර මහජ නියෝජිතයින් පැවරුන අධ්\\u200dයාප කටයුතු',\n",
              " 'හරිසේන අලහබ ප්\\u200dරශස්ති තොරතුර ලැබෙ සමුද්\\u200dරගුප්ත රජතුමාට',\n",
              " 'ජෝ මැකඩ හඳුන් දෙ ලැබ මැකඩ ක්\\u200dරම භාවිත කරන ලද්ද මාර්ග තැනී සඳහා',\n",
              " 'කොන්ෆියුසියස ධර්ම පැතිරෙ ලද්ද චීන විසි',\n",
              " 'අන්කෝර් විහාර පිහිටි රටව කාම්බෝජ',\n",
              " 'අනුරාධගා පිහිටි ලංක මල්වත ඔය ආශ්\\u200dරිත',\n",
              " 'අතීතයේ ලංක දීඝකා පිහිටි ගල්ඔ ගංග නිම්න ආශ්\\u200dරිත',\n",
              " 'අතීත උරුවේලගා පිහිටි ලංක ගෝන නදී ගංග නිම්න ආශ්\\u200dරිත',\n",
              " 'අතීත ලංක මහාගා පිහිටි කිරිඳිඔ ආශ්\\u200dරිතව',\n",
              " 'අනුරාධපුර යුග මුල භාග වාරිමාර්ග ආරම්භ කිරී කෙර බලපෑ ප්\\u200dරධා හේත ව ජනතා ප්\\u200dරධා ජීවනෝපා වූ වී වගා ්\\u200dර ප්\\u200dරමාණ ගංග ජලය නොලැබීම . අවුරුද්ද කාලය න කාල පැවතීම වර්ෂා අවුරුද්ද එක් කාලයක සීම වීම ඔව ජලය අතිරික්ත තැන ගරා ඒමට සැලසුවහ . ක්\\u200dරම වාරිමාර්ග පද්ධතිය අවශ්\\u200d විය',\n",
              " 'එකල ලංක පැවැ දේශ වෙළඳා සංවිධාන වී තිබ ප්\\u200dරධා භාණ්ඩ හුවමාර මතය . සීමිත කාසි භාවිතය පැවතිණි . ල කුලුබඩ රෙදි පිළි වෙළඳ භාණ්ඩ බහුල භාවිත කර ඇත . මුත මැණි ඇත ඇත්ද මෙර දේශ වෙළෙඳපොල අලෙවි උයේ නැත ජන අවශ්\\u200dයත සරල වූ වෙළඳ භාණ්ඩ ග්\\u200dරාම නිප වූ ඒවා බහු විය',\n",
              " 'පෘතුගීසී ලංකාව පැමිණෙ මෙර පැවැ රාජධා ව කෝට්ට, කන් උඩර, යාපන රාජධාන',\n",
              " 'ලන්දේසී ලංකා ආර්ථික බස් ලබා ගැනීම පුරුද වගා සංවිධානාත්මක දිය කරන ලදී . එයට අමතර ඔව පොල උක්, කුළුබඩ, බෝගවගා, ඒවා ගැලපෙ දේශග තත්ත්ව සහිත ප්\\u200dරදේශ වගා කරන ලදී . අත්හැර දමා තිබ මුඩ බි ප්\\u200dරයෝජනය ගැනීම ලන්දේසී මෙරට උපරි ආර්ථික වාසි ලබා ගැනීම යෙදූප ක්\\u200dරමයකිි',\n",
              " 'පෘතුගීසීන් හාලන්දේසීන් උඩට රාජධානිය කර ගැනීම නොහැ වීම බලපෑ එක් හේතුව ව උඩර රාජධා සත පැව ස්වභාවික රැකවරණ . එන ගිරි ජල දුර්ග කපල උඩර රාජධානිය මායිම් බහු පිහිට තිබීම . උඩරට පිවිසෙ මාර්ග යුරෝපීයයන් තිබ අඩු දැනු ඔවුන් උඩර රාජධානි ය කිරී අපහසු',\n",
              " 'රට ස්වාධී රාජ්\\u200dයය තිබී බ්\\u200dරිතාන්\\u200dය කටයුතුවල බාධාව වීම පහතර වූ කැරලිවලද උඩර රජ ඒවා උද දීම බ්\\u200dරිතාන්\\u200dයයන් බාධාව විය',\n",
              " 'ක්\\u200dරිස්ත වර්ෂ 1818 උඩර බ්\\u200dරිතාන්\\u200d විරෝධ නිදහස අරගලය ඇතිවීම බලපෑ එක් හේතුව ව 1915 ගිවිසු ප්\\u200dරකාර පොරොන්ද ඉටු නොකිරීම . පෙර බුද දහම අනුග්\\u200dරහණ දැක්වී භික්\\u200dෂූ නොසල හැරී බොද සිරි විරි තුළ ගරු නොකිරී රදළවරවල ගරු නොකිරී රදළ වරප්\\u200dරසා ආදාය මාර්ග අහි කිරී ආද සිදුවූ 1915 පොරොන්ද කඩ කරමින් . 1818 උඩර බ්\\u200dරිතාන්\\u200d විරෝධ නිදහස අරගලය ඇතිව',\n",
              " 'ඉන්ද බෝධිසංග පිහිටවූ අනගාරික ධර්මපාලතුම විසි',\n",
              " 'යාපන වන්නාරපන්නේ ඉංග්\\u200dරීසි පාසල පිහිටුවූ ආරුමුග නාවලර තුම විසි',\n",
              " 'මෙර බෞද්ධ අධ්\\u200dයාපන නගා සිටුවී හෙන්රි ස්ටීල ඕල්කට තුම පරම විඤ්ඤාණාර්ථ බෞද්ධ සමාග පිහිට එමඟ බෞද්ධ පාසල ආරම්භ කළේ . කොළඹ ආනන් විද්\\u200dයාල ගාල් මහින් විද්\\u200dයාල මහනුවර ධර්මරාජ විද්\\u200dයාල මේෙස බි වී බෞද්ධ අධ්\\u200dයාපන නගා සිටුව කාර්ය දිය විය . කාන්ත බෞද්ධ අධ්\\u200dයාපන නඟා සිටුවීම විශාඛ මියුසියර සැබෑ බාලි පාසල ආරම්භ කළේ හෙන්රි ස්ටීල ඕල්කට තුමා',\n",
              " 'ක්\\u200dරිස්ත වර්ෂ 6 ශත වර්ෂ උතුර ඉන්දිය පැව දේශපාල සංවිධාන මූලික ජනප දාසය යටත සංවිධාන වී තිබිණි . ජනප ව්\\u200dයාප්ත තිබ ගංගාන ගංගානිම්නයේ . ජනපද රාජාණ්ඩ සමූහාණ්ඩ පාල ක්\\u200dර තිබිණි . මගධ කෝස වස්ස අවන්ත ජනප රාජාණ්ඩ අතර වැදගත් ඒවා අතර මගධ ප්\\u200dරබ අධිරාජ්\\u200d පත්ව වජ්ජි මල් ජනප සමූහා වැදග විය',\n",
              " 'ඉන්දිය අවසා බ්\\u200dරිතාන්\\u200d ප්\\u200dරතිරාජ ව මව බැට ස්වාමිවර වේ',\n",
              " 'බ්\\u200dරිතාන්\\u200dය ඉන්දියා පිටුදැකී අවි බලය යෙද යුතු අදහස දැර සුභාෂ්චන්ද්\\u200dරභෝස නම්',\n",
              " 'ඉන්දියා ජාතික ව්\\u200dයාපාර පි සැලකෙ සුරේන්ද්\\u200dරනා බැනර්ජ මහතා',\n",
              " 'ඉන්දියා ජාතික කොංග්\\u200dරස මුස්ලි සංගම එකඟතාව ඇතිකර ගැනී සම්මේලන පැවැත්වූ සිම් ස්ථානයේ',\n",
              " 'බ්\\u200dරිතාන්\\u200dය ආරම්භ කරන ලද ඉංග්\\u200dරීසි අධ්\\u200dයාපන විවිධ භාෂ කතා කරන ඉන්දියානු ඒකාබද්ධතාව වී එය ජාතිකානුරාග හැඟී ඇතිවීම හේතුව විය . ් හුදෙකලා තිබ ඉන්දියා බ්\\u200dරිතාන්\\u200dය කරන ලද යටිත පහසුක අප සියල්ලෝ ඉන්දියානුවෝ හැඟී ඉන්දියා ජාතික විය . යම් බ්\\u200dරිතාන්\\u200dය ඉන්දිය පුරාවිද්\\u200dයාත් කැණ සිදුකර මතු කරන ලද ඉන්දිය පැරණි විභූත දැක ඉන්දියානු ප්\\u200dරබෝධය විය.',\n",
              " 'ප්\\u200dරංශ යාන්ත්\\u200dරිකෝණ පද වූ භාණ්ඩවල අත නිපදව තත්ත්ව උසස භාණ්ඩවල තිබ මහජ කැමැත්ත ප්\\u200dරංශ අනුගමන කළ අභ්\\u200dයන්තර තීර පොද ක්\\u200dරම හේතු කාර්මික විප්ලව එංගලන්ත අනි යුරෝප රට අසාර්ථක විය',\n",
              " 'කාර්මික විප්ලව ලොව ප්\\u200dරවාහ කටයුත සීඝ්\\u200dර සංවර්ධනයක පත්වී සාගර ප්\\u200dරවාහ ක්ෂේත්\\u200dර කැප පෙනෙ . 1807 රොබට පොල්ට වාෂ්පෑන්ජිම උපයෝග කරගනි ද බෝට්ට නිපදවීම ඉන්පස ක්\\u200dරිස්ත වර්ෂ 1811 හෙන්රි බෙල දුම්නැ නිපදවීම සාගර ප්\\u200dරවාහ කටයුත සීඝ්\\u200dර සංවර්ධනයක හේතුවියහ . ඉන්පස ප්\\u200dරමාණ විශා නැ සාගර ප්\\u200dරවාහනය යොද ගැනී සිදුව එමඟ රට විශා භාණ්ඩ හුවමාර විය . කාර්මික විප්ලව ලොව ප්\\u200dරවාහ කටයුත සීඝ්\\u200dර සංවර්ධනය ගොඩබි ප්\\u200dරවාහනය දා විය . මැකඩ ක්\\u200dරම භාවිත මාර්ග තැනී සිදුව',\n",
              " 'පුනර්ාවර්ත ප්\\u200dරාග්ද වේ',\n",
              " 'ශ\\u200d්\\u200dර ලං විදුලි සංදේශ නියාම කොමිෂ',\n",
              " 'සතියක වර',\n",
              " 'බොල ණය ආයෝජ ඇතිව හැ අලාභ අන්තර ග\\u200d්\\u200dරහණ කර ගැන හැකියා පෙන්න් කරන මිණුම',\n",
              " 'භාණ්ඩාගාර බිල්ප භාණ්ඩාගාර බැඳුම්කර ගනුදෙ හිමික පි',\n",
              " 'පවුල පෝෂණ ඉහළ නැංවී 2 . පවුල දෛනික ජීව වියද අඩු කිරී',\n",
              " 'ගනුදෙ අවදාන 2 . පරිවර්තක අවදාන',\n",
              " 'සුරැකුම්ප විනිම කොමිෂ සභා',\n",
              " 'udi 03\" udi 06\" wjqreÿ 01',\n",
              " 'භාණ්ඩාගාර බිල්ප',\n",
              " 'එක්ස ජනපද, මෙක්\\u200dෂිකෝ, කැනඩා',\n",
              " 'ශ\\u200d්\\u200dර ලං බැංකුව',\n",
              " 'දේශ භාණ්ඩාගාර බිල්ප ආඥා පනත ලියාපදිංචි ස්කන්ධ සුරැකුම්ප ආඥා පනත',\n",
              " 'අවුරුද 75.1',\n",
              " 'ඇඩ ස්මි',\n",
              " 'ආදාය අසමානතාව',\n",
              " 'පිටකොට, වැල්ලවත්ත, මරදා',\n",
              " 'ශ\\u200d්\\u200dර ලං සංවර්ධ බැඳුම්කර',\n",
              " 'කොටස බලපත\\u200d්\\u200dර',\n",
              " 'ශ\\u200d්\\u200dර ලං මහබැංක, රජය සතු විදේශ විනිම',\n",
              " 'රොන මෙල මහත',\n",
              " '1981',\n",
              " 'රොබට ජේ . මිලර, ඉයුජ එෆ් . ෆැම, ලාස්ට පීටර හැන්ස',\n",
              " 'ආචාර් මන් මෝහ සිං',\n",
              " 'ජෝ එක්ස්ටර මහත',\n",
              " 'ලයනල රොබින්ස',\n",
              " 'නිර්ලේඛ සුරැකුම්ප',\n",
              " 'ශ\\u200d්\\u200dර ලං බැංක',\n",
              " 'බැංක අධිප',\n",
              " 'භාණ්ඩාගාර බිල්ප',\n",
              " 'ශ\\u200d්\\u200dර ලං ආර්ථික ඉතිහාස කෞතුකාගාර',\n",
              " 'බැං අධීක්\\u200dෂණ දෙපාර්තමේන්ත බැං නොව මූල්\\u200d ආයත අධීක්\\u200dෂණ දෙපාර්තමේන්ත',\n",
              " 'දිය සලක, වර්ණ ගැන්ව කො, ආරක්\\u200dෂක නූල, විනිවි පෙනෙ සලක, කුඩ අක්\\u200dෂර,',\n",
              " 'ප\\u200d්\\u200dරසා කොටස නිකුතුව',\n",
              " '19]',\n",
              " 'ජන සංඛ්\\u200dයාලේඛ දෙපාර්තමේන්ත',\n",
              " 'දවස ඕනෑ වෙලා මුදල ලබා ගැන හැකියා, ගිණ ශේෂ දැන ගැනී',\n",
              " 'මහජන සතු බැං සතු මුදල (කාසි නෝට්ට *, බැං මහබැංක පව ගෙන සංචිත',\n",
              " 'රාජ්\\u200d සුරැකුම්ප මධ්\\u200dය තැන්පත ක\\u200d්\\u200dරම',\n",
              " 'ශ\\u200d්\\u200dර ලං රක්\\u200dෂණ මණ්ඩල',\n",
              " 'වරණ කොටස නිශ්චිත ලාභාංශ ප\\u200d්\\u200dරතිශතය ගෙ',\n",
              " '7',\n",
              " 'ඉදිරි ගිවිසුම',\n",
              " '1952',\n",
              " 'බදු',\n",
              " 'ජංග ගිණ පව ගැන බලය හි ව වාණිජ බැං වලට පමණ වීම',\n",
              " 'ලන්ඩ අන්තර්ජාතික බැං අර්පණ අනුපාත',\n",
              " 'ප\\u200d්\\u200dරථමික අලෙවිකරු හෝ ප\\u200d්\\u200dරාථමික අලෙවි නියෝජිතය, නියෝජිතය 15',\n",
              " '9 කි',\n",
              " 'ලං ක්ලියර (පුද්ගලික * සමාග',\n",
              " 'අපරාධ පරීක්\\u200dෂණ දෙපාර්තමේන්ත',\n",
              " '1988 අංක 30 දරණ බැං පනත',\n",
              " '6 (5',\n",
              " 'සේ අර්ථ සාධක අරමුද කළමනාකරණ',\n",
              " 'රජ සුරැකුම්ප මධ්\\u200dය තැන්පත ක\\u200d්\\u200dරම',\n",
              " 'ව්\\u200dයවහාර මුදල මණ්්ඩ ක\\u200d්\\u200dරම',\n",
              " 'කල් පිර දිනයේ ලබා ගත හැක',\n",
              " 'චන්ද්\\u200dරි බණ්ඩාරනා කුමාරතුංග මැතිණ',\n",
              " 'චානක්\\u200d, කෞටිල්\\u200d, විෂ්ණ ගුප්ත',\n",
              " 'ධනවාද අර්ථ ක\\u200d්\\u200dරම',\n",
              " '2005 අංක 28 දරණ ගෙව පියව පද්ධ පනත',\n",
              " 'අපනය සංවර්ධ මණ්ඩල',\n",
              " 'ප\\u200d්\\u200dරාථමික අලෙවිකරුවන්',\n",
              " 'දළ ජාතික නිෂ්පාදිත',\n",
              " 'පඩි පාලක සභා',\n",
              " 'අරමුදල කළමනාකරණ සමාග හෝ අරමුදල කළමනාකරු,, ඒකක භාරකර,, ඒකක හිම,',\n",
              " 'තත්කාලී දළ පියව පද්ධත, ලං සෙක්\\u200dය',\n",
              " 'මධ්\\u200dය තැන්පත ක\\u200d්\\u200dරම',\n",
              " 'කාගීස්ල බැංක',\n",
              " 'කොළඹ පාරිභෝගික මිල දර්ශක',\n",
              " 'මිල්ට ෆ\\u200d්\\u200dරීඞ්ම',\n",
              " 'ලැස්ප ියර ක\\u200d්\\u200dරම',\n",
              " 'සියල කොටස මිල දර්ශක',\n",
              " 'මිල්ට ෆ\\u200d්\\u200dරීඞ්ම',\n",
              " 'පොල ආදාය',\n",
              " 'ගැන හිමික',\n",
              " 'ුදල ප \\u200d්\\u200dරතිපත්ත',\n",
              " 'ඇල්ෆ \\u200d්\\u200dරඞ නොබෙ',\n",
              " 'ජන සංඛ්\\u200d ලේඛ දෙපාර්තමේ ්ත',\n",
              " 'ුදල ක\\u200d්\\u200dරමසම්පාද අමාත්\\u200dයංශ',\n",
              " 'ඇමෙරි එක්ස ජනපද',\n",
              " 'ජෝ මේනාඞ කේන්ස',\n",
              " 'චීන',\n",
              " '2011 අංක 42 දරණ මුදල ව්\\u200dයාප පනත යටත',\n",
              " 'ුරැකුම්ප නික ුත් කිරීමෙ ් අනතුර අපේක්\\u200dෂිත ුළු වටිනාක ලැබෙ වෙන්දේස විවෘත තැබී',\n",
              " 'පුදග ආදාය පොල ආදාය',\n",
              " 'ස්වීඩන රික ්ස් බැංක',\n",
              " 'ශ\\u200d්\\u200dරි ලං ආයෝජ මණ්ඩල',\n",
              " 'මාස 6 කට වරක ්',\n",
              " 'ඉන්දියා',\n",
              " 'වාණිජ බැංකුවල ජංග ගිණ පවත්වාගෙ යා අයිත හිමිවී',\n",
              " 'කාල මාක්ස',\n",
              " 'ඇමෙරි එක්ස ජනපද වොෂිංට',\n",
              " 'යුරෝප බැංක',\n",
              " '1969',\n",
              " '1944',\n",
              " 'චීන මහජ බැංක',\n",
              " 'අප\\u200d්\\u200dරිකා',\n",
              " 'රෝයල මිස්ට',\n",
              " 'අතුර සම්මත ගිණු',\n",
              " 'දේශ ණය මූලාශ\\u200d්\\u200dර විදේශ ණය මූලාශ\\u200d්\\u200dර',\n",
              " 'ෆෙඩරල සංචිත ක\\u200d්\\u200dරම',\n",
              " '42 කි',\n",
              " 'ප\\u200d්\\u200dරාථමික වෙළඳපොළ',\n",
              " 'ජේ . ආර් . ජයවර්ධ මහත',\n",
              " 'ආර්ථීක මිල ස්ථායීතාව පව ගැනී',\n",
              " '11 කි',\n",
              " 'ගෙව තුලන',\n",
              " 'ප\\u200d්\\u200dරාථමික වෙන්දේසි මිලද ගත් බිල්ප බැඳුම්කර,',\n",
              " '1953 දරණ විනිම පාල පනත',\n",
              " 'ඇමෙරි එක්ස ජනපද වොෂිංට නුවර',\n",
              " 'ඬේව්ඞ රිකාඩ',\n",
              " '2005 අංක 28 දරණ ගෙව පියව පද්ධ පනත',\n",
              " '1945 වසර',\n",
              " 'පාර්ලිමේන්ත',\n",
              " 'එංගලන්ත හයව ජෝර්ජ රජ්ු රූප',\n",
              " 'බංග්ලාදේශ මොහොමඞ යුසූෆ',\n",
              " '2006 අංක 6 දරණ මූල්\\u200d ගනුදෙ වාර්තාකරණ පනත',\n",
              " 'මුදල ක\\u200d්\\u200dර සම්පාද අමාත්\\u200dයංශ විදේශ සම්ප දෙපාර්තමේන්ත',\n",
              " 'ගනුදෙන කළ මොහොතේ එය සිද',\n",
              " '20% කි',\n",
              " 'ලං ක්ලියර ආයතන',\n",
              " 'ආර්ථික අවපාතය',\n",
              " 'මුදල ක\\u200d්\\u200dර ශක්ත අඩු වීම,, ඉතිරිකිර අධෙර්යම කිරී,, අනාගත සැලස අපහස වීම,, ඵලදාය ආයත  ඵලදාය නොව ආයෝජ වලට විතැ වීම,, ආනය දිරිම වීම,, අපනය අධෙර්යම වීම,',\n",
              " 'ජන ලේඛ සංඛ්\\u200d ලේඛ දෙපාර්තමේන්ත',\n",
              " 'කර්මාන්ත අංශය',\n",
              " 'රුසියා',\n",
              " 'ස්ව්ට්සර්ලන්ත ජීනී නුවර',\n",
              " 'පිරමීඩ යෝජ ක\\u200d්\\u200dරම',\n",
              " '1947',\n",
              " 'බෙල්ජිය',\n",
              " 'රුපියල බිලිය 1',\n",
              " '2500 බුද්ධ ජයන්ත සැමරී',\n",
              " 'මියැන්මාර නේජිංට නගර',\n",
              " 'ලෝක වෙළඳ සංවිධාන',\n",
              " '1875',\n",
              " 'ප\\u200d්\\u200dරාථමික වෙළඳ,, වාණිජ බැංක,, සේ අර්ථ සාධක අරමුද',\n",
              " 'ආර්ථීක මිල ස්ථායීතාව පව ගැනී,, මූල්\\u200d ක\\u200d්\\u200dරම ස්ථායීතාව පව ගැනී',\n",
              " '1966',\n",
              " 'ශ\\u200d්\\u200dර ලං බැංක',\n",
              " 'බලපත\\u200d්\\u200dරලාභි බැං,, බලපත\\u200d්\\u200dරලාභ මූල්\\u200d සමාග',\n",
              " 'බලපත\\u200d්\\u200dරලාභ විශේෂිත බැංකුවක ජංග ගිණූ පව ගත නොහැ',\n",
              " 'ශ\\u200d්\\u200dර ලං බැංක රාජ්\\u200dය ණය කළමනාකරණ දෙපාර්තමේන්ත',\n",
              " 'ශ\\u200d්\\u200dර ලං බැංක',\n",
              " '03 කි',\n",
              " 'රාජ්\\u200d මූල්\\u200d වගක කළමනාකරණ පනත,',\n",
              " 'ඇෆ්ගනිස්ථාන, භූතාන, බංග්ලාදේශ, ඉන්දියා, නේපාල',\n",
              " 'ශ\\u200d්\\u200dර ලං බැංකු',\n",
              " 'චීන',\n",
              " 'එක්ස ජාතී සංවිධාන',\n",
              " 'අදාළ ආයත වලට නොගොස විදුලි බිල,, ජල බිල,, දුරකත බිල බිල්ප ලැබීම හැ වීම \\uf0d8 මාස කාලය පොල අය නොකිරී \\uf0d8 කාල මුදල ගැනීම වියද අඩු වීම \\uf0d8 ඕනෑ ප\\u200d්\\u200dරදේශයකද ගනුදෙ ගෙවීම හෝ මුදල ලබා ගැනීම යොදාගත හැ වීම',\n",
              " 'නිත්\\u200d ණය පහසුක අනුපාත',\n",
              " '2001',\n",
              " ', ාර්ථික ව්\\u200dයාපාරික පරිසර \\uf0d8 ජන ජීවිත යහ පැවැත් \\uf0d8 සමාජ ආර්ථික යටිත පහසුක',\n",
              " 'එක්ස රාජධා, ස්වීඩන, ඩෙන්මාර්ක',\n",
              " '2000 $2007',\n",
              " 'ස්වෛරිත් බැඳුම්කර නිකු කිරී',\n",
              " 'රුපියල 200,000',\n",
              " 'wdodhï l% uh\" úhoï l% uh\" ksiamdok l% uh',\n",
              " 'ජනලේඛ සංඛ්\\u200dයාලේඛ දෙපාර්තමේන්ත',\n",
              " 'විදේශ විනිම අනුපාත',\n",
              " 'රුපියල 10 රුපියල 1000',\n",
              " 'තෝමස රොබට මැල්තස',\n",
              " '1988 අංක 30 දරණ බැං පනත',\n",
              " 'ලෝක බැංක',\n",
              " 'පාවෙ විනිම අනුපාත ක\\u200d්\\u200dරම',\n",
              " 'ලං බැංක',\n",
              " 'ඇරිස්ටෝටල',\n",
              " 'අර්ව ෆීෂර',\n",
              " 'අපේ පොද අනාගත (බෲට්ලන්ඞ වාර්තා',\n",
              " '2011 අංක 42 දරණ මුදල ව්\\u200dයාපාර පනත',\n",
              " '205 අංක 28 දරණ බේර කිර පද්ධ පනත',\n",
              " '2012',\n",
              " 'බංග්ලාදේශ,, භූතාන,, ඉන්දියා,, හ\\u200d්\\u200dර ලංකා,, නේපාල,, මියන්මාර,, තායිලන්ත',\n",
              " 'විසර්ජ පනත',\n",
              " 'මුදල ඇම මහබැංක අධිප',\n",
              " 'මුදල වර්ෂ අවසන් මාස 04 ඇතුළත',\n",
              " 'ති සලක',\n",
              " 'පිලීපීන මැන නුවර',\n",
              " 'රුපියල 02',\n",
              " 'එක් දිනය',\n",
              " 'පොද රාජ්\\u200d මණ්ඩල රාජ නා සමුළ ශ\\u200d්\\u200dර ලංක පැවැත්වී සැමරී',\n",
              " '2011 ජ මාස',\n",
              " 'සමාගමික ණයකර (බාහිර *,, රඳවාග ලාභ (බාහිර',\n",
              " 'මූලික ප\\u200d්\\u200dරසිද්ධ කොටස නිකුතුව',\n",
              " 'තේ නිෂ්පාදන',\n",
              " 'පතල,, නිෂ්පාද කර්මාන්ත,, සැකස කර්මාන්තශා නිෂ්පාද',\n",
              " 'ඡුයාගත චෙක්ප පිළිබිඹ නිෂ්කාශ පද්ධත',\n",
              " 'රුපියල 1 රුපියල 20',\n",
              " 'රුපියල බිලිය 04',\n",
              " '2002 වර්ෂ',\n",
              " 'නාණක විද්\\u200dයාව/ නාණක ශ\\u200d්\\u200dරාස්ත\\u200d්\\u200dර',\n",
              " 'මාස්ට්\\u200d්\\u200dරට ගිවිසු',\n",
              " 'සහශ\\u200d්\\u200dර සංවර්ධ අභිමතාර්ථ',\n",
              " 'ඇමෙරි එක්ස ජනපද වූ උප .... නිවාස ණය අර්බුද',\n",
              " 'ලෝක බැංක, ජාත්\\u200dයන්තර මූල්\\u200d ආයතන',\n",
              " '1990 අංක 6 දරණ සිවිල නඩු විභාග සංග\\u200d්\\u200dරහ පනත නිර්වචන කර මුදල අයකර ගැනී සම්බන්ධ වූ නීතිම ක\\u200d්\\u200dරියාමාර්ග අදාළ පොලි',\n",
              " 'භාණ්ඩාගාර බිල්ප \\uf0d8 භාණ්ඩාගාර බැඳුම්කර \\uf0d8 ශ\\u200d්\\u200dර ලං සංවර්ධ බැඳුම්කර \\uf0d8 රුපියල ණය \\uf0d8 බැං අයිර පහසුක',\n",
              " 'රුපියල 1 රුපියල 5',\n",
              " '8]',\n",
              " 'මහජ බැංක',\n",
              " 'භාණ්ඩාගාර බැඳුම්කර',\n",
              " 'කොටස වෙළඳපොළ',\n",
              " 'නාවුක,, ගු,, වාණිජ,, බලශක්,, දැනු',\n",
              " 'කිත්සිරිමෙ රජදවස',\n",
              " 'භාතිකාභ',\n",
              " 'ඉලනාග රජතුම',\n",
              " 'නිශ්ශංකමල් (හැටද, රන්ක වෙහෙර, නිශ්ශංකලත මණ්ඩප',\n",
              " 'ඉබන්බතූත',\n",
              " 'තට් රාජාලි',\n",
              " 'ටැන්සානියා',\n",
              " '8 යි',\n",
              " 'ඉතාල',\n",
              " 'චීන රුසියා',\n",
              " 'ඇමරිකා කැනඩා',\n",
              " 'ෂැංග වරා',\n",
              " 'දෙවුන්දර ප\\u200d්\\u200dරදීපාගාර',\n",
              " 'ඔලූවිල ප\\u200d්\\u200dරදීපාගාර',\n",
              " 'සර් හිය ක්ලිෆර්ඞ',\n",
              " 'ඞී.එම්.කොලඹ',\n",
              " '1967',\n",
              " 'නෙවිල ජයවීර',\n",
              " '1956',\n",
              " '1947 ජූ 28',\n",
              " 'ටි.බි . ඉලංගරත් මහත',\n",
              " '1971.01.05 - ඕස්ටේ\\u200d්\\u200dරලියා - එංගලන්ත',\n",
              " '1975 - බටහිර ඉන්ද කොදෙ කැනඩාව එරෙහි',\n",
              " '43 - දක අපි\\u200d්\\u200dරකාව එරෙහි',\n",
              " 'සන ජයසූර - අවස්ථ ගණන 34 කි.',\n",
              " 'ප්\\u200dරොජ බියුටේ',\n",
              " 'ඇලූමිනිය',\n",
              " 'caocl2 කැල්සිය ඔක්සික්ලෝරයිඩි',\n",
              " 'ලෙඩි සල්ෆයිඞ',\n",
              " '1988 - ol=kq fldßhdfõ\" äfhda, a kqjr',\n",
              " 'c¾uksfha\" fndaka kqjr',\n",
              " 'ප\\u200d්\\u200dරදීප සංජ',\n",
              " 'දිනේෂ පි \\u200d්\\u200dරයන්ත හේර - හෙල් විසිකිරී',\n",
              " '400',\n",
              " '1885.03.17 දින බලත ගැසට පත\\u200d්\\u200dර මගි',\n",
              " 'සර් . ආතර හැවිල්ට ගෝර්ඩ',\n",
              " '54 සම්මේලන',\n",
              " 'වීර අලකේක්\\u200dෂ්වර',\n",
              " '1965 ජූලි 26',\n",
              " 'උත්තර ප\\u200d්\\u200dරදේශ',\n",
              " 'රාෂ්ඨ ප\\u200d්\\u200dරාන්තය',\n",
              " 'විජ ලක්\\u200dෂ පන්ඬ',\n",
              " 'නීට අම්බා',\n",
              " 'අරුන්දත රෝස',\n",
              " 'කොළඹ මහනගර සභා',\n",
              " '1865',\n",
              " 'කුෂ්ඨ රාජග',\n",
              " 'රාජාධිරාජසිංහ රජතුම',\n",
              " \"1832'01'30\",\n",
              " '1930',\n",
              " 'ඩි.වි.මේරි රත්න',\n",
              " '1958',\n",
              " '6',\n",
              " 'මේරි රත්න',\n",
              " 'විනෝහ හාය',\n",
              " 'ලූමි සහෝදර',\n",
              " 'ඩි.ඩබ්.ගි\\u200d්\\u200dරවි',\n",
              " 'දිලීප කුමාර මී කුමාරි',\n",
              " 'බේ ලයිට',\n",
              " 'කැල්සිය ඔක්සලේට',\n",
              " 'ජෝ බ\\u200d්\\u200dරවුන',\n",
              " 'මීටර 10,000 - එස්.එල්.බි . රෝස 1975 - ්ර්නපි ඹි විනාඩි 29.18',\n",
              " 'වි.ඒ.සුගතදාස',\n",
              " 'ශී\\u200d්\\u200dරයා කුලවංශ - 1996.07.26 100 කඩුළ මත දිවී',\n",
              " 'තිල ජිනදාස',\n",
              " 'නයිජීරියා',\n",
              " 'බි\\u200d්\\u200dරතාන්\\u200d',\n",
              " 'යුරිවිඩස',\n",
              " 'සොෂොන්ලිස',\n",
              " 'තායිවාන',\n",
              " 'ෂි ෂොරප, ටිවිස්රා රය, යසර අරෆ.',\n",
              " 'මහානා රජ දවස',\n",
              " 'සියබස්ලකර',\n",
              " '1890',\n",
              " '1947 - අනුරාධපුර පුර විද භවන',\n",
              " '1877 ජනවාරි 01',\n",
              " 'සර් විලිය හෙන්රි ග්\\u200dරෙගරි',\n",
              " 'මැඩ තුෂාඞ',\n",
              " 'ඇමර්ස්ටඩෑ, නෙදර්ලන්ත',\n",
              " 'මාරි කියුරි - 1907',\n",
              " 'ජෝ බාර්ඞී',\n",
              " '2007',\n",
              " 'ශී\\u200d්\\u200dර ලං ප ප\\u200d්\\u200dරකාශකයි සංගම',\n",
              " 'වොර නීලි හින්ගට',\n",
              " '1991',\n",
              " 'කැප්ට අලදෙ',\n",
              " 'දියමන්ත',\n",
              " 'පොටෑසිය නයිට්ෙඩි\\u200d්\\u200dරට',\n",
              " 'ගම්පො',\n",
              " 'ගජබ රජ දවස',\n",
              " 'මහස රජ',\n",
              " 'දක්ඛිණ විහාර',\n",
              " 'විලිය ගිල්බට ගේ\\u200d්\\u200dරස',\n",
              " 'හතීෂ මොහොමඞ',\n",
              " 'මීටර 100 සමන ආර',\n",
              " 'කුවේට',\n",
              " 'පුෂ්ප කමල දහාල',\n",
              " 'මාවෝවාදි ගරි කණ්ඩාය',\n",
              " 'මහාචාර් ෘගෑගහෙට්ටි ආරච්චි',\n",
              " '1963',\n",
              " '15',\n",
              " 'සර් ඞී.බී.ජයතිලක',\n",
              " 'සර් ජෝර්ර ටර්ගර 1837',\n",
              " 'සර් විල්හෙල ගයිගර 1912',\n",
              " 'බි\\u200d්\\u200dරටනි විහ් කෝෂ',\n",
              " 'රොබට කවිඩිරි - 1604',\n",
              " 'යුක්රේන',\n",
              " 'ජර්ම',\n",
              " 'වොල්ග නද (කි.මී.3692 *',\n",
              " 'මිසොරි',\n",
              " 'ඩෑග හැමර්ෂ',\n",
              " 'කර්ට වෝල්ඩිහය',\n",
              " 'ජාවියර ෂෙරප ඩි . ක්වෙයිග',\n",
              " 'අටවෙ',\n",
              " 'ටයිකෝන්ඩ',\n",
              " 'දුනුවිදී',\n",
              " 'ජලවිදුලි බලය',\n",
              " 'මුටසි',\n",
              " 'මාලදිවයි',\n",
              " 'මහස රජතුම',\n",
              " 'වළගම්බ රජතුම',\n",
              " 'වසභ රජතුම',\n",
              " 'භුමිතෙල',\n",
              " 'බේරිය',\n",
              " 'කැන්ගර මී',\n",
              " 'ගුණසේ ගලප්පත්',\n",
              " 'සුගතපාල සිල්',\n",
              " 'ජයන් කිරිඋතුම්පා (2016 - මැ',\n",
              " '1802 මාර්ත 15',\n",
              " 'රොබට විලිය හෝර්ට',\n",
              " 'ලං ලෝක 1860.09.10 ගාල්ලේද.',\n",
              " 'මාසික තෑග්ග 1832',\n",
              " 'ලක්මි පහන 1863.09.11',\n",
              " 'උදය තාරග - 1841 - යාපන.',\n",
              " '1896.03.07 - දිනපත ප\\u200d්\\u200dරවෘත්ත',\n",
              " 'ස්වදේශ මිත\\u200d්\\u200dර 1924.07.13',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "detokenized_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chcdUvABFSCV"
      },
      "outputs": [],
      "source": [
        "simplify_characters_dict = {\n",
        "    # Consonant\n",
        "    \"ඛ\": \"ක\",\n",
        "    \"ඝ\": \"ග\",\n",
        "    \"ඟ\": \"ග\",\n",
        "    \"ඡ\": \"ච\",\n",
        "    \"ඣ\": \"ජ\",\n",
        "    \"ඦ\": \"ජ\",\n",
        "    \"ඤ\": \"ඥ\",\n",
        "    \"ඨ\": \"ට\",\n",
        "    \"ඪ\": \"ඩ\",\n",
        "    \"ණ\": \"න\",\n",
        "    \"ඳ\": \"ද\",\n",
        "    \"ඵ\": \"ප\",\n",
        "    \"භ\": \"බ\",\n",
        "    \"ඹ\": \"බ\",\n",
        "    \"ශ\": \"ෂ\",\n",
        "    \"ළ\": \"ල\",\n",
        "\n",
        "    # Vowels\n",
        "    \"ආ\": \"අ\",\n",
        "    \"ඈ\": \"ඇ\",\n",
        "    \"ඊ\": \"ඉ\",\n",
        "    \"ඌ\": \"උ\",\n",
        "    \"ඒ\": \"එ\",\n",
        "    \"ඕ\": \"ඔ\",\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX3yNG2CFBCn"
      },
      "outputs": [],
      "source": [
        "def get_simplified_character(character: str) -> str:\n",
        "    if len(character) != 1:\n",
        "        raise TypeError(\"character should be a string with length 1\")\n",
        "    try:\n",
        "        return simplify_characters_dict[character]\n",
        "    except KeyError:\n",
        "        return character"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h6zI54oE1fz"
      },
      "outputs": [],
      "source": [
        "def simplify_sinhalese_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    simplify\n",
        "    :param text:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    modified_text = \"\"\n",
        "    for c in text:\n",
        "        modified_text += get_simplified_character(c)\n",
        "    return modified_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJp6SrbzEmXE"
      },
      "outputs": [],
      "source": [
        "df['filtered_sentence'] = detokenized_sentences\n",
        "df['filtered_sentence'] = df['filtered_sentence'].apply(simplify_sinhalese_text).tolist()\n",
        "#df['filtered_sentence'] = df['Text'].apply(remove_english_words).tolist()\n",
        "\n",
        "#df.to_csv('SubjectivityTagged.csv')\n",
        "df.to_excel('stem.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygqTibDqHIH7"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUTdcDqaHXEr"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('stem.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOXAmr8FKYWl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c3ed0751-110c-427a-f111-65af3394b2b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ස්ථූප ආකෘති හය මෙසේ නම් කළ හැකිය:\\n\\n1.  ධම්මචෙත්තිය  (Dhammacetiya) - භාෂිත ආකෘතිය\\n2.  සුභූමිචෙත්තිය  (Subhūmicetiya) - පුෂ්ප ආකෘතිය\\n3.  වජ්\\u200dරචෙත්තිය  (Vajiracetiya) - සුල ගොමන ආකෘතිය\\n4.  මනිචෙත්තිය  (Manicetiya) - ස්කන්ධක ආකෘතිය\\n5.  බුද්ධකෙත්තිය  (Buddhaketiya) - වඩුගෙය ආකෘතිය\\n6.  කඨිනචෙත්තිය  (Kaṭhinacetiya) - කොණ්ඩෝටු ආකෘතිය'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "df['Text_cleaned'] = df['Answers'].str.replace('**',' ')\n",
        "df['Text_cleaned'] = df['Text_cleaned'].str.replace('?',' ')\n",
        "\n",
        "df['Text_cleaned'][1188]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWGtQEnNOOX1"
      },
      "outputs": [],
      "source": [
        "# english-sinhala dictionary\n",
        "dictionary = {}\n",
        "df_translate= pd.read_csv('en-sinhala dictionary.csv')\n",
        "dictionary_file = df_translate[\"En,sinhala\"]\n",
        "\n",
        "for line in dictionary_file:\n",
        "    key, value = line.strip().split(\",\")\n",
        "    dictionary[key] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq4TTFpNNU15"
      },
      "outputs": [],
      "source": [
        "# to check whether the string contains English words(any)\n",
        "\n",
        "def translate_english(x):\n",
        "    for word in x.split():\n",
        "        word_cleaned = \"\".join(char for char in word if char not in string.punctuation)  # Remove punctuation\n",
        "        if re.match('[a-zA-Z]', word_cleaned):  # Check if the word contains English letters\n",
        "            word_lower = word_cleaned.lower()  # Convert to lowercase for dictionary lookup\n",
        "            translated_word = dictionary.get(word_lower, '')  # Translate using the dictionary\n",
        "            x = x.replace(word, translated_word)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL9OkWtmOr6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901099db-97cc-4eae-8eb3-9a86bc0ebf90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2006 entries, 0 to 2005\n",
            "Data columns (total 5 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   Unnamed: 0         2006 non-null   int64 \n",
            " 1   Answers            2000 non-null   object\n",
            " 2   Label              2006 non-null   object\n",
            " 3   filtered_sentence  2000 non-null   object\n",
            " 4   Text_cleaned       2000 non-null   object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 78.5+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxXBGZ9MGMp3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "4dd83a45-3f5a-4113-8605-598573cacdb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pandas.core.strings.accessor.StringMethods object at 0x7a1f28ed0c10>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                            Answers  Label  \\\n",
              "0              0                                            රාවණා 1  Human   \n",
              "1              1                                     ලෝන්ලි ප්ලැනට්  Human   \n",
              "2              2                                             වූහාන්  Human   \n",
              "3              3                                              25200  Human   \n",
              "4              4                     ආසියා රග්බී පළමු කාණ්ඩ ශූරතාවය  Human   \n",
              "...          ...                                                ...    ...   \n",
              "2001        2001  ශ්‍රී ලංකාවේ ප්‍රථම සිංහල දිනපතා පුවත්පත වන්නේ...     AI   \n",
              "2002        2002  ශ්‍රී ලංකාවේ ප්‍රථම ඉරිදා පුවත්පත වන්නේ ස්වදේශ...     AI   \n",
              "2003        2003  ශ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව ලෙස සැලකෙන්නේ ...     AI   \n",
              "2004        2004  ශ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව වන \"නිලා\" නිර්...     AI   \n",
              "2005        2005  ඔව්, ශ්‍රී ලංකාවේ නූතන පන්සල් චිත්‍ර කථාවේ පුර...     AI   \n",
              "\n",
              "                                      filtered_sentence  \\\n",
              "0                                                රාවන 1   \n",
              "1                                         ලෝන්ලි ප්ලැනට   \n",
              "2                                                  වූහා   \n",
              "3                                                 25200   \n",
              "4                              අසි රග්බ පල කාන්ඩ ෂූරතාව   \n",
              "...                                                 ...   \n",
              "2001  ලංක ප්‍රථ සිංහ දිනපත පුවත්පත ව * * දිවයි * * ....   \n",
              "2002  ලංක ප්‍රථ ඉරිද පුවත්පත ව ස්වදේෂ මිතෘ (swadesha...   \n",
              "2003  ලංක ප්‍රථ චිත්‍ර කතා සැලකෙ * *\" න\" * * . එය 19...   \n",
              "2004  ලංක ප්‍රථ චිත්‍ර කතා \"න\" නිර්මාන කලේ ප්‍රවීන ච...   \n",
              "2005  ඔව්, ලංක නූත පන්සල චිත්‍ර කථ පුරෝගාමි * * සාර්...   \n",
              "\n",
              "                                           Text_cleaned  \n",
              "0                                               රාවනා 1  \n",
              "1                                        ලෝන්ලි ප්ලැනට්  \n",
              "2                                                වූහාන්  \n",
              "3                                                 25200  \n",
              "4                        අසියා රග්බී පලමු කාන්ඩ ෂූරතාවය  \n",
              "...                                                 ...  \n",
              "2001  ෂ්‍රී ලංකාවේ ප්‍රථම සිංහල දිනපතා පුවත්පත වන්නේ...  \n",
              "2002  ෂ්‍රී ලංකාවේ ප්‍රථම ඉරිදා පුවත්පත වන්නේ ස්වදේෂ...  \n",
              "2003  ෂ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව ලෙස සැලකෙන්නේ ...  \n",
              "2004  ෂ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව වන නිලා නිර්මා...  \n",
              "2005  ඔව් ෂ්‍රී ලංකාවේ නූතන පන්සල් චිත්‍ර කථාවේ පුරෝ...  \n",
              "\n",
              "[1991 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86ebe8a2-db7d-4d19-8c38-e32104b8316d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Answers</th>\n",
              "      <th>Label</th>\n",
              "      <th>filtered_sentence</th>\n",
              "      <th>Text_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>රාවණා 1</td>\n",
              "      <td>Human</td>\n",
              "      <td>රාවන 1</td>\n",
              "      <td>රාවනා 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ලෝන්ලි ප්ලැනට්</td>\n",
              "      <td>Human</td>\n",
              "      <td>ලෝන්ලි ප්ලැනට</td>\n",
              "      <td>ලෝන්ලි ප්ලැනට්</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>වූහාන්</td>\n",
              "      <td>Human</td>\n",
              "      <td>වූහා</td>\n",
              "      <td>වූහාන්</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>25200</td>\n",
              "      <td>Human</td>\n",
              "      <td>25200</td>\n",
              "      <td>25200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ආසියා රග්බී පළමු කාණ්ඩ ශූරතාවය</td>\n",
              "      <td>Human</td>\n",
              "      <td>අසි රග්බ පල කාන්ඩ ෂූරතාව</td>\n",
              "      <td>අසියා රග්බී පලමු කාන්ඩ ෂූරතාවය</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001</th>\n",
              "      <td>2001</td>\n",
              "      <td>ශ්‍රී ලංකාවේ ප්‍රථම සිංහල දිනපතා පුවත්පත වන්නේ...</td>\n",
              "      <td>AI</td>\n",
              "      <td>ලංක ප්‍රථ සිංහ දිනපත පුවත්පත ව * * දිවයි * * ....</td>\n",
              "      <td>ෂ්‍රී ලංකාවේ ප්‍රථම සිංහල දිනපතා පුවත්පත වන්නේ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002</th>\n",
              "      <td>2002</td>\n",
              "      <td>ශ්‍රී ලංකාවේ ප්‍රථම ඉරිදා පුවත්පත වන්නේ ස්වදේශ...</td>\n",
              "      <td>AI</td>\n",
              "      <td>ලංක ප්‍රථ ඉරිද පුවත්පත ව ස්වදේෂ මිතෘ (swadesha...</td>\n",
              "      <td>ෂ්‍රී ලංකාවේ ප්‍රථම ඉරිදා පුවත්පත වන්නේ ස්වදේෂ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003</th>\n",
              "      <td>2003</td>\n",
              "      <td>ශ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව ලෙස සැලකෙන්නේ ...</td>\n",
              "      <td>AI</td>\n",
              "      <td>ලංක ප්‍රථ චිත්‍ර කතා සැලකෙ * *\" න\" * * . එය 19...</td>\n",
              "      <td>ෂ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව ලෙස සැලකෙන්නේ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004</th>\n",
              "      <td>2004</td>\n",
              "      <td>ශ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව වන \"නිලා\" නිර්...</td>\n",
              "      <td>AI</td>\n",
              "      <td>ලංක ප්‍රථ චිත්‍ර කතා \"න\" නිර්මාන කලේ ප්‍රවීන ච...</td>\n",
              "      <td>ෂ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව වන නිලා නිර්මා...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005</th>\n",
              "      <td>2005</td>\n",
              "      <td>ඔව්, ශ්‍රී ලංකාවේ නූතන පන්සල් චිත්‍ර කථාවේ පුර...</td>\n",
              "      <td>AI</td>\n",
              "      <td>ඔව්, ලංක නූත පන්සල චිත්‍ර කථ පුරෝගාමි * * සාර්...</td>\n",
              "      <td>ඔව් ෂ්‍රී ලංකාවේ නූතන පන්සල් චිත්‍ර කථාවේ පුරෝ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1991 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86ebe8a2-db7d-4d19-8c38-e32104b8316d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-86ebe8a2-db7d-4d19-8c38-e32104b8316d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-86ebe8a2-db7d-4d19-8c38-e32104b8316d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-217afc01-3186-46f4-ba37-b761eaa4c723\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-217afc01-3186-46f4-ba37-b761eaa4c723')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-217afc01-3186-46f4-ba37-b761eaa4c723 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2da3de53-223c-4202-85a1-b6c695925d00\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2da3de53-223c-4202-85a1-b6c695925d00 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1991,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 579,\n        \"min\": 0,\n        \"max\": 2005,\n        \"num_unique_values\": 1991,\n        \"samples\": [\n          898,\n          1685,\n          417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1990,\n        \"samples\": [\n          \"\\u0dc3\\u0dbb\\u0dca. \\u0d86\\u0dad\\u0dbb\\u0dca \\u0dc4\\u0dd0\\u0dc0\\u0dd2\\u0dbd\\u0dca\\u0da7\\u0db1\\u0dca \\u0d9c\\u0ddd\\u0dbb\\u0dca\\u0da9\\u0db1\",\n          \"\\u0d89\\u0db1\\u0dca\\u0daf\\u0dd2\\u0dba\\u0dcf\\u0dc0\\u0dda \\u0d85\\u0d9c\\u0db8\\u0dd0\\u0dad\\u0dd2 \\u0db0\\u0dd4\\u0dbb\\u0dba\\u0da7 \\u0daf\\u0dd9\\u0dc0\\u0dbb\\u0d9a\\u0dca\\u0db8 \\u0db4\\u0dad\\u0dca \\u0dc0\\u0dd6 \\u0d89\\u0db1\\u0dca\\u0daf\\u0dd3\\u0dba \\u0db8\\u0dc4 \\u0db6\\u0dd0\\u0d82\\u0d9a\\u0dd4\\u0dc0\\u0dda \\u0dc4\\u0dd2\\u0da7\\u0db4\\u0dd4 \\u0d85\\u0db0\\u0dd2\\u0db4\\u0dad\\u0dd2\\u0dc0\\u0dbb\\u0dba\\u0dcf \\u0dc0\\u0db1\\u0dca\\u0db1\\u0dda **\\u0db8\\u0db1\\u0ddd\\u0dc4\\u0dbb\\u0dca \\u0dc3\\u0dd2\\u0db1\\u0dca\\u0dc4\\u0dca** (Manmohan Singh) \\u0db8\\u0dc4\\u0dad\\u0dcf\\u0dba. 2004 \\u0dc3\\u0dd2\\u0da7 2014 \\u0daf\\u0d9a\\u0dca\\u0dc0\\u0dcf \\u0d89\\u0db1\\u0dca\\u0daf\\u0dd3\\u0dba \\u0d85\\u0d9c\\u0db8\\u0dd0\\u0dad\\u0dd2 \\u0db0\\u0dd6\\u0dbb\\u0dba \\u0daf\\u0dbb\\u0db1 \\u0d94\\u0dc4\\u0dd4, 1982 \\u0dc3\\u0dd2\\u0da7 1985 \\u0daf\\u0d9a\\u0dca\\u0dc0\\u0dcf \\u0d89\\u0db1\\u0dca\\u0daf\\u0dd3\\u0dba \\u0db8\\u0dc4 \\u0db6\\u0dd0\\u0d82\\u0d9a\\u0dd4\\u0dc0\\u0dda \\u0d85\\u0db0\\u0dd2\\u0db4\\u0dad\\u0dd2\\u0dc0\\u0dbb\\u0dba\\u0dcf \\u0dbd\\u0dd9\\u0dc3 \\u0d9a\\u0da7\\u0dba\\u0dd4\\u0dad\\u0dd4 \\u0d9a\\u0dc5\\u0dda\\u0dba.\",\n          \"\\u0da2\\u0dd9\\u0dbb\\u0dd4\\u0dc3\\u0dbd\\u0db8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"AI\",\n          \"Human\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filtered_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1984,\n        \"samples\": [\n          \"\\u0db8\\u0dbd\\u0dca\\u0dc0\\u0dad \\u0d94\\u0dba \\u0d85\\u0dc2\\u0dca\\u200d\\u0dbb\\u0dd2\\u0dad \\u0da2\\u0db1\\u0dcf\\u0dc0\\u0dcf\\u0dc3 \\u0db4\\u0dd2\\u0dc4\\u0dd2\\u0da7 \\u0d9c\\u0dad\\u0dca\\u0dad \\u0d8b\\u0db4\\u0dad\\u0dd2\\u0dc3\\u0dca\\u0dc3 \\u0d87\\u0db8\\u0dad\",\n          \"\\u0da2\\u0dd2\\u0dbb\\u0dcf\\u0dc6 \\u0da2\\u0dcf\\u0dad\\u0dd2\\u0d9a \\u0dc3\\u0dad\\u0dca\\u0dc0 * * \\u0da7\\u0dd0\\u0db1\\u0dca\\u0dc3\\u0dcf\\u0db1\\u0dd2\\u0dba * * \\u0da2\\u0dcf\\u0dad\\u0dd2\\u0d9a \\u0dc3\\u0dad \\u0d9a\\u0dd9\\u0db1\\u0dd9.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1991,\n        \"samples\": [\n          \"18850317 \\u0dc0\\u0db1 \\u0daf\\u0dd2\\u0db1 \\u0db6\\u0dbd\\u0dad\\u0dbd \\u0d9c\\u0dd0\\u0dc3\\u0da7\\u0dca \\u0db4\\u0dad\\u200d\\u0dca\\u200d\\u0dbb\\u0dba \\u0db8\\u0d9c\\u0dd2\\u0db1\",\n          \"2013 \\u0dc0\\u0dc3\\u0dbb\\u0dda \\u0d85\\u0dbb\\u0dca\\u0dae\\u0dd2\\u0d9a \\u0dc0\\u0dd2\\u0daf\\u0dca\\u200d\\u0dba\\u0dcf\\u0dc0 \\u0dc3\\u0daf\\u0dc4\\u0dcf \\u0db1\\u0ddc\\u0db6\\u0dd9\\u0dbd\\u0dca \\u0dad\\u0dca\\u200d\\u0dba\\u0dcf\\u0d9c\\u0dba\\u0dd9\\u0db1\\u0dca \\u0db4\\u0dd2\\u0daf\\u0dd4\\u0db8\\u0dca \\u0dbd\\u0dd0\\u0db6\\u0dd6 \\u0d85\\u0dbb\\u0dca\\u0dae\\u0dd2\\u0d9a \\u0dc0\\u0dd2\\u0daf\\u0dca\\u200d\\u0dba\\u0dcf\\u0da5\\u0dba\\u0db1\\u0dca \\u0dbd\\u0dd9\\u0dc3  \\u0d85\\u0dbb\\u0dca\\u0db1\\u0da7\\u0dca \\u0dc2\\u0dd2\\u0dbd\\u0dbb\\u0dca  \\u0d89\\u0d82\\u0d9c\\u0dca\\u200d\\u0dbb\\u0dd3\\u0dc3\\u0dd2 \\u0dc4\\u0ddd\\u0da9\\u0dd2\\u0dba\\u0dda \\u0daf\\u0dc4\\u0dc0\\u0dd9\\u0db1\\u0dd2 \\u0d85\\u0d9a\\u0dd4\\u0dbb    \\u0dba\\u0dd4\\u0da2\\u0dd3\\u0db1\\u0dca \\u0dc6\\u0dcf\\u0db8\\u0dcf  \\u0dc3\\u0d82\\u0d9c\\u0dd3\\u0dad\\u0dba\\u0dd9\\u0dc4\\u0dd2 \\u0dc3\\u0dca\\u0dc0\\u0dbb\\u0dba\\u0d9a\\u0dca \\u0dc3\\u0d82\\u0d9c\\u0dd3\\u0dad\\u0dba\\u0dd9\\u0dc4\\u0dd2 \\u0dc3\\u0dca\\u0dc0\\u0dbb\\u0dba\\u0d9a\\u0dcaama  \\u0dc3\\u0dc4  \\u0dbd\\u0dcf\\u0dbb\\u0dca\\u0dc3\\u0dca \\u0db4\\u0dd3\\u0da7\\u0dbb\\u0dca \\u0dc4\\u0db1\\u0dca\\u0dc3\\u0db1\\u0dca  \\u0d9a\\u0dca\\u200d\\u0dbb\\u0db8\\u0dba\\u0dd9\\u0db1\\u0dca \\u0d85\\u0da9\\u0dd4\\u0dc0\\u0dd3 \\u0dba\\u0db1\\u0dc0\\u0dcf   \\u0db1\\u0db8\\u0dca \\u0dad\\u0dd2\\u0daf\\u0dd9\\u0db1\\u0dcf \\u0db4\\u0dd2\\u0daf\\u0dd4\\u0db8\\u0dca \\u0dbd\\u0dd0\\u0db6\\u0dd6\\u0dc4 \\u0d94\\u0dc0\\u0dd4\\u0db1\\u0dca\\u0da7 \\u0db8\\u0dd9\\u0db8 \\u0dad\\u0dca\\u200d\\u0dba\\u0dcf\\u0d9c\\u0dba \\u0dc4\\u0dd2\\u0db8\\u0dd2\\u0dc0\\u0dd6\\u0dba\\u0dda \\u0d85\\u0dbb\\u0dca\\u0dae\\u0dd2\\u0d9a \\u0dc0\\u0dd9\\u0dbd\\u0daf\\u0db4\\u0ddc\\u0dbd \\u0dc3\\u0dc4 \\u0daf\\u0dda\\u0db4\\u0dbd \\u0db8\\u0dd2\\u0dbd \\u0dc3\\u0db8\\u0dca\\u0db6\\u0db1\\u0dca\\u0db0\\u0dba\\u0dd9\\u0db1\\u0dca \\u0dc3\\u0dd2\\u0daf\\u0dd4\\u0d9a\\u0dbd \\u0db4\\u0dbb\\u0dca\\u0dba\\u0dda\\u0dc2\\u0db1 \\u0dc3\\u0daf\\u0dc4\\u0dcf\\u0dba\\u0dd2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "\n",
        "def clean_data(dataframe):\n",
        "    # Drop duplicate rows\n",
        "    dataframe.drop_duplicates(subset='Answers', inplace=True)\n",
        "\n",
        "    #punctuation removal\n",
        "    string_text = dataframe['Text_cleaned'].str\n",
        "    dataframe['Text_cleaned'] = string_text.translate(str.maketrans('', '', string.punctuation))\n",
        "    print(string_text)\n",
        "\n",
        "    # coerced entire coloumn to str dtype\n",
        "    dataframe['Text_cleaned'] = dataframe['Text_cleaned'].astype(str)\n",
        "\n",
        "    #translate English to sinhala\n",
        "    df['Text_cleaned'] = df['Text_cleaned'].apply(translate_to_sinhala).tolist()\n",
        "    df['Text_cleaned'] = df['Text_cleaned'].apply(translate_english).tolist()\n",
        "\n",
        "    # simplify sinhala characters\n",
        "    df['Text_cleaned'] = df['Text_cleaned'].apply(simplify_sinhalese_text).tolist()\n",
        "\n",
        "    # pos tagging\n",
        "    #df['Text'] = df['Text'].apply(tagger.predict).tolist()\n",
        "\n",
        "    #print(\"New shape:\", dataframe.shape)\n",
        "    return dataframe.head()\n",
        "\n",
        "clean_data(df)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCeHxGkTGMm-"
      },
      "outputs": [],
      "source": [
        "df.to_excel('clean.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0OAXoM6GMkl"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(how='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdcs3H2qGMiM"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.to_excel('clean.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_CNfgn_GMfr"
      },
      "outputs": [],
      "source": [
        "# Convert 'Labels' column to 0 and 1\n",
        "df['Label'] = df['Label'].map({'Human': 0, 'AI': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6usxEQSLGMc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "fa2cd4c8-8cbb-4b24-81d9-1015408be529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "1    999\n",
            "0    992\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                            Answers  Label  \\\n",
              "0              0                                            රාවණා 1      0   \n",
              "1              1                                     ලෝන්ලි ප්ලැනට්      0   \n",
              "2              2                                             වූහාන්      0   \n",
              "3              3                                              25200      0   \n",
              "4              4                     ආසියා රග්බී පළමු කාණ්ඩ ශූරතාවය      0   \n",
              "...          ...                                                ...    ...   \n",
              "2001        2001  ශ්‍රී ලංකාවේ ප්‍රථම සිංහල දිනපතා පුවත්පත වන්නේ...      1   \n",
              "2002        2002  ශ්‍රී ලංකාවේ ප්‍රථම ඉරිදා පුවත්පත වන්නේ ස්වදේශ...      1   \n",
              "2003        2003  ශ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව ලෙස සැලකෙන්නේ ...      1   \n",
              "2004        2004  ශ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව වන \"නිලා\" නිර්...      1   \n",
              "2005        2005  ඔව්, ශ්‍රී ලංකාවේ නූතන පන්සල් චිත්‍ර කථාවේ පුර...      1   \n",
              "\n",
              "                                      filtered_sentence  \\\n",
              "0                                                රාවන 1   \n",
              "1                                         ලෝන්ලි ප්ලැනට   \n",
              "2                                                  වූහා   \n",
              "3                                                 25200   \n",
              "4                              අසි රග්බ පල කාන්ඩ ෂූරතාව   \n",
              "...                                                 ...   \n",
              "2001  ලංක ප්‍රථ සිංහ දිනපත පුවත්පත ව * * දිවයි * * ....   \n",
              "2002  ලංක ප්‍රථ ඉරිද පුවත්පත ව ස්වදේෂ මිතෘ (swadesha...   \n",
              "2003  ලංක ප්‍රථ චිත්‍ර කතා සැලකෙ * *\" න\" * * . එය 19...   \n",
              "2004  ලංක ප්‍රථ චිත්‍ර කතා \"න\" නිර්මාන කලේ ප්‍රවීන ච...   \n",
              "2005  ඔව්, ලංක නූත පන්සල චිත්‍ර කථ පුරෝගාමි * * සාර්...   \n",
              "\n",
              "                                           Text_cleaned  \n",
              "0                                               රාවනා 1  \n",
              "1                                        ලෝන්ලි ප්ලැනට්  \n",
              "2                                                වූහාන්  \n",
              "3                                                 25200  \n",
              "4                        අසියා රග්බී පලමු කාන්ඩ ෂූරතාවය  \n",
              "...                                                 ...  \n",
              "2001  ෂ්‍රී ලංකාවේ ප්‍රථම සිංහල දිනපතා පුවත්පත වන්නේ...  \n",
              "2002  ෂ්‍රී ලංකාවේ ප්‍රථම ඉරිදා පුවත්පත වන්නේ ස්වදේෂ...  \n",
              "2003  ෂ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව ලෙස සැලකෙන්නේ ...  \n",
              "2004  ෂ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව වන නිලා නිර්මා...  \n",
              "2005  ඔව් ෂ්‍රී ලංකාවේ නූතන පන්සල් චිත්‍ර කථාවේ පුරෝ...  \n",
              "\n",
              "[1991 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-958d7fb9-1d0f-4d09-90f8-87d934fd4cc1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Answers</th>\n",
              "      <th>Label</th>\n",
              "      <th>filtered_sentence</th>\n",
              "      <th>Text_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>රාවණා 1</td>\n",
              "      <td>0</td>\n",
              "      <td>රාවන 1</td>\n",
              "      <td>රාවනා 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ලෝන්ලි ප්ලැනට්</td>\n",
              "      <td>0</td>\n",
              "      <td>ලෝන්ලි ප්ලැනට</td>\n",
              "      <td>ලෝන්ලි ප්ලැනට්</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>වූහාන්</td>\n",
              "      <td>0</td>\n",
              "      <td>වූහා</td>\n",
              "      <td>වූහාන්</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>25200</td>\n",
              "      <td>0</td>\n",
              "      <td>25200</td>\n",
              "      <td>25200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ආසියා රග්බී පළමු කාණ්ඩ ශූරතාවය</td>\n",
              "      <td>0</td>\n",
              "      <td>අසි රග්බ පල කාන්ඩ ෂූරතාව</td>\n",
              "      <td>අසියා රග්බී පලමු කාන්ඩ ෂූරතාවය</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001</th>\n",
              "      <td>2001</td>\n",
              "      <td>ශ්‍රී ලංකාවේ ප්‍රථම සිංහල දිනපතා පුවත්පත වන්නේ...</td>\n",
              "      <td>1</td>\n",
              "      <td>ලංක ප්‍රථ සිංහ දිනපත පුවත්පත ව * * දිවයි * * ....</td>\n",
              "      <td>ෂ්‍රී ලංකාවේ ප්‍රථම සිංහල දිනපතා පුවත්පත වන්නේ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002</th>\n",
              "      <td>2002</td>\n",
              "      <td>ශ්‍රී ලංකාවේ ප්‍රථම ඉරිදා පුවත්පත වන්නේ ස්වදේශ...</td>\n",
              "      <td>1</td>\n",
              "      <td>ලංක ප්‍රථ ඉරිද පුවත්පත ව ස්වදේෂ මිතෘ (swadesha...</td>\n",
              "      <td>ෂ්‍රී ලංකාවේ ප්‍රථම ඉරිදා පුවත්පත වන්නේ ස්වදේෂ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003</th>\n",
              "      <td>2003</td>\n",
              "      <td>ශ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව ලෙස සැලකෙන්නේ ...</td>\n",
              "      <td>1</td>\n",
              "      <td>ලංක ප්‍රථ චිත්‍ර කතා සැලකෙ * *\" න\" * * . එය 19...</td>\n",
              "      <td>ෂ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව ලෙස සැලකෙන්නේ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004</th>\n",
              "      <td>2004</td>\n",
              "      <td>ශ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව වන \"නිලා\" නිර්...</td>\n",
              "      <td>1</td>\n",
              "      <td>ලංක ප්‍රථ චිත්‍ර කතා \"න\" නිර්මාන කලේ ප්‍රවීන ච...</td>\n",
              "      <td>ෂ්‍රී ලංකාවේ ප්‍රථම චිත්‍ර කතාව වන නිලා නිර්මා...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005</th>\n",
              "      <td>2005</td>\n",
              "      <td>ඔව්, ශ්‍රී ලංකාවේ නූතන පන්සල් චිත්‍ර කථාවේ පුර...</td>\n",
              "      <td>1</td>\n",
              "      <td>ඔව්, ලංක නූත පන්සල චිත්‍ර කථ පුරෝගාමි * * සාර්...</td>\n",
              "      <td>ඔව් ෂ්‍රී ලංකාවේ නූතන පන්සල් චිත්‍ර කථාවේ පුරෝ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1991 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-958d7fb9-1d0f-4d09-90f8-87d934fd4cc1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-958d7fb9-1d0f-4d09-90f8-87d934fd4cc1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-958d7fb9-1d0f-4d09-90f8-87d934fd4cc1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-52410c48-895a-4c06-b8b3-2d2effb2ad48\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52410c48-895a-4c06-b8b3-2d2effb2ad48')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-52410c48-895a-4c06-b8b3-2d2effb2ad48 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5dbe296d-2b12-4966-ac19-db54d7d31aaf\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5dbe296d-2b12-4966-ac19-db54d7d31aaf button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1991,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 579,\n        \"min\": 0,\n        \"max\": 2005,\n        \"num_unique_values\": 1991,\n        \"samples\": [\n          898,\n          1685,\n          417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1990,\n        \"samples\": [\n          \"\\u0dc3\\u0dbb\\u0dca. \\u0d86\\u0dad\\u0dbb\\u0dca \\u0dc4\\u0dd0\\u0dc0\\u0dd2\\u0dbd\\u0dca\\u0da7\\u0db1\\u0dca \\u0d9c\\u0ddd\\u0dbb\\u0dca\\u0da9\\u0db1\",\n          \"\\u0d89\\u0db1\\u0dca\\u0daf\\u0dd2\\u0dba\\u0dcf\\u0dc0\\u0dda \\u0d85\\u0d9c\\u0db8\\u0dd0\\u0dad\\u0dd2 \\u0db0\\u0dd4\\u0dbb\\u0dba\\u0da7 \\u0daf\\u0dd9\\u0dc0\\u0dbb\\u0d9a\\u0dca\\u0db8 \\u0db4\\u0dad\\u0dca \\u0dc0\\u0dd6 \\u0d89\\u0db1\\u0dca\\u0daf\\u0dd3\\u0dba \\u0db8\\u0dc4 \\u0db6\\u0dd0\\u0d82\\u0d9a\\u0dd4\\u0dc0\\u0dda \\u0dc4\\u0dd2\\u0da7\\u0db4\\u0dd4 \\u0d85\\u0db0\\u0dd2\\u0db4\\u0dad\\u0dd2\\u0dc0\\u0dbb\\u0dba\\u0dcf \\u0dc0\\u0db1\\u0dca\\u0db1\\u0dda **\\u0db8\\u0db1\\u0ddd\\u0dc4\\u0dbb\\u0dca \\u0dc3\\u0dd2\\u0db1\\u0dca\\u0dc4\\u0dca** (Manmohan Singh) \\u0db8\\u0dc4\\u0dad\\u0dcf\\u0dba. 2004 \\u0dc3\\u0dd2\\u0da7 2014 \\u0daf\\u0d9a\\u0dca\\u0dc0\\u0dcf \\u0d89\\u0db1\\u0dca\\u0daf\\u0dd3\\u0dba \\u0d85\\u0d9c\\u0db8\\u0dd0\\u0dad\\u0dd2 \\u0db0\\u0dd6\\u0dbb\\u0dba \\u0daf\\u0dbb\\u0db1 \\u0d94\\u0dc4\\u0dd4, 1982 \\u0dc3\\u0dd2\\u0da7 1985 \\u0daf\\u0d9a\\u0dca\\u0dc0\\u0dcf \\u0d89\\u0db1\\u0dca\\u0daf\\u0dd3\\u0dba \\u0db8\\u0dc4 \\u0db6\\u0dd0\\u0d82\\u0d9a\\u0dd4\\u0dc0\\u0dda \\u0d85\\u0db0\\u0dd2\\u0db4\\u0dad\\u0dd2\\u0dc0\\u0dbb\\u0dba\\u0dcf \\u0dbd\\u0dd9\\u0dc3 \\u0d9a\\u0da7\\u0dba\\u0dd4\\u0dad\\u0dd4 \\u0d9a\\u0dc5\\u0dda\\u0dba.\",\n          \"\\u0da2\\u0dd9\\u0dbb\\u0dd4\\u0dc3\\u0dbd\\u0db8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filtered_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1984,\n        \"samples\": [\n          \"\\u0db8\\u0dbd\\u0dca\\u0dc0\\u0dad \\u0d94\\u0dba \\u0d85\\u0dc2\\u0dca\\u200d\\u0dbb\\u0dd2\\u0dad \\u0da2\\u0db1\\u0dcf\\u0dc0\\u0dcf\\u0dc3 \\u0db4\\u0dd2\\u0dc4\\u0dd2\\u0da7 \\u0d9c\\u0dad\\u0dca\\u0dad \\u0d8b\\u0db4\\u0dad\\u0dd2\\u0dc3\\u0dca\\u0dc3 \\u0d87\\u0db8\\u0dad\",\n          \"\\u0da2\\u0dd2\\u0dbb\\u0dcf\\u0dc6 \\u0da2\\u0dcf\\u0dad\\u0dd2\\u0d9a \\u0dc3\\u0dad\\u0dca\\u0dc0 * * \\u0da7\\u0dd0\\u0db1\\u0dca\\u0dc3\\u0dcf\\u0db1\\u0dd2\\u0dba * * \\u0da2\\u0dcf\\u0dad\\u0dd2\\u0d9a \\u0dc3\\u0dad \\u0d9a\\u0dd9\\u0db1\\u0dd9.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1991,\n        \"samples\": [\n          \"18850317 \\u0dc0\\u0db1 \\u0daf\\u0dd2\\u0db1 \\u0db6\\u0dbd\\u0dad\\u0dbd \\u0d9c\\u0dd0\\u0dc3\\u0da7\\u0dca \\u0db4\\u0dad\\u200d\\u0dca\\u200d\\u0dbb\\u0dba \\u0db8\\u0d9c\\u0dd2\\u0db1\",\n          \"2013 \\u0dc0\\u0dc3\\u0dbb\\u0dda \\u0d85\\u0dbb\\u0dca\\u0dae\\u0dd2\\u0d9a \\u0dc0\\u0dd2\\u0daf\\u0dca\\u200d\\u0dba\\u0dcf\\u0dc0 \\u0dc3\\u0daf\\u0dc4\\u0dcf \\u0db1\\u0ddc\\u0db6\\u0dd9\\u0dbd\\u0dca \\u0dad\\u0dca\\u200d\\u0dba\\u0dcf\\u0d9c\\u0dba\\u0dd9\\u0db1\\u0dca \\u0db4\\u0dd2\\u0daf\\u0dd4\\u0db8\\u0dca \\u0dbd\\u0dd0\\u0db6\\u0dd6 \\u0d85\\u0dbb\\u0dca\\u0dae\\u0dd2\\u0d9a \\u0dc0\\u0dd2\\u0daf\\u0dca\\u200d\\u0dba\\u0dcf\\u0da5\\u0dba\\u0db1\\u0dca \\u0dbd\\u0dd9\\u0dc3  \\u0d85\\u0dbb\\u0dca\\u0db1\\u0da7\\u0dca \\u0dc2\\u0dd2\\u0dbd\\u0dbb\\u0dca  \\u0d89\\u0d82\\u0d9c\\u0dca\\u200d\\u0dbb\\u0dd3\\u0dc3\\u0dd2 \\u0dc4\\u0ddd\\u0da9\\u0dd2\\u0dba\\u0dda \\u0daf\\u0dc4\\u0dc0\\u0dd9\\u0db1\\u0dd2 \\u0d85\\u0d9a\\u0dd4\\u0dbb    \\u0dba\\u0dd4\\u0da2\\u0dd3\\u0db1\\u0dca \\u0dc6\\u0dcf\\u0db8\\u0dcf  \\u0dc3\\u0d82\\u0d9c\\u0dd3\\u0dad\\u0dba\\u0dd9\\u0dc4\\u0dd2 \\u0dc3\\u0dca\\u0dc0\\u0dbb\\u0dba\\u0d9a\\u0dca \\u0dc3\\u0d82\\u0d9c\\u0dd3\\u0dad\\u0dba\\u0dd9\\u0dc4\\u0dd2 \\u0dc3\\u0dca\\u0dc0\\u0dbb\\u0dba\\u0d9a\\u0dcaama  \\u0dc3\\u0dc4  \\u0dbd\\u0dcf\\u0dbb\\u0dca\\u0dc3\\u0dca \\u0db4\\u0dd3\\u0da7\\u0dbb\\u0dca \\u0dc4\\u0db1\\u0dca\\u0dc3\\u0db1\\u0dca  \\u0d9a\\u0dca\\u200d\\u0dbb\\u0db8\\u0dba\\u0dd9\\u0db1\\u0dca \\u0d85\\u0da9\\u0dd4\\u0dc0\\u0dd3 \\u0dba\\u0db1\\u0dc0\\u0dcf   \\u0db1\\u0db8\\u0dca \\u0dad\\u0dd2\\u0daf\\u0dd9\\u0db1\\u0dcf \\u0db4\\u0dd2\\u0daf\\u0dd4\\u0db8\\u0dca \\u0dbd\\u0dd0\\u0db6\\u0dd6\\u0dc4 \\u0d94\\u0dc0\\u0dd4\\u0db1\\u0dca\\u0da7 \\u0db8\\u0dd9\\u0db8 \\u0dad\\u0dca\\u200d\\u0dba\\u0dcf\\u0d9c\\u0dba \\u0dc4\\u0dd2\\u0db8\\u0dd2\\u0dc0\\u0dd6\\u0dba\\u0dda \\u0d85\\u0dbb\\u0dca\\u0dae\\u0dd2\\u0d9a \\u0dc0\\u0dd9\\u0dbd\\u0daf\\u0db4\\u0ddc\\u0dbd \\u0dc3\\u0dc4 \\u0daf\\u0dda\\u0db4\\u0dbd \\u0db8\\u0dd2\\u0dbd \\u0dc3\\u0db8\\u0dca\\u0db6\\u0db1\\u0dca\\u0db0\\u0dba\\u0dd9\\u0db1\\u0dca \\u0dc3\\u0dd2\\u0daf\\u0dd4\\u0d9a\\u0dbd \\u0db4\\u0dbb\\u0dca\\u0dba\\u0dda\\u0dc2\\u0db1 \\u0dc3\\u0daf\\u0dc4\\u0dcf\\u0dba\\u0dd2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "\n",
        "# Verify the conversion\n",
        "print(df['Label'].value_counts())\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSZ1n1P7GMZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99632bbe-66e1-4c77-c003-3873b6a7fa37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')  # Download tokenizer resources\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Tokenize the 'Text_cleaned' column and create a new 'Tokenized' column\n",
        "df['Tokenized'] = df['Text_cleaned'].apply(word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pen4u26x8ILI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328bd6f7-0a5e-4cb6-e4ab-1313a2988a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Text_cleaned                             Tokenized\n",
            "0                         රාවනා 1                            [රාවනා, 1]\n",
            "1                  ලෝන්ලි ප්ලැනට්                     [ලෝන්ලි, ප්ලැනට්]\n",
            "2                          වූහාන්                              [වූහාන්]\n",
            "3                           25200                               [25200]\n",
            "4  අසියා රග්බී පලමු කාන්ඩ ෂූරතාවය  [අසියා, රග්බී, පලමු, කාන්ඩ, ෂූරතාවය]\n"
          ]
        }
      ],
      "source": [
        "print(df[['Text_cleaned', 'Tokenized']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIjC7sbeYLB-"
      },
      "outputs": [],
      "source": [
        "df.to_excel('tokenized_data.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlisVEGxZ7Dk"
      },
      "source": [
        "#Feature **Extraction** | TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtEY_7CU8AFY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30mS3T4RaF7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8767c09d-5f65-4be7-8018-f7c21a4487af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Download NLTK Sinhala support (if necessary)\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Step 1: Tokenize Sinhala text\n",
        "df['Tokenized'] = df['Text_cleaned'].apply(word_tokenize)\n",
        "\n",
        "# Step 2: Convert tokens back to sentences for TF-IDF\n",
        "df['Text_reconstructed'] = df['Tokenized'].apply(lambda tokens: \" \".join(tokens))\n",
        "\n",
        "# Step 3: Initialize TF-IDF Vectorizer (customize stop words for Sinhala if needed)\n",
        "tfidf_vectorizer = TfidfVectorizer(tokenizer=word_tokenize)\n",
        "\n",
        "# Step 4: Fit and transform the Sinhala text data\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['Text_reconstructed'])\n",
        "\n",
        "# Step 5: Convert TF-IDF matrix to a DataFrame\n",
        "tfidf_features = pd.DataFrame(\n",
        "    tfidf_matrix.toarray(),\n",
        "    columns=tfidf_vectorizer.get_feature_names_out()\n",
        ")\n",
        "\n",
        "# Step 6: Combine TF-IDF features with the original dataset\n",
        "df_with_tfidf = pd.concat([df, tfidf_features], axis=1)\n",
        "\n",
        "# Save the TF-IDF-enhanced dataset\n",
        "#output_file = \"/mnt/data/tfidf_features_sinhala.xlsx\"\n",
        "#df_with_tfidf.to_excel(output_file, index=False)\n",
        "\n",
        "#output_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZljWvlGb5dU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "b47aa777-b94b-42ab-e283-f9ab4cf7da4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                         Answers  Label  \\\n",
              "0         0.0                         රාවණා 1    0.0   \n",
              "1         1.0                  ලෝන්ලි ප්ලැනට්    0.0   \n",
              "2         2.0                          වූහාන්    0.0   \n",
              "3         3.0                           25200    0.0   \n",
              "4         4.0  ආසියා රග්බී පළමු කාණ්ඩ ශූරතාවය    0.0   \n",
              "\n",
              "          filtered_sentence                    Text_cleaned  \\\n",
              "0                    රාවන 1                         රාවනා 1   \n",
              "1             ලෝන්ලි ප්ලැනට                  ලෝන්ලි ප්ලැනට්   \n",
              "2                      වූහා                          වූහාන්   \n",
              "3                     25200                           25200   \n",
              "4  අසි රග්බ පල කාන්ඩ ෂූරතාව  අසියා රග්බී පලමු කාන්ඩ ෂූරතාවය   \n",
              "\n",
              "                              Tokenized              Text_reconstructed   01  \\\n",
              "0                            [රාවනා, 1]                         රාවනා 1  0.0   \n",
              "1                     [ලෝන්ලි, ප්ලැනට්]                  ලෝන්ලි ප්ලැනට්  0.0   \n",
              "2                              [වූහාන්]                          වූහාන්  0.0   \n",
              "3                               [25200]                           25200  0.0   \n",
              "4  [අසියා, රග්බී, පලමු, කාන්ඩ, ෂූරතාවය]  අසියා රග්බී පලමු කාන්ඩ ෂූරතාවය  0.0   \n",
              "\n",
              "    02   03  ...   天宫  普通话   것은   그는    송   있는  있으며  지ාතික  필ීපීනස්      \n",
              "0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0  0.0  \n",
              "1  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0  0.0  \n",
              "2  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0  0.0  \n",
              "3  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0  0.0  \n",
              "4  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0  0.0  \n",
              "\n",
              "[5 rows x 10333 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84308dcd-8930-48f6-8cb2-1112fa46afc2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Answers</th>\n",
              "      <th>Label</th>\n",
              "      <th>filtered_sentence</th>\n",
              "      <th>Text_cleaned</th>\n",
              "      <th>Tokenized</th>\n",
              "      <th>Text_reconstructed</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>03</th>\n",
              "      <th>...</th>\n",
              "      <th>天宫</th>\n",
              "      <th>普通话</th>\n",
              "      <th>것은</th>\n",
              "      <th>그는</th>\n",
              "      <th>송</th>\n",
              "      <th>있는</th>\n",
              "      <th>있으며</th>\n",
              "      <th>지ාතික</th>\n",
              "      <th>필ීපීනස්</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>රාවණා 1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>රාවන 1</td>\n",
              "      <td>රාවනා 1</td>\n",
              "      <td>[රාවනා, 1]</td>\n",
              "      <td>රාවනා 1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>ලෝන්ලි ප්ලැනට්</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ලෝන්ලි ප්ලැනට</td>\n",
              "      <td>ලෝන්ලි ප්ලැනට්</td>\n",
              "      <td>[ලෝන්ලි, ප්ලැනට්]</td>\n",
              "      <td>ලෝන්ලි ප්ලැනට්</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>වූහාන්</td>\n",
              "      <td>0.0</td>\n",
              "      <td>වූහා</td>\n",
              "      <td>වූහාන්</td>\n",
              "      <td>[වූහාන්]</td>\n",
              "      <td>වූහාන්</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>25200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25200</td>\n",
              "      <td>25200</td>\n",
              "      <td>[25200]</td>\n",
              "      <td>25200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>ආසියා රග්බී පළමු කාණ්ඩ ශූරතාවය</td>\n",
              "      <td>0.0</td>\n",
              "      <td>අසි රග්බ පල කාන්ඩ ෂූරතාව</td>\n",
              "      <td>අසියා රග්බී පලමු කාන්ඩ ෂූරතාවය</td>\n",
              "      <td>[අසියා, රග්බී, පලමු, කාන්ඩ, ෂූරතාවය]</td>\n",
              "      <td>අසියා රග්බී පලමු කාන්ඩ ෂූරතාවය</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10333 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84308dcd-8930-48f6-8cb2-1112fa46afc2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-84308dcd-8930-48f6-8cb2-1112fa46afc2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-84308dcd-8930-48f6-8cb2-1112fa46afc2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bbaf0676-9783-40b2-a5b4-0002b02139b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bbaf0676-9783-40b2-a5b4-0002b02139b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bbaf0676-9783-40b2-a5b4-0002b02139b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_with_tfidf"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "df_with_tfidf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNawsmsxb6Ss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "8512a6d4-0cd0-4e50-dde2-6c016a6a391d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e1883008829e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the TF-IDF-enhanced dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"tfidf_features_sinhala.xlsx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_with_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   2415\u001b[0m             \u001b[0minf_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf_rep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m         )\n\u001b[0;32m-> 2417\u001b[0;31m         formatter.write(\n\u001b[0m\u001b[1;32m   2418\u001b[0m             \u001b[0mexcel_writer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             writer._write_cells(\n\u001b[0m\u001b[1;32m    953\u001b[0m                 \u001b[0mformatted_cells\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                 \u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36m_write_cells\u001b[0;34m(self, cells, sheet_name, startrow, startcol, freeze_panes)\u001b[0m\n\u001b[1;32m    484\u001b[0m             )\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcells\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m             xcell = wks.cell(\n\u001b[1;32m    488\u001b[0m                 \u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstartrow\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstartcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36mget_formatted_cells\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_formatted_cells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mExcelCell\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36m_format_regular_rows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0mcoloffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoloffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_hierarchical_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mExcelCell\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36m_generate_body\u001b[0;34m(self, coloffset)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m                 yield CssExcelCell(\n\u001b[0m\u001b[1;32m    878\u001b[0m                     \u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowcounter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m                     \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolidx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcoloffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Save the TF-IDF-enhanced dataset\n",
        "output_file = \"tfidf_features_sinhala.xlsx\"\n",
        "df_with_tfidf.to_excel(output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuLbtUTzQK57"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = tfidf_matrix  # Features from TF-IDF\n",
        "y = df['Label']   # Labels: Human (0) or AI (1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlpLhSYD5Evt"
      },
      "source": [
        "# ANN **Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGmcYfarR0sl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2aa6a5b-43bc-4186-a46d-a140102c8390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.6035 - loss: 0.6906 - val_accuracy: 0.7712 - val_loss: 0.6794\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9240 - loss: 0.6526 - val_accuracy: 0.8182 - val_loss: 0.6349\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9719 - loss: 0.5468 - val_accuracy: 0.8245 - val_loss: 0.5461\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9801 - loss: 0.3618 - val_accuracy: 0.8433 - val_loss: 0.4528\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9917 - loss: 0.1746 - val_accuracy: 0.8245 - val_loss: 0.4026\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9986 - loss: 0.0700 - val_accuracy: 0.8119 - val_loss: 0.3947\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9998 - loss: 0.0314 - val_accuracy: 0.8119 - val_loss: 0.4036\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 0.0170 - val_accuracy: 0.8025 - val_loss: 0.4168\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.8025 - val_loss: 0.4268\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9999 - loss: 0.0082 - val_accuracy: 0.8056 - val_loss: 0.4329\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Accuracy: 0.8546365914786967\n",
            "MAE (Mean Absolute Error): 0.17835712432861328\n",
            "RMSE (Root Mean Squared Error): 0.32067929879469326\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       194\n",
            "           1       0.87      0.84      0.86       205\n",
            "\n",
            "    accuracy                           0.85       399\n",
            "   macro avg       0.85      0.85      0.85       399\n",
            "weighted avg       0.86      0.85      0.85       399\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Ensure inputs are in array format\n",
        "if hasattr(X_train, 'toarray'):  # Convert sparse matrix to dense array if needed\n",
        "    X_train = X_train.toarray()\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "if hasattr(X_test, 'toarray'):  # Convert sparse matrix to dense array if needed\n",
        "    X_test = X_test.toarray()\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Define the ANN model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_dim=X_train.shape[1]),  # Input layer with 128 neurons\n",
        "    Dropout(0.2),  # Dropout for regularization\n",
        "    Dense(64, activation='relu'),  # Hidden layer with 64 neurons\n",
        "    Dropout(0.2),  # Dropout for regularization\n",
        "    Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=100, validation_split=0.2)\n",
        "\n",
        "# Test the model\n",
        "y_pred_prob = model.predict(X_test)  # Predicted probabilities\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()  # Convert probabilities to binary predictions\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred_prob.flatten())  # MAE for probabilities\n",
        "rmse = np.sqrt(np.mean((y_test - y_pred_prob.flatten())**2))  # RMSE for probabilities\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"MAE (Mean Absolute Error):\", mae)\n",
        "print(\"RMSE (Root Mean Squared Error):\", rmse)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2MXKwV0I-4A"
      },
      "source": [
        "# ANN | Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xTZlJXnJEEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d98f945-d5f0-4e18-d759-2d0df23198c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:tensorflow:5 out of the last 21 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a1d6827d260> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a1d6813d8a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\n",
            "Cross-Validation Results:\n",
            "Fold 1:\n",
            "  Accuracy: 0.8800\n",
            "  Confusion Matrix (TN FP FN TP): TN: 90, FP: 10, FN: 14, TP: 86\n",
            "Fold 2:\n",
            "  Accuracy: 0.8342\n",
            "  Confusion Matrix (TN FP FN TP): TN: 80, FP: 20, FN: 13, TP: 86\n",
            "Fold 3:\n",
            "  Accuracy: 0.8392\n",
            "  Confusion Matrix (TN FP FN TP): TN: 83, FP: 16, FN: 16, TP: 84\n",
            "Fold 4:\n",
            "  Accuracy: 0.8744\n",
            "  Confusion Matrix (TN FP FN TP): TN: 87, FP: 12, FN: 13, TP: 87\n",
            "Fold 5:\n",
            "  Accuracy: 0.8442\n",
            "  Confusion Matrix (TN FP FN TP): TN: 84, FP: 15, FN: 16, TP: 84\n",
            "Fold 6:\n",
            "  Accuracy: 0.8191\n",
            "  Confusion Matrix (TN FP FN TP): TN: 81, FP: 18, FN: 18, TP: 82\n",
            "Fold 7:\n",
            "  Accuracy: 0.8744\n",
            "  Confusion Matrix (TN FP FN TP): TN: 90, FP: 9, FN: 16, TP: 84\n",
            "Fold 8:\n",
            "  Accuracy: 0.8543\n",
            "  Confusion Matrix (TN FP FN TP): TN: 86, FP: 13, FN: 16, TP: 84\n",
            "Fold 9:\n",
            "  Accuracy: 0.8442\n",
            "  Confusion Matrix (TN FP FN TP): TN: 84, FP: 15, FN: 16, TP: 84\n",
            "Fold 10:\n",
            "  Accuracy: 0.7990\n",
            "  Confusion Matrix (TN FP FN TP): TN: 76, FP: 23, FN: 17, TP: 83\n",
            "\n",
            "Average Accuracy: 0.8463\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure inputs are in array format and reset indices if using pandas\n",
        "if hasattr(X, 'reset_index'):\n",
        "    X = X.reset_index(drop=True)  # Reset index for X if it's a pandas DataFrame\n",
        "if hasattr(y, 'reset_index'):\n",
        "    y = y.reset_index(drop=True)  # Reset index for y if it's a pandas Series\n",
        "\n",
        "# Convert to numpy arrays if not already\n",
        "if not isinstance(X, np.ndarray):\n",
        "    if hasattr(X, \"toarray\"):\n",
        "        X = X.toarray()  # Convert sparse matrix to dense array\n",
        "    else:\n",
        "        X = np.array(X)\n",
        "\n",
        "if not isinstance(y, np.ndarray):\n",
        "    y = np.array(y)\n",
        "\n",
        "# Define a function to create the ANN model\n",
        "def create_ann_model(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_dim=input_dim),  # Input layer with 128 neurons\n",
        "        Dropout(0.2),  # Dropout for regularization\n",
        "        Dense(64, activation='relu'),  # Hidden layer with 64 neurons\n",
        "        Dropout(0.2),  # Dropout for regularization\n",
        "        Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Cross-validation setup\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "fold_accuracies = []\n",
        "confusion_matrices = []\n",
        "\n",
        "for train_index, test_index in kfold.split(X, y):\n",
        "    # Split data into training and validation sets for this fold\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Create a new ANN model for each fold\n",
        "    model = create_ann_model(input_dim=X_train.shape[1])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=100, verbose=0)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred_prob = model.predict(X_test)  # Predicted probabilities\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()  # Convert probabilities to binary predictions\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    fold_accuracies.append(accuracy)\n",
        "\n",
        "    # Confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    confusion_matrices.append(conf_matrix)\n",
        "\n",
        "# Print cross-validation results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "for i, (accuracy, conf_matrix) in enumerate(zip(fold_accuracies, confusion_matrices), start=1):\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "    print(f\"Fold {i}:\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  Confusion Matrix (TN FP FN TP): TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n",
        "\n",
        "# Average accuracy across all folds\n",
        "avg_accuracy = np.mean(fold_accuracies)\n",
        "print(f\"\\nAverage Accuracy: {avg_accuracy:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7_x81qsKStX"
      },
      "source": [
        "# ANN Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7FJZjniKQkx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b116554-3fd9-4f87-80f2-8b6a87473e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.6099 - loss: 0.6878 - val_accuracy: 0.0000e+00 - val_loss: 0.7809\n",
            "Epoch 2/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.6048 - loss: 0.6459 - val_accuracy: 0.0000e+00 - val_loss: 0.9116\n",
            "Epoch 3/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7365 - loss: 0.5309 - val_accuracy: 0.1448 - val_loss: 0.9526\n",
            "Epoch 4/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9316 - loss: 0.3436 - val_accuracy: 0.3538 - val_loss: 0.9526\n",
            "Epoch 5/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9790 - loss: 0.1591 - val_accuracy: 0.4819 - val_loss: 0.9399\n",
            "Epoch 6/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9965 - loss: 0.0571 - val_accuracy: 0.5070 - val_loss: 1.0151\n",
            "Epoch 7/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9995 - loss: 0.0262 - val_accuracy: 0.5348 - val_loss: 1.0498\n",
            "Epoch 8/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 0.5237 - val_loss: 1.1941\n",
            "Epoch 9/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9998 - loss: 0.0083 - val_accuracy: 0.5571 - val_loss: 1.0753\n",
            "Epoch 10/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9999 - loss: 0.0062 - val_accuracy: 0.5376 - val_loss: 1.1792\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Accuracy: 0.7638190954773869\n",
            "MAE (Mean Absolute Error): 0.2594166398048401\n",
            "RMSE (Root Mean Squared Error): 0.4189892920079144\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.83      0.78        99\n",
            "           1       0.80      0.70      0.75       100\n",
            "\n",
            "    accuracy                           0.76       199\n",
            "   macro avg       0.77      0.76      0.76       199\n",
            "weighted avg       0.77      0.76      0.76       199\n",
            "\n",
            "\n",
            "Confusion Matrix (TN FP FN TP):\n",
            "TN: 82, FP: 17, FN: 30, TP: 70\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure inputs are in array format\n",
        "if hasattr(X_train, 'toarray'):  # Convert sparse matrix to dense array if needed\n",
        "    X_train = X_train.toarray()\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "if hasattr(X_test, 'toarray'):  # Convert sparse matrix to dense array if needed\n",
        "    X_test = X_test.toarray()\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Define the ANN model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_dim=X_train.shape[1]),  # Input layer with 128 neurons\n",
        "    Dropout(0.2),  # Dropout for regularization\n",
        "    Dense(64, activation='relu'),  # Hidden layer with 64 neurons\n",
        "    Dropout(0.2),  # Dropout for regularization\n",
        "    Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=100, validation_split=0.2)\n",
        "\n",
        "# Test the model\n",
        "y_pred_prob = model.predict(X_test)  # Predicted probabilities\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()  # Convert probabilities to binary predictions\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred_prob.flatten())  # MAE for probabilities\n",
        "rmse = np.sqrt(np.mean((y_test - y_pred_prob.flatten())**2))  # RMSE for probabilities\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"MAE (Mean Absolute Error):\", mae)\n",
        "print(\"RMSE (Root Mean Squared Error):\", rmse)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Output confusion matrix in TN FP FN TP format\n",
        "print(\"\\nConfusion Matrix (TN FP FN TP):\")\n",
        "print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8STtjU0OcPH"
      },
      "source": [
        "# LSTM Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94EcaJm5ObtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15cb10e8-1bcb-4a99-81e8-0ad68bd46a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X_train shape: (1792, 10326)\n",
            "Original X_test shape: (199, 10326)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - accuracy: 0.5627 - loss: 0.6901 - val_accuracy: 0.0000e+00 - val_loss: 0.7401\n",
            "Epoch 2/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.6110 - loss: 0.6632 - val_accuracy: 0.0000e+00 - val_loss: 0.7889\n",
            "Epoch 3/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 0.8038 - loss: 0.5978 - val_accuracy: 0.1421 - val_loss: 0.8123\n",
            "Epoch 4/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - accuracy: 0.9184 - loss: 0.4690 - val_accuracy: 0.3148 - val_loss: 0.8224\n",
            "Epoch 5/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.9696 - loss: 0.3015 - val_accuracy: 0.4234 - val_loss: 0.8309\n",
            "Epoch 6/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.9852 - loss: 0.1601 - val_accuracy: 0.4986 - val_loss: 0.8616\n",
            "Epoch 7/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.9952 - loss: 0.0802 - val_accuracy: 0.5097 - val_loss: 0.9285\n",
            "Epoch 8/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.9985 - loss: 0.0414 - val_accuracy: 0.5265 - val_loss: 0.9583\n",
            "Epoch 9/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 0.5209 - val_loss: 1.0429\n",
            "Epoch 10/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 0.5153 - val_loss: 1.1191\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step\n",
            "Accuracy: 0.7638190954773869\n",
            "MAE (Mean Absolute Error): 0.28010421991348267\n",
            "RMSE (Root Mean Squared Error): 0.42012879784242835\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.83      0.78        99\n",
            "           1       0.80      0.70      0.75       100\n",
            "\n",
            "    accuracy                           0.76       199\n",
            "   macro avg       0.77      0.76      0.76       199\n",
            "weighted avg       0.77      0.76      0.76       199\n",
            "\n",
            "\n",
            "Confusion Matrix (TN FP FN TP):\n",
            "TN: 82, FP: 17, FN: 30, TP: 70\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Ensure inputs are in array format and convert sparse matrices to dense arrays if necessary\n",
        "if hasattr(X_train, 'toarray'):  # Convert sparse matrix to dense array if needed\n",
        "    X_train = X_train.toarray()\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "if hasattr(X_test, 'toarray'):  # Convert sparse matrix to dense array if needed\n",
        "    X_test = X_test.toarray()\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Check original shapes before reshaping\n",
        "print(\"Original X_train shape:\", X_train.shape)\n",
        "print(\"Original X_test shape:\", X_test.shape)\n",
        "\n",
        "# Reshape data to 3D [samples, timesteps, features]\n",
        "timesteps = 1  # Number of timesteps (set to 1 if not sequential)\n",
        "n_features = X_train.shape[1]  # Number of features in each sample\n",
        "X_train = X_train.reshape((X_train.shape[0], timesteps, n_features))\n",
        "X_test = X_test.reshape((X_test.shape[0], timesteps, n_features))\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(128, activation='tanh', return_sequences=False, input_shape=(timesteps, n_features)),  # LSTM layer\n",
        "    Dropout(0.2),  # Dropout for regularization\n",
        "    Dense(64, activation='relu'),  # Dense layer for further processing\n",
        "    Dropout(0.2),  # Dropout for regularization\n",
        "    Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=100, validation_split=0.2)\n",
        "\n",
        "# Test the model\n",
        "y_pred_prob = model.predict(X_test)  # Predicted probabilities\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()  # Convert probabilities to binary predictions\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred_prob.flatten())  # MAE for probabilities\n",
        "rmse = np.sqrt(np.mean((y_test - y_pred_prob.flatten())**2))  # RMSE for probabilities\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"MAE (Mean Absolute Error):\", mae)\n",
        "print(\"RMSE (Root Mean Squared Error):\", rmse)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Output confusion matrix in TN FP FN TP format\n",
        "print(\"\\nConfusion Matrix (TN FP FN TP):\")\n",
        "print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkkMBIMZNBD3"
      },
      "source": [
        "# LSTM | Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "679x5EEhNEq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c192d72d-de73-466f-94d2-44dba1058f4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (1991, 10326)\n",
            "y shape: (1991,)\n",
            "Unique classes in y: [0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\n",
            "Cross-Validation Results:\n",
            "Fold 1:\n",
            "  Accuracy: 0.8546\n",
            "  Confusion Matrix (TN FP FN TP): TN: 167, FP: 32, FN: 26, TP: 174\n",
            "Fold 2:\n",
            "  Accuracy: 0.8467\n",
            "  Confusion Matrix (TN FP FN TP): TN: 170, FP: 29, FN: 32, TP: 167\n",
            "Fold 3:\n",
            "  Accuracy: 0.8492\n",
            "  Confusion Matrix (TN FP FN TP): TN: 168, FP: 30, FN: 30, TP: 170\n",
            "Fold 4:\n",
            "  Accuracy: 0.8518\n",
            "  Confusion Matrix (TN FP FN TP): TN: 171, FP: 27, FN: 32, TP: 168\n",
            "Fold 5:\n",
            "  Accuracy: 0.8266\n",
            "  Confusion Matrix (TN FP FN TP): TN: 161, FP: 37, FN: 32, TP: 168\n",
            "\n",
            "Average Accuracy: 0.8458\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Ensure inputs are numpy arrays and 2D\n",
        "if hasattr(X, 'reset_index'):\n",
        "    X = X.reset_index(drop=True)\n",
        "if hasattr(y, 'reset_index'):\n",
        "    y = y.reset_index(drop=True)\n",
        "\n",
        "X = np.array(X) if not isinstance(X, np.ndarray) else X\n",
        "y = np.array(y) if not isinstance(y, np.ndarray) else y\n",
        "\n",
        "# Ensure X has at least 2 dimensions\n",
        "if X.ndim == 1:\n",
        "    X = X.reshape(-1, 1)\n",
        "\n",
        "# Check the data dimensions and class distribution\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Unique classes in y:\", np.unique(y))\n",
        "\n",
        "if X.shape[0] != len(y):\n",
        "    raise ValueError(f\"Mismatch in sample sizes: X has {X.shape[0]} samples, y has {len(y)} samples\")\n",
        "\n",
        "if len(np.unique(y)) < 2:\n",
        "    raise ValueError(f\"y must have at least 2 classes, but found: {np.unique(y)}\")\n",
        "\n",
        "# Reshape data to 3D [samples, timesteps, features]\n",
        "timesteps = 1  # Number of timesteps\n",
        "n_samples, n_features = X.shape\n",
        "X = X.reshape((n_samples, timesteps, n_features))\n",
        "\n",
        "# Define a function to create the LSTM model\n",
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(128, activation='tanh', return_sequences=False, input_shape=input_shape),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Cross-validation setup\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_accuracies = []\n",
        "confusion_matrices = []\n",
        "\n",
        "for train_index, test_index in kfold.split(X, y):\n",
        "    # Split data into training and testing sets for this fold\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Create and train the LSTM model\n",
        "    model = create_lstm_model(input_shape=(timesteps, n_features))\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=100, verbose=0)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    fold_accuracies.append(accuracy)\n",
        "\n",
        "    # Confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    confusion_matrices.append(conf_matrix)\n",
        "\n",
        "# Print cross-validation results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "for i, (accuracy, conf_matrix) in enumerate(zip(fold_accuracies, confusion_matrices), start=1):\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "    print(f\"Fold {i}:\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  Confusion Matrix (TN FP FN TP): TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n",
        "\n",
        "# Average accuracy across all folds\n",
        "avg_accuracy = np.mean(fold_accuracies)\n",
        "print(f\"\\nAverage Accuracy: {avg_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTjAL9ZQRcMA"
      },
      "source": [
        "# LSTM Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gPTAbtiRfu_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "80b3b2d7-6a27-404e-dd66-07f151abf9a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X_train shape: (1593, 1, 10326)\n",
            "Original X_test shape: (398, 1, 10326)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 16449318 into shape (1593,1,1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-da561d98e84b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Reshape data to 3D [samples, timesteps, features]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 16449318 into shape (1593,1,1)"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Ensure inputs are in array format and convert sparse matrices to dense arrays if necessary\n",
        "if hasattr(X_train, 'toarray'):  # Convert sparse matrix to dense array if needed\n",
        "    X_train = X_train.toarray()\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "if hasattr(X_test, 'toarray'):  # Convert sparse matrix to dense array if needed\n",
        "    X_test = X_test.toarray()\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Check original shapes before reshaping\n",
        "print(\"Original X_train shape:\", X_train.shape)\n",
        "print(\"Original X_test shape:\", X_test.shape)\n",
        "\n",
        "# Assuming X_train has shape (15920, n_features) and you want to reshape for LSTM\n",
        "# The reshape needs to be 3D: [samples, timesteps, features]\n",
        "# If there are no natural timesteps (like in time series), you can set timesteps=1\n",
        "timesteps = 1  # Number of timesteps (set to 1 if not sequential)\n",
        "n_features = X_train.shape[1]  # Number of features in each sample\n",
        "\n",
        "# Reshape data to 3D [samples, timesteps, features]\n",
        "X_train = X_train.reshape((X_train.shape[0], timesteps, n_features))\n",
        "X_test = X_test.reshape((X_test.shape[0], timesteps, n_features))\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(128, activation='tanh', return_sequences=False, input_shape=(timesteps, n_features)),  # LSTM layer\n",
        "    Dropout(0.2),  # Dropout for regularization\n",
        "    Dense(64, activation='relu'),  # Dense layer for further processing\n",
        "    Dropout(0.2),  # Dropout for regularization\n",
        "    Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=100, validation_split=0.2)\n",
        "\n",
        "# Test the model\n",
        "y_pred_prob = model.predict(X_test)  # Predicted probabilities\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()  # Convert probabilities to binary predictions\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred_prob.flatten())  # MAE for probabilities\n",
        "rmse = np.sqrt(np.mean((y_test - y_pred_prob.flatten())**2))  # RMSE for probabilities\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"MAE (Mean Absolute Error):\", mae)\n",
        "print(\"RMSE (Root Mean Squared Error):\", rmse)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM Algorithm | Confusion Matrix"
      ],
      "metadata": {
        "id": "we-Rz-ejYa7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure inputs are in array format\n",
        "if hasattr(X_train, 'toarray'):  # Convert sparse matrix to dense array if needed\n",
        "    X_train = X_train.toarray()\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "if hasattr(X_test, 'toarray'):  # Convert sparse matrix to dense array if needed\n",
        "    X_test = X_test.toarray()\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Define the SVM model\n",
        "model = SVC(kernel='linear', probability=True)  # You can change the kernel to 'rbf', 'poly', etc.\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Test the model\n",
        "y_pred_prob = model.predict_proba(X_test)[:, 1]  # Predicted probabilities for the positive class\n",
        "y_pred = model.predict(X_test)  # Predicted class labels\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred_prob)  # MAE for probabilities\n",
        "rmse = np.sqrt(np.mean((y_test - y_pred_prob)**2))  # RMSE for probabilities\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"MAE (Mean Absolute Error):\", mae)\n",
        "print(\"RMSE (Root Mean Squared Error):\", rmse)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Output confusion matrix in TN FP FN TP format\n",
        "print(\"\\nConfusion Matrix (TN FP FN TP):\")\n",
        "print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxQGfHEzYeyQ",
        "outputId": "0653d72e-cadc-463d-a250-ac37cf824bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8696741854636592\n",
            "MAE (Mean Absolute Error): 0.19912483339954276\n",
            "RMSE (Root Mean Squared Error): 0.30899652045386233\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       194\n",
            "           1       0.88      0.87      0.87       205\n",
            "\n",
            "    accuracy                           0.87       399\n",
            "   macro avg       0.87      0.87      0.87       399\n",
            "weighted avg       0.87      0.87      0.87       399\n",
            "\n",
            "\n",
            "Confusion Matrix (TN FP FN TP):\n",
            "TN: 169, FP: 25, FN: 27, TP: 178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM | Cross Validation"
      ],
      "metadata": {
        "id": "9juHIqOT_EVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Ensure inputs are in array format\n",
        "if hasattr(X_train, 'toarray'):  # Convert sparse matrix to dense array if needed\n",
        "    X_train = X_train.toarray()\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "if hasattr(X_test, 'toarray'):  # Convert sparse matrix to dense array if needed\n",
        "    X_test = X_test.toarray()\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Define the SVM model\n",
        "model = SVC(kernel='linear', probability=True)  # You can change the kernel to 'rbf', 'poly', etc.\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "k_folds = 5  # You can change this to any number of folds (e.g., 5, 10)\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='accuracy')\n",
        "\n",
        "# Print cross-validation results\n",
        "print(f\"Cross-Validation Accuracy (Mean ± Std Dev): {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
        "\n",
        "# Train the model on the full training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Test the model on the test set\n",
        "y_pred_prob = model.predict_proba(X_test)[:, 1]  # Predicted probabilities for the positive class\n",
        "y_pred = model.predict(X_test)  # Predicted class labels\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred_prob)  # MAE for probabilities\n",
        "rmse = np.sqrt(np.mean((y_test - y_pred_prob)**2))  # RMSE for probabilities\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Print results\n",
        "print(\"\\nTest Set Evaluation:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"MAE (Mean Absolute Error):\", mae)\n",
        "print(\"RMSE (Root Mean Squared Error):\", rmse)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Output confusion matrix in TN FP FN TP format\n",
        "print(\"\\nConfusion Matrix (TN FP FN TP):\")\n",
        "print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ACIWJ8o_IBq",
        "outputId": "3485b6db-6193-4b81-cd4a-b6583fe91981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracy (Mean ± Std Dev): 0.8291 ± 0.0181\n",
            "\n",
            "Test Set Evaluation:\n",
            "Accuracy: 0.8696741854636592\n",
            "MAE (Mean Absolute Error): 0.20079672877191956\n",
            "RMSE (Root Mean Squared Error): 0.30933164244464606\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87       194\n",
            "           1       0.88      0.87      0.87       205\n",
            "\n",
            "    accuracy                           0.87       399\n",
            "   macro avg       0.87      0.87      0.87       399\n",
            "weighted avg       0.87      0.87      0.87       399\n",
            "\n",
            "\n",
            "Confusion Matrix (TN FP FN TP):\n",
            "TN: 169, FP: 25, FN: 27, TP: 178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rpN_l25WX2X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming tfidf_matrix and df are already available\n",
        "X = tfidf_matrix  # Features from TF-IDF\n",
        "y = df['Label']   # Labels: Human (0) or AI (1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check if X_train and X_test are sparse matrices (in case of TF-IDF)\n",
        "if hasattr(X_train, 'toarray'):  # Check if it's a sparse matrix\n",
        "    X_train = X_train.toarray()  # Convert to dense array\n",
        "    X_test = X_test.toarray()    # Convert to dense array\n",
        "\n",
        "# Now let's check if the conversion worked and ensure they are 2D arrays\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "\n",
        "# Ensure the data is 2D (samples, features)\n",
        "if len(X_train.shape) == 2:  # If X_train is 2D\n",
        "    samples_train = X_train.shape[0]  # Number of samples\n",
        "    features_train = X_train.shape[1]  # Number of features\n",
        "\n",
        "    samples_test = X_test.shape[0]  # Number of samples in test set\n",
        "    features_test = X_test.shape[1]  # Number of features in test set\n",
        "\n",
        "    # Reshape for LSTM (samples, time_steps=1, features)\n",
        "    X_train = X_train.reshape((samples_train, 1, features_train))\n",
        "    X_test = X_test.reshape((samples_test, 1, features_test))\n",
        "else:\n",
        "    raise ValueError(\"X_train and X_test must be 2D arrays!\")\n",
        "\n",
        "# ------------ LSTM Model ------------\n",
        "\n",
        "# Define the LSTM model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(128, activation='tanh', input_shape=(1, features_train), return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(64, activation='tanh', return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the LSTM model\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_model.fit(X_train, y_train, epochs=20, batch_size=50, validation_split=0.2)\n",
        "\n",
        "# Test the LSTM model\n",
        "y_pred_prob_lstm = lstm_model.predict(X_test)\n",
        "y_pred_lstm = (y_pred_prob_lstm > 0.5).astype(int).flatten()\n",
        "\n",
        "# LSTM model metrics\n",
        "accuracy_lstm = accuracy_score(y_test, y_pred_lstm)\n",
        "mse_lstm = mean_squared_error(y_test, y_pred_prob_lstm.flatten())\n",
        "rmse_lstm = np.sqrt(mse_lstm)\n",
        "\n",
        "# ------------ ANN Model ------------\n",
        "\n",
        "# Define the ANN model (Feedforward neural network)\n",
        "ann_model = Sequential([\n",
        "    Dense(128, input_dim=features_train, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the ANN model\n",
        "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the ANN model\n",
        "ann_model.fit(X_train.reshape(X_train.shape[0], -1), y_train, epochs=20, batch_size=50, validation_split=0.2)\n",
        "\n",
        "# Test the ANN model\n",
        "y_pred_ann = ann_model.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "\n",
        "# ANN model metrics\n",
        "y_pred_ann_bin = (y_pred_ann > 0.5).astype(int)  # Binarize the predictions\n",
        "accuracy_ann = accuracy_score(y_test, y_pred_ann_bin)\n",
        "mse_ann = mean_squared_error(y_test, y_pred_ann)\n",
        "rmse_ann = np.sqrt(mse_ann)\n",
        "\n",
        "# ------------ Plotting Comparison ------------\n",
        "\n",
        "# Prepare data for plotting\n",
        "metrics = ['Accuracy', 'MSE', 'RMSE']\n",
        "ann_scores = [accuracy_ann, mse_ann, rmse_ann]\n",
        "lstm_scores = [accuracy_lstm, mse_lstm, rmse_lstm]\n",
        "\n",
        "# Plotting\n",
        "x = np.arange(len(metrics))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Create bars for ANN and LSTM\n",
        "bars1 = ax.bar(x - width/2, ann_scores, width, label='ANN', color='skyblue')\n",
        "bars2 = ax.bar(x + width/2, lstm_scores, width, label='LSTM', color='lightgreen')\n",
        "\n",
        "# Add labels, title, and custom x-axis tick labels\n",
        "ax.set_xlabel('Metrics')\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Comparison of ANN and LSTM Models')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-JDM9K2erUg"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/comparison_plot.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWCntNMOhLo4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data for the bar graph\n",
        "metrics = ['MSE', 'RMSE']\n",
        "ann_scores = [0.12, 0.35]  # Example scores for ANN\n",
        "lstm_scores = [0.10, 0.32]  # Example scores for LSTM\n",
        "\n",
        "# Create the bar graph\n",
        "x = np.arange(len(metrics))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Create bars for ANN and LSTM\n",
        "bars1 = ax.bar(x - width/2, ann_scores, width, label='ANN', color='skyblue')\n",
        "bars2 = ax.bar(x + width/2, lstm_scores, width, label='LSTM', color='lightgreen')\n",
        "\n",
        "# Add labels, title, and custom x-axis tick labels\n",
        "ax.set_xlabel('Metrics')\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Comparison of ANN and LSTM Models')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "\n",
        "# Show the plot (ensure it renders before saving)\n",
        "plt.show()\n",
        "\n",
        "# Save the plot as an image file\n",
        "plt.savefig('/content/comparison_plot.png')\n",
        "\n",
        "# Download the plot image\n",
        "from google.colab import files\n",
        "files.download('/content/comparison_plot.png')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0-lL-m4nDVz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define metrics and their values for both models\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "ann_scores = [0.85, 0.88, 0.86, 0.87]  # Example scores for ANN\n",
        "lstm_scores = [0.88, 0.90, 0.89, 0.91]  # Example scores for LSTM\n",
        "\n",
        "# Create the bar plot\n",
        "x = np.arange(len(metrics))  # The label locations\n",
        "width = 0.35  # Width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Create bars for ANN and LSTM\n",
        "bars1 = ax.bar(x - width/2, ann_scores, width, label='ANN', color='skyblue')\n",
        "bars2 = ax.bar(x + width/2, lstm_scores, width, label='LSTM', color='lightgreen')\n",
        "\n",
        "# Add labels, title, and custom x-axis tick labels\n",
        "ax.set_xlabel('Metrics', fontsize=12)\n",
        "ax.set_ylabel('Scores', fontsize=12)\n",
        "ax.set_title('Comparison of ANN and LSTM Models', fontsize=14)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics, fontsize=10)\n",
        "ax.legend()\n",
        "\n",
        "# Annotate bars with their values\n",
        "for bar in bars1:\n",
        "    height = bar.get_height()\n",
        "    ax.annotate(f'{height:.2f}',\n",
        "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                xytext=(0, 3),  # Offset for the annotation\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "for bar in bars2:\n",
        "    height = bar.get_height()\n",
        "    ax.annotate(f'{height:.2f}',\n",
        "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                xytext=(0, 3),  # Offset for the annotation\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "# Save the plot as an image file\n",
        "plt.savefig('/content/metrics_comparison_plot.png')\n",
        "\n",
        "# Download the plot image\n",
        "from google.colab import files\n",
        "files.download('/content/metrics_comparison_plot.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mx-rKpiD18D"
      },
      "source": [
        "Change colors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk4TmTm5iEUW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define metrics and their values for both models\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "ann_scores = [0.85, 0.88, 0.86, 0.87]  # Example scores for ANN\n",
        "lstm_scores = [0.88, 0.90, 0.89, 0.91]  # Example scores for LSTM\n",
        "\n",
        "# Define distinct colors for both models\n",
        "colors_ann = ['#b8b8b8', '#b8b8b8', '#b8b8b8', '#b8b8b8']  # Muted tones for ANN\n",
        "colors_lstm = ['#1a80bb', '#1a80bb', '#1a80bb', '#1a80bb']  # Muted tones for LSTM\n",
        "\n",
        "# Create the bar plot\n",
        "x = np.arange(len(metrics))  # The label locations\n",
        "width = 0.35  # Width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Create bars for ANN and LSTM with distinct colors\n",
        "bars1 = [ax.bar(x[i] - width/2, ann_scores[i], width, label='ANN' if i == 0 else \"\", color=colors_ann[i]) for i in range(len(metrics))]\n",
        "bars2 = [ax.bar(x[i] + width/2, lstm_scores[i], width, label='LSTM' if i == 0 else \"\", color=colors_lstm[i]) for i in range(len(metrics))]\n",
        "\n",
        "# Add labels, title, and custom x-axis tick labels\n",
        "ax.set_xlabel('Metrics', fontsize=12)\n",
        "ax.set_ylabel('Scores', fontsize=12)\n",
        "ax.set_title('Comparison of ANN and LSTM Models', fontsize=14)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics, fontsize=10)\n",
        "ax.legend()\n",
        "\n",
        "# Annotate bars with their values\n",
        "for i in range(len(metrics)):\n",
        "    height1 = ann_scores[i]\n",
        "    height2 = lstm_scores[i]\n",
        "    ax.annotate(f'{height1:.2f}',\n",
        "                xy=(x[i] - width/2, height1),\n",
        "                xytext=(0, 3),  # Offset for the annotation\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom', fontsize=10)\n",
        "    ax.annotate(f'{height2:.2f}',\n",
        "                xy=(x[i] + width/2, height2),\n",
        "                xytext=(0, 3),  # Offset for the annotation\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "# Save the plot as an image file\n",
        "plt.savefig('/content/metrics_comparison_plot_distinct_colors.png')\n",
        "\n",
        "# Download the plot image\n",
        "from google.colab import files\n",
        "files.download('/content/metrics_comparison_plot_distinct_colors.png')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLz8zV0FD4qx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}